diff --git a/broker/src/main/java/org/apache/rocketmq/broker/BrokerController.java b/broker/src/main/java/org/apache/rocketmq/broker/BrokerController.java
index d4bded600..9f1fd0ad0 100644
--- a/broker/src/main/java/org/apache/rocketmq/broker/BrokerController.java
+++ b/broker/src/main/java/org/apache/rocketmq/broker/BrokerController.java
@@ -16,7 +16,33 @@
  */
 package org.apache.rocketmq.broker;
 
+import java.io.IOException;
+import java.net.InetSocketAddress;
+import java.util.AbstractMap;
+import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.Collections;
+import java.util.HashMap;
+import java.util.List;
+import java.util.Map;
+import java.util.Objects;
+import java.util.Optional;
+import java.util.concurrent.BlockingQueue;
+import java.util.concurrent.ConcurrentHashMap;
+import java.util.concurrent.ConcurrentMap;
+import java.util.concurrent.CountDownLatch;
+import java.util.concurrent.ExecutorService;
+import java.util.concurrent.LinkedBlockingQueue;
+import java.util.concurrent.ScheduledExecutorService;
+import java.util.concurrent.ScheduledFuture;
+import java.util.concurrent.TimeUnit;
+import java.util.concurrent.locks.Lock;
+import java.util.concurrent.locks.ReentrantLock;
+import java.util.function.Function;
+import java.util.stream.Collectors;
+
 import com.google.common.collect.Lists;
+
 import org.apache.rocketmq.acl.AccessValidator;
 import org.apache.rocketmq.acl.plain.PlainAccessValidator;
 import org.apache.rocketmq.broker.client.ClientHousekeepingService;
@@ -126,7 +152,7 @@ import org.apache.rocketmq.store.DefaultMessageStore;
 import org.apache.rocketmq.store.MessageArrivingListener;
 import org.apache.rocketmq.store.MessageStore;
 import org.apache.rocketmq.store.PutMessageResult;
-import org.apache.rocketmq.store.StoreType;
+import org.apache.rocketmq.store.RocksDBMessageStore;
 import org.apache.rocketmq.store.config.BrokerRole;
 import org.apache.rocketmq.store.config.MessageStoreConfig;
 import org.apache.rocketmq.store.dledger.DLedgerCommitLog;
@@ -141,31 +167,6 @@ import org.apache.rocketmq.store.timer.TimerCheckpoint;
 import org.apache.rocketmq.store.timer.TimerMessageStore;
 import org.apache.rocketmq.store.timer.TimerMetrics;
 
-import java.io.IOException;
-import java.net.InetSocketAddress;
-import java.util.AbstractMap;
-import java.util.ArrayList;
-import java.util.Arrays;
-import java.util.Collections;
-import java.util.HashMap;
-import java.util.List;
-import java.util.Map;
-import java.util.Objects;
-import java.util.Optional;
-import java.util.concurrent.BlockingQueue;
-import java.util.concurrent.ConcurrentHashMap;
-import java.util.concurrent.ConcurrentMap;
-import java.util.concurrent.CountDownLatch;
-import java.util.concurrent.ExecutorService;
-import java.util.concurrent.LinkedBlockingQueue;
-import java.util.concurrent.ScheduledExecutorService;
-import java.util.concurrent.ScheduledFuture;
-import java.util.concurrent.TimeUnit;
-import java.util.concurrent.locks.Lock;
-import java.util.concurrent.locks.ReentrantLock;
-import java.util.function.Function;
-import java.util.stream.Collectors;
-
 public class BrokerController {
     protected static final Logger LOG = LoggerFactory.getLogger(LoggerName.BROKER_LOGGER_NAME);
     private static final Logger LOG_PROTECTION = LoggerFactory.getLogger(LoggerName.PROTECTION_LOGGER_NAME);
@@ -308,7 +309,7 @@ public class BrokerController {
         this.setStoreHost(new InetSocketAddress(this.getBrokerConfig().getBrokerIP1(), getListenPort()));
         this.brokerStatsManager = messageStoreConfig.isEnableLmq() ? new LmqBrokerStatsManager(this.brokerConfig.getBrokerClusterName(), this.brokerConfig.isEnableDetailStat()) : new BrokerStatsManager(this.brokerConfig.getBrokerClusterName(), this.brokerConfig.isEnableDetailStat());
         this.broadcastOffsetManager = new BroadcastOffsetManager(this);
-        if (isEnableRocksDBStore()) {
+        if (this.messageStoreConfig.isEnableRocksDBStore()) {
             this.topicConfigManager = messageStoreConfig.isEnableLmq() ? new RocksDBLmqTopicConfigManager(this) : new RocksDBTopicConfigManager(this);
             this.subscriptionGroupManager = messageStoreConfig.isEnableLmq() ? new RocksDBLmqSubscriptionGroupManager(this) : new RocksDBSubscriptionGroupManager(this);
             this.consumerOffsetManager = messageStoreConfig.isEnableLmq() ? new RocksDBLmqConsumerOffsetManager(this) : new RocksDBConsumerOffsetManager(this);
@@ -747,7 +748,12 @@ public class BrokerController {
     public boolean initializeMessageStore() {
         boolean result = true;
         try {
-            DefaultMessageStore defaultMessageStore = new DefaultMessageStore(this.messageStoreConfig, this.brokerStatsManager, this.messageArrivingListener, this.brokerConfig, topicConfigManager.getTopicConfigTable());
+            DefaultMessageStore defaultMessageStore;
+            if (this.messageStoreConfig.isEnableRocksDBStore()) {
+                defaultMessageStore = new RocksDBMessageStore(this.messageStoreConfig, this.brokerStatsManager, this.messageArrivingListener, this.brokerConfig, topicConfigManager.getTopicConfigTable());
+            } else {
+                defaultMessageStore = new DefaultMessageStore(this.messageStoreConfig, this.brokerStatsManager, this.messageArrivingListener, this.brokerConfig, topicConfigManager.getTopicConfigTable());
+            }
 
             if (messageStoreConfig.isEnableDLegerCommitLog()) {
                 DLedgerRoleChangeHandler roleChangeHandler =
@@ -944,16 +950,16 @@ public class BrokerController {
         this.transactionalMessageService = ServiceProvider.loadClass(TransactionalMessageService.class);
         if (null == this.transactionalMessageService) {
             this.transactionalMessageService = new TransactionalMessageServiceImpl(
-                    new TransactionalMessageBridge(this, this.getMessageStore()));
+                new TransactionalMessageBridge(this, this.getMessageStore()));
             LOG.warn("Load default transaction message hook service: {}",
-                    TransactionalMessageServiceImpl.class.getSimpleName());
+                TransactionalMessageServiceImpl.class.getSimpleName());
         }
         this.transactionalMessageCheckListener = ServiceProvider.loadClass(
-                AbstractTransactionalMessageCheckListener.class);
+            AbstractTransactionalMessageCheckListener.class);
         if (null == this.transactionalMessageCheckListener) {
             this.transactionalMessageCheckListener = new DefaultTransactionalMessageCheckListener();
             LOG.warn("Load default discard message hook service: {}",
-                    DefaultTransactionalMessageCheckListener.class.getSimpleName());
+                DefaultTransactionalMessageCheckListener.class.getSimpleName());
         }
         this.transactionalMessageCheckListener.setBrokerController(this);
         this.transactionalMessageCheckService = new TransactionalMessageCheckService(this);
@@ -2412,8 +2418,4 @@ public class BrokerController {
     public void setColdDataCgCtrService(ColdDataCgCtrService coldDataCgCtrService) {
         this.coldDataCgCtrService = coldDataCgCtrService;
     }
-
-    public boolean isEnableRocksDBStore() {
-        return StoreType.DEFAULT_ROCKSDB.getStoreType().equalsIgnoreCase(this.messageStoreConfig.getStoreType());
-    }
 }
diff --git a/broker/src/main/java/org/apache/rocketmq/broker/controller/ReplicasManager.java b/broker/src/main/java/org/apache/rocketmq/broker/controller/ReplicasManager.java
index a989e6e68..a1d711cb2 100644
--- a/broker/src/main/java/org/apache/rocketmq/broker/controller/ReplicasManager.java
+++ b/broker/src/main/java/org/apache/rocketmq/broker/controller/ReplicasManager.java
@@ -224,7 +224,7 @@ public class ReplicasManager {
 
     public synchronized void changeBrokerRole(final Long newMasterBrokerId, final String newMasterAddress,
         final Integer newMasterEpoch,
-        final Integer syncStateSetEpoch, final Set<Long> syncStateSet) {
+        final Integer syncStateSetEpoch, final Set<Long> syncStateSet) throws Exception {
         if (newMasterBrokerId != null && newMasterEpoch > this.masterEpoch) {
             if (newMasterBrokerId.equals(this.brokerControllerId)) {
                 changeToMaster(newMasterEpoch, syncStateSetEpoch, syncStateSet);
@@ -234,7 +234,7 @@ public class ReplicasManager {
         }
     }
 
-    public void changeToMaster(final int newMasterEpoch, final int syncStateSetEpoch, final Set<Long> syncStateSet) {
+    public void changeToMaster(final int newMasterEpoch, final int syncStateSetEpoch, final Set<Long> syncStateSet) throws Exception {
         synchronized (this) {
             if (newMasterEpoch > this.masterEpoch) {
                 LOGGER.info("Begin to change to master, brokerName:{}, replicas:{}, new Epoch:{}", this.brokerConfig.getBrokerName(), this.brokerAddress, newMasterEpoch);
diff --git a/broker/src/main/java/org/apache/rocketmq/broker/offset/RocksDBConsumerOffsetManager.java b/broker/src/main/java/org/apache/rocketmq/broker/offset/RocksDBConsumerOffsetManager.java
index 5695a3356..05b53b0bc 100644
--- a/broker/src/main/java/org/apache/rocketmq/broker/offset/RocksDBConsumerOffsetManager.java
+++ b/broker/src/main/java/org/apache/rocketmq/broker/offset/RocksDBConsumerOffsetManager.java
@@ -33,7 +33,7 @@ public class RocksDBConsumerOffsetManager extends ConsumerOffsetManager {
 
     public RocksDBConsumerOffsetManager(BrokerController brokerController) {
         super(brokerController);
-        this.rocksDBConfigManager = new RocksDBConfigManager(this.brokerController.getMessageStoreConfig().getMemTableFlushInterval());
+        this.rocksDBConfigManager = new RocksDBConfigManager(brokerController.getMessageStoreConfig().getMemTableFlushIntervalMs());
     }
 
     @Override
@@ -49,7 +49,7 @@ public class RocksDBConsumerOffsetManager extends ConsumerOffsetManager {
     @Override
     protected void removeConsumerOffset(String topicAtGroup) {
         try {
-            byte[] keyBytes = topicAtGroup.getBytes(DataConverter.charset);
+            byte[] keyBytes = topicAtGroup.getBytes(DataConverter.CHARSET_UTF8);
             this.rocksDBConfigManager.delete(keyBytes);
         } catch (Exception e) {
             LOG.error("kv remove consumerOffset Failed, {}", topicAtGroup);
@@ -58,7 +58,7 @@ public class RocksDBConsumerOffsetManager extends ConsumerOffsetManager {
 
     @Override
     protected void decode0(final byte[] key, final byte[] body) {
-        String topicAtGroup = new String(key, DataConverter.charset);
+        String topicAtGroup = new String(key, DataConverter.CHARSET_UTF8);
         RocksDBOffsetSerializeWrapper wrapper = JSON.parseObject(body, RocksDBOffsetSerializeWrapper.class);
 
         this.offsetTable.put(topicAtGroup, wrapper.getOffsetTable());
@@ -93,7 +93,7 @@ public class RocksDBConsumerOffsetManager extends ConsumerOffsetManager {
     }
 
     private void putWriteBatch(final WriteBatch writeBatch, final String topicGroupName, final ConcurrentMap<Integer, Long> offsetMap) throws Exception {
-        byte[] keyBytes = topicGroupName.getBytes(DataConverter.charset);
+        byte[] keyBytes = topicGroupName.getBytes(DataConverter.CHARSET_UTF8);
         RocksDBOffsetSerializeWrapper wrapper = new RocksDBOffsetSerializeWrapper();
         wrapper.setOffsetTable(offsetMap);
         byte[] valueBytes = JSON.toJSONBytes(wrapper, SerializerFeature.BrowserCompatible);
diff --git a/broker/src/main/java/org/apache/rocketmq/broker/processor/AckMessageProcessor.java b/broker/src/main/java/org/apache/rocketmq/broker/processor/AckMessageProcessor.java
index 244b459d6..59a3e63b2 100644
--- a/broker/src/main/java/org/apache/rocketmq/broker/processor/AckMessageProcessor.java
+++ b/broker/src/main/java/org/apache/rocketmq/broker/processor/AckMessageProcessor.java
@@ -253,7 +253,7 @@ public class AckMessageProcessor implements NettyRequestProcessor {
 
         MessageExtBrokerInner msgInner = new MessageExtBrokerInner();
         msgInner.setTopic(reviveTopic);
-        msgInner.setBody(JSON.toJSONString(ackMsg).getBytes(DataConverter.charset));
+        msgInner.setBody(JSON.toJSONString(ackMsg).getBytes(DataConverter.CHARSET_UTF8));
         msgInner.setQueueId(rqId);
         if (ackMsg instanceof BatchAckMsg) {
             msgInner.setTags(PopAckConstants.BATCH_ACK_TAG);
diff --git a/broker/src/main/java/org/apache/rocketmq/broker/processor/AdminBrokerProcessor.java b/broker/src/main/java/org/apache/rocketmq/broker/processor/AdminBrokerProcessor.java
index e77120e15..dd4ec960f 100644
--- a/broker/src/main/java/org/apache/rocketmq/broker/processor/AdminBrokerProcessor.java
+++ b/broker/src/main/java/org/apache/rocketmq/broker/processor/AdminBrokerProcessor.java
@@ -539,14 +539,18 @@ public class AdminBrokerProcessor implements NettyRequestProcessor {
 
         final Set<String> groups = this.brokerController.getConsumerOffsetManager().whichGroupByTopic(topic);
         // delete pop retry topics first
-        for (String group : groups) {
-            final String popRetryTopic = KeyBuilder.buildPopRetryTopic(topic, group);
-            if (brokerController.getTopicConfigManager().selectTopicConfig(popRetryTopic) != null) {
-                deleteTopicInBroker(popRetryTopic);
+        try {
+            for (String group : groups) {
+                final String popRetryTopic = KeyBuilder.buildPopRetryTopic(topic, group);
+                if (brokerController.getTopicConfigManager().selectTopicConfig(popRetryTopic) != null) {
+                    deleteTopicInBroker(popRetryTopic);
+                }
             }
+            // delete topic
+            deleteTopicInBroker(topic);
+        } catch (Throwable t) {
+            return buildErrorResponse(ResponseCode.SYSTEM_ERROR, t.getMessage());
         }
-        // delete topic
-        deleteTopicInBroker(topic);
         response.setCode(ResponseCode.SUCCESS);
         response.setRemark(null);
         return response;
@@ -2081,7 +2085,11 @@ public class AdminBrokerProcessor implements NettyRequestProcessor {
     public RemotingCommand cleanExpiredConsumeQueue() {
         LOGGER.info("AdminBrokerProcessor#cleanExpiredConsumeQueue: start.");
         final RemotingCommand response = RemotingCommand.createResponseCommand(null);
-        brokerController.getMessageStore().cleanExpiredConsumerQueue();
+        try {
+            brokerController.getMessageStore().cleanExpiredConsumerQueue();
+        } catch (Throwable t) {
+            return buildErrorResponse(ResponseCode.SYSTEM_ERROR, t.getMessage());
+        }
         LOGGER.info("AdminBrokerProcessor#cleanExpiredConsumeQueue: end.");
         response.setCode(ResponseCode.SUCCESS);
         response.setRemark(null);
@@ -2781,7 +2789,11 @@ public class AdminBrokerProcessor implements NettyRequestProcessor {
 
         final ReplicasManager replicasManager = this.brokerController.getReplicasManager();
         if (replicasManager != null) {
-            replicasManager.changeBrokerRole(requestHeader.getMasterBrokerId(), requestHeader.getMasterAddress(), requestHeader.getMasterEpoch(), requestHeader.getSyncStateSetEpoch(), syncStateSetInfo.getSyncStateSet());
+            try {
+                replicasManager.changeBrokerRole(requestHeader.getMasterBrokerId(), requestHeader.getMasterAddress(), requestHeader.getMasterEpoch(), requestHeader.getSyncStateSetEpoch(), syncStateSetInfo.getSyncStateSet());
+            } catch (Exception e) {
+                throw new RemotingCommandException(e.getMessage());
+            }
         }
         response.setCode(ResponseCode.SUCCESS);
         response.setRemark(null);
diff --git a/broker/src/main/java/org/apache/rocketmq/broker/processor/ChangeInvisibleTimeProcessor.java b/broker/src/main/java/org/apache/rocketmq/broker/processor/ChangeInvisibleTimeProcessor.java
index 2ccdf07f6..bdfffff09 100644
--- a/broker/src/main/java/org/apache/rocketmq/broker/processor/ChangeInvisibleTimeProcessor.java
+++ b/broker/src/main/java/org/apache/rocketmq/broker/processor/ChangeInvisibleTimeProcessor.java
@@ -180,7 +180,7 @@ public class ChangeInvisibleTimeProcessor implements NettyRequestProcessor {
         }
 
         msgInner.setTopic(reviveTopic);
-        msgInner.setBody(JSON.toJSONString(ackMsg).getBytes(DataConverter.charset));
+        msgInner.setBody(JSON.toJSONString(ackMsg).getBytes(DataConverter.CHARSET_UTF8));
         msgInner.setQueueId(rqId);
         msgInner.setTags(PopAckConstants.ACK_TAG);
         msgInner.setBornTimestamp(System.currentTimeMillis());
@@ -216,7 +216,7 @@ public class ChangeInvisibleTimeProcessor implements NettyRequestProcessor {
         ck.addDiff(0);
         ck.setBrokerName(brokerName);
 
-        msgInner.setBody(JSON.toJSONString(ck).getBytes(DataConverter.charset));
+        msgInner.setBody(JSON.toJSONString(ck).getBytes(DataConverter.CHARSET_UTF8));
         msgInner.setQueueId(reviveQid);
         msgInner.setTags(PopAckConstants.CK_TAG);
         msgInner.setBornTimestamp(System.currentTimeMillis());
diff --git a/broker/src/main/java/org/apache/rocketmq/broker/processor/PopBufferMergeService.java b/broker/src/main/java/org/apache/rocketmq/broker/processor/PopBufferMergeService.java
index b7ba8ad4a..8a85dd8fe 100644
--- a/broker/src/main/java/org/apache/rocketmq/broker/processor/PopBufferMergeService.java
+++ b/broker/src/main/java/org/apache/rocketmq/broker/processor/PopBufferMergeService.java
@@ -633,7 +633,7 @@ public class PopBufferMergeService extends ServiceThread {
         ackMsg.setQueueId(point.getQueueId());
         ackMsg.setPopTime(point.getPopTime());
         msgInner.setTopic(popMessageProcessor.reviveTopic);
-        msgInner.setBody(JSON.toJSONString(ackMsg).getBytes(DataConverter.charset));
+        msgInner.setBody(JSON.toJSONString(ackMsg).getBytes(DataConverter.CHARSET_UTF8));
         msgInner.setQueueId(pointWrapper.getReviveQueueId());
         msgInner.setTags(PopAckConstants.ACK_TAG);
         msgInner.setBornTimestamp(System.currentTimeMillis());
@@ -673,7 +673,7 @@ public class PopBufferMergeService extends ServiceThread {
         batchAckMsg.setQueueId(point.getQueueId());
         batchAckMsg.setPopTime(point.getPopTime());
         msgInner.setTopic(popMessageProcessor.reviveTopic);
-        msgInner.setBody(JSON.toJSONString(batchAckMsg).getBytes(DataConverter.charset));
+        msgInner.setBody(JSON.toJSONString(batchAckMsg).getBytes(DataConverter.CHARSET_UTF8));
         msgInner.setQueueId(pointWrapper.getReviveQueueId());
         msgInner.setTags(PopAckConstants.BATCH_ACK_TAG);
         msgInner.setBornTimestamp(System.currentTimeMillis());
diff --git a/broker/src/main/java/org/apache/rocketmq/broker/processor/PopMessageProcessor.java b/broker/src/main/java/org/apache/rocketmq/broker/processor/PopMessageProcessor.java
index 0d9bdf143..f5d07c5aa 100644
--- a/broker/src/main/java/org/apache/rocketmq/broker/processor/PopMessageProcessor.java
+++ b/broker/src/main/java/org/apache/rocketmq/broker/processor/PopMessageProcessor.java
@@ -685,7 +685,7 @@ public class PopMessageProcessor implements NettyRequestProcessor {
         MessageExtBrokerInner msgInner = new MessageExtBrokerInner();
 
         msgInner.setTopic(reviveTopic);
-        msgInner.setBody(JSON.toJSONString(ck).getBytes(DataConverter.charset));
+        msgInner.setBody(JSON.toJSONString(ck).getBytes(DataConverter.CHARSET_UTF8));
         msgInner.setQueueId(reviveQid);
         msgInner.setTags(PopAckConstants.CK_TAG);
         msgInner.setBornTimestamp(System.currentTimeMillis());
diff --git a/broker/src/main/java/org/apache/rocketmq/broker/processor/PopReviveService.java b/broker/src/main/java/org/apache/rocketmq/broker/processor/PopReviveService.java
index d5174d3d1..4f80752e1 100644
--- a/broker/src/main/java/org/apache/rocketmq/broker/processor/PopReviveService.java
+++ b/broker/src/main/java/org/apache/rocketmq/broker/processor/PopReviveService.java
@@ -356,7 +356,7 @@ public class PopReviveService extends ServiceThread {
             }
             for (MessageExt messageExt : messageExts) {
                 if (PopAckConstants.CK_TAG.equals(messageExt.getTags())) {
-                    String raw = new String(messageExt.getBody(), DataConverter.charset);
+                    String raw = new String(messageExt.getBody(), DataConverter.CHARSET_UTF8);
                     if (brokerController.getBrokerConfig().isEnablePopLog()) {
                         POP_LOGGER.info("reviveQueueId={},find ck, offset:{}, raw : {}", messageExt.getQueueId(), messageExt.getQueueOffset(), raw);
                     }
@@ -371,7 +371,7 @@ public class PopReviveService extends ServiceThread {
                         firstRt = point.getReviveTime();
                     }
                 } else if (PopAckConstants.ACK_TAG.equals(messageExt.getTags())) {
-                    String raw = new String(messageExt.getBody(), DataConverter.charset);
+                    String raw = new String(messageExt.getBody(), DataConverter.CHARSET_UTF8);
                     if (brokerController.getBrokerConfig().isEnablePopLog()) {
                         POP_LOGGER.info("reviveQueueId={},find ack, offset:{}, raw : {}", messageExt.getQueueId(), messageExt.getQueueOffset(), raw);
                     }
@@ -395,7 +395,7 @@ public class PopReviveService extends ServiceThread {
                         }
                     }
                 } else if (PopAckConstants.BATCH_ACK_TAG.equals(messageExt.getTags())) {
-                    String raw = new String(messageExt.getBody(), DataConverter.charset);
+                    String raw = new String(messageExt.getBody(), DataConverter.CHARSET_UTF8);
                     if (brokerController.getBrokerConfig().isEnablePopLog()) {
                         POP_LOGGER.info("reviveQueueId={}, find batch ack, offset:{}, raw : {}", messageExt.getQueueId(), messageExt.getQueueOffset(), raw);
                     }
diff --git a/broker/src/main/java/org/apache/rocketmq/broker/subscription/RocksDBSubscriptionGroupManager.java b/broker/src/main/java/org/apache/rocketmq/broker/subscription/RocksDBSubscriptionGroupManager.java
index 6503970af..e9a81a8d6 100644
--- a/broker/src/main/java/org/apache/rocketmq/broker/subscription/RocksDBSubscriptionGroupManager.java
+++ b/broker/src/main/java/org/apache/rocketmq/broker/subscription/RocksDBSubscriptionGroupManager.java
@@ -30,7 +30,7 @@ public class RocksDBSubscriptionGroupManager extends SubscriptionGroupManager {
 
     public RocksDBSubscriptionGroupManager(BrokerController brokerController) {
         super(brokerController, false);
-        this.rocksDBConfigManager = new RocksDBConfigManager(this.brokerController.getMessageStoreConfig().getMemTableFlushInterval());
+        this.rocksDBConfigManager = new RocksDBConfigManager(brokerController.getMessageStoreConfig().getMemTableFlushIntervalMs());
     }
 
     @Override
@@ -53,7 +53,7 @@ public class RocksDBSubscriptionGroupManager extends SubscriptionGroupManager {
         SubscriptionGroupConfig oldConfig = this.subscriptionGroupTable.put(groupName, subscriptionGroupConfig);
 
         try {
-            byte[] keyBytes = groupName.getBytes(DataConverter.charset);
+            byte[] keyBytes = groupName.getBytes(DataConverter.CHARSET_UTF8);
             byte[] valueBytes = JSON.toJSONBytes(subscriptionGroupConfig, SerializerFeature.BrowserCompatible);
             this.rocksDBConfigManager.put(keyBytes, keyBytes.length, valueBytes);
         } catch (Exception e) {
@@ -68,7 +68,7 @@ public class RocksDBSubscriptionGroupManager extends SubscriptionGroupManager {
         SubscriptionGroupConfig oldConfig = this.subscriptionGroupTable.putIfAbsent(groupName, subscriptionGroupConfig);
         if (oldConfig == null) {
             try {
-                byte[] keyBytes = groupName.getBytes(DataConverter.charset);
+                byte[] keyBytes = groupName.getBytes(DataConverter.CHARSET_UTF8);
                 byte[] valueBytes = JSON.toJSONBytes(subscriptionGroupConfig, SerializerFeature.BrowserCompatible);
                 this.rocksDBConfigManager.put(keyBytes, keyBytes.length, valueBytes);
             } catch (Exception e) {
@@ -82,7 +82,7 @@ public class RocksDBSubscriptionGroupManager extends SubscriptionGroupManager {
     protected SubscriptionGroupConfig removeSubscriptionGroupConfig(String groupName) {
         SubscriptionGroupConfig subscriptionGroupConfig = this.subscriptionGroupTable.remove(groupName);
         try {
-            this.rocksDBConfigManager.delete(groupName.getBytes(DataConverter.charset));
+            this.rocksDBConfigManager.delete(groupName.getBytes(DataConverter.CHARSET_UTF8));
         } catch (Exception e) {
             log.error("kv delete sub Failed, {}", subscriptionGroupConfig.toString());
         }
@@ -91,7 +91,7 @@ public class RocksDBSubscriptionGroupManager extends SubscriptionGroupManager {
 
     @Override
     protected void decode0(byte[] key, byte[] body) {
-        String groupName = new String(key, DataConverter.charset);
+        String groupName = new String(key, DataConverter.CHARSET_UTF8);
         SubscriptionGroupConfig subscriptionGroupConfig = JSON.parseObject(body, SubscriptionGroupConfig.class);
 
         this.subscriptionGroupTable.put(groupName, subscriptionGroupConfig);
diff --git a/broker/src/main/java/org/apache/rocketmq/broker/topic/RocksDBTopicConfigManager.java b/broker/src/main/java/org/apache/rocketmq/broker/topic/RocksDBTopicConfigManager.java
index 7da0d7c8a..fddecf2d9 100644
--- a/broker/src/main/java/org/apache/rocketmq/broker/topic/RocksDBTopicConfigManager.java
+++ b/broker/src/main/java/org/apache/rocketmq/broker/topic/RocksDBTopicConfigManager.java
@@ -30,7 +30,7 @@ public class RocksDBTopicConfigManager extends TopicConfigManager {
 
     public RocksDBTopicConfigManager(BrokerController brokerController) {
         super(brokerController, false);
-        this.rocksDBConfigManager = new RocksDBConfigManager(this.brokerController.getMessageStoreConfig().getMemTableFlushInterval());
+        this.rocksDBConfigManager = new RocksDBConfigManager(brokerController.getMessageStoreConfig().getMemTableFlushIntervalMs());
     }
 
     @Override
@@ -49,7 +49,7 @@ public class RocksDBTopicConfigManager extends TopicConfigManager {
 
     @Override
     protected void decode0(byte[] key, byte[] body) {
-        String topicName = new String(key, DataConverter.charset);
+        String topicName = new String(key, DataConverter.CHARSET_UTF8);
         TopicConfig topicConfig = JSON.parseObject(body, TopicConfig.class);
 
         this.topicConfigTable.put(topicName, topicConfig);
@@ -66,7 +66,7 @@ public class RocksDBTopicConfigManager extends TopicConfigManager {
         String topicName = topicConfig.getTopicName();
         TopicConfig oldTopicConfig = this.topicConfigTable.put(topicName, topicConfig);
         try {
-            byte[] keyBytes = topicName.getBytes(DataConverter.charset);
+            byte[] keyBytes = topicName.getBytes(DataConverter.CHARSET_UTF8);
             byte[] valueBytes = JSON.toJSONBytes(topicConfig, SerializerFeature.BrowserCompatible);
             this.rocksDBConfigManager.put(keyBytes, keyBytes.length, valueBytes);
         } catch (Exception e) {
@@ -79,7 +79,7 @@ public class RocksDBTopicConfigManager extends TopicConfigManager {
     protected TopicConfig removeTopicConfig(String topicName) {
         TopicConfig topicConfig = this.topicConfigTable.remove(topicName);
         try {
-            this.rocksDBConfigManager.delete(topicName.getBytes(DataConverter.charset));
+            this.rocksDBConfigManager.delete(topicName.getBytes(DataConverter.CHARSET_UTF8));
         } catch (Exception e) {
             log.error("kv remove topic Failed, {}", topicConfig.toString());
         }
diff --git a/common/src/main/java/org/apache/rocketmq/common/MixAll.java b/common/src/main/java/org/apache/rocketmq/common/MixAll.java
index 1233a5422..407ef2842 100644
--- a/common/src/main/java/org/apache/rocketmq/common/MixAll.java
+++ b/common/src/main/java/org/apache/rocketmq/common/MixAll.java
@@ -492,6 +492,7 @@ public class MixAll {
     public static int compareLong(long x, long y) {
         return Long.compare(x, y);
     }
+
     public static boolean isLmq(String lmqMetaData) {
         return lmqMetaData != null && lmqMetaData.startsWith(LMQ_PREFIX);
     }
diff --git a/common/src/main/java/org/apache/rocketmq/common/attribute/CQType.java b/common/src/main/java/org/apache/rocketmq/common/attribute/CQType.java
index 73ef21880..9148d5a18 100644
--- a/common/src/main/java/org/apache/rocketmq/common/attribute/CQType.java
+++ b/common/src/main/java/org/apache/rocketmq/common/attribute/CQType.java
@@ -19,5 +19,6 @@ package org.apache.rocketmq.common.attribute;
 
 public enum CQType {
     SimpleCQ,
-    BatchCQ
+    BatchCQ,
+    RocksDBCQ
 }
diff --git a/common/src/main/java/org/apache/rocketmq/common/config/AbstractRocksDBStorage.java b/common/src/main/java/org/apache/rocketmq/common/config/AbstractRocksDBStorage.java
index 6f19a9815..20319abba 100644
--- a/common/src/main/java/org/apache/rocketmq/common/config/AbstractRocksDBStorage.java
+++ b/common/src/main/java/org/apache/rocketmq/common/config/AbstractRocksDBStorage.java
@@ -17,7 +17,6 @@
 package org.apache.rocketmq.common.config;
 
 import java.nio.ByteBuffer;
-import java.nio.charset.Charset;
 import java.util.ArrayList;
 import java.util.List;
 import java.util.Map;
@@ -27,11 +26,11 @@ import java.util.concurrent.Semaphore;
 import java.util.concurrent.ThreadPoolExecutor;
 import java.util.concurrent.TimeUnit;
 
-import com.google.common.collect.Lists;
 import com.google.common.collect.Maps;
 
 import org.apache.rocketmq.common.ThreadFactoryImpl;
 import org.apache.rocketmq.common.constant.LoggerName;
+import org.apache.rocketmq.common.utils.DataConverter;
 import org.apache.rocketmq.common.utils.ThreadUtils;
 import org.apache.rocketmq.logging.org.slf4j.Logger;
 import org.apache.rocketmq.logging.org.slf4j.LoggerFactory;
@@ -47,7 +46,6 @@ import org.rocksdb.Priority;
 import org.rocksdb.ReadOptions;
 import org.rocksdb.RocksDB;
 import org.rocksdb.RocksDBException;
-import org.rocksdb.RocksIterator;
 import org.rocksdb.Statistics;
 import org.rocksdb.Status;
 import org.rocksdb.WriteBatch;
@@ -58,7 +56,6 @@ import static org.rocksdb.RocksDB.NOT_FOUND;
 public abstract class AbstractRocksDBStorage {
     protected static final Logger LOGGER = LoggerFactory.getLogger(LoggerName.ROCKSDB_LOGGER_NAME);
 
-    private static final Charset CHARSET_UTF8 = Charset.forName("UTF-8");
     private static final String SPACE = " | ";
 
     protected String dbPath;
@@ -223,10 +220,6 @@ public abstract class AbstractRocksDBStorage {
         }
     }
 
-    protected WrappedRocksIterator newIterator(ColumnFamilyHandle cfHandle, ReadOptions readOptions) {
-        return new WrappedRocksIterator(this.db.newIterator(cfHandle, readOptions));
-    }
-
     protected void rangeDelete(ColumnFamilyHandle cfHandle, WriteOptions writeOptions,
                                final byte[] startKey, final byte[] endKey) throws RocksDBException {
         if (!hold()) {
@@ -243,46 +236,6 @@ public abstract class AbstractRocksDBStorage {
         }
     }
 
-    protected void manualCompactionDefaultCfMaxLevel(final CompactionOptions compactionOptions) throws Exception {
-        final ColumnFamilyHandle defaultCFHandle = this.defaultCFHandle;
-        final byte[] defaultCFName = defaultCFHandle.getName();
-        List<LiveFileMetaData> fileMetaDataList = this.db.getLiveFilesMetaData();
-        if (fileMetaDataList == null || fileMetaDataList.isEmpty()) {
-            return;
-        }
-
-        List<LiveFileMetaData> defaultLiveFileDataList = Lists.newArrayList();
-        List<String> inputFileNames = Lists.newArrayList();
-        int maxLevel = 0;
-        for (LiveFileMetaData fileMetaData : fileMetaDataList) {
-            if (compareTo(fileMetaData.columnFamilyName(), defaultCFName) != 0) {
-                continue;
-            }
-            defaultLiveFileDataList.add(fileMetaData);
-            if (fileMetaData.level() > maxLevel) {
-                maxLevel = fileMetaData.level();
-            }
-        }
-        if (maxLevel == 0) {
-            LOGGER.info("manualCompactionDefaultCfFiles skip level 0.");
-            return;
-        }
-
-        for (LiveFileMetaData fileMetaData : defaultLiveFileDataList) {
-            if (fileMetaData.level() != maxLevel || fileMetaData.beingCompacted()) {
-                continue;
-            }
-            inputFileNames.add(fileMetaData.path() + fileMetaData.fileName());
-        }
-        if (!inputFileNames.isEmpty()) {
-            List<String> outputLists = this.db.compactFiles(compactionOptions, defaultCFHandle,
-                    inputFileNames, maxLevel, -1, null);
-            LOGGER.info("manualCompactionDefaultCfFiles OK. src: {}, dst: {}", inputFileNames, outputLists);
-        } else {
-            LOGGER.info("manualCompactionDefaultCfFiles Empty.");
-        }
-    }
-
     protected void manualCompactionDefaultCfRange(CompactRangeOptions compactRangeOptions) {
         if (!hold()) {
             return;
@@ -494,50 +447,6 @@ public abstract class AbstractRocksDBStorage {
         this.db.flushWal(true);
     }
 
-    protected class WrappedRocksIterator {
-        private final RocksIterator iterator;
-
-        public WrappedRocksIterator(final RocksIterator iterator) {
-            this.iterator = iterator;
-        }
-
-        public byte[] key() {
-            return iterator.key();
-        }
-
-        public byte[] value() {
-            return iterator.value();
-        }
-
-        public void next() {
-            iterator.next();
-        }
-
-        public void prev() {
-            iterator.prev();
-        }
-
-        public void seek(byte[] target) {
-            iterator.seek(target);
-        }
-
-        public void seekForPrev(byte[] target) {
-            iterator.seekForPrev(target);
-        }
-
-        public void seekToFirst() {
-            iterator.seekToFirst();
-        }
-
-        public boolean isValid() {
-            return iterator.isValid();
-        }
-
-        public void close() {
-            iterator.close();
-        }
-    }
-
     private String getStatusError(RocksDBException e) {
         if (e == null || e.getStatus() == null) {
             return "null";
@@ -574,7 +483,7 @@ public abstract class AbstractRocksDBStorage {
                     sb = new StringBuilder(256);
                     map.put(metaData.level(), sb);
                 }
-                sb.append(new String(metaData.columnFamilyName(), CHARSET_UTF8)).append(SPACE).
+                sb.append(new String(metaData.columnFamilyName(), DataConverter.CHARSET_UTF8)).append(SPACE).
                         append(metaData.fileName()).append(SPACE).
                         append("s: ").append(metaData.size()).append(SPACE).
                         append("a: ").append(metaData.numEntries()).append(SPACE).
@@ -595,21 +504,4 @@ public abstract class AbstractRocksDBStorage {
         } catch (Exception ignored) {
         }
     }
-
-    public int compareTo(byte[] v1, byte[] v2) {
-        int len1 = v1.length;
-        int len2 = v2.length;
-        int lim = Math.min(len1, len2);
-
-        int k = 0;
-        while (k < lim) {
-            byte c1 = v1[k];
-            byte c2 = v2[k];
-            if (c1 != c2) {
-                return c1 - c2;
-            }
-            k++;
-        }
-        return len1 - len2;
-    }
 }
\ No newline at end of file
diff --git a/common/src/main/java/org/apache/rocketmq/common/config/ConfigRocksDBStorage.java b/common/src/main/java/org/apache/rocketmq/common/config/ConfigRocksDBStorage.java
index 463bd8fed..b40f8046e 100644
--- a/common/src/main/java/org/apache/rocketmq/common/config/ConfigRocksDBStorage.java
+++ b/common/src/main/java/org/apache/rocketmq/common/config/ConfigRocksDBStorage.java
@@ -203,7 +203,7 @@ public class ConfigRocksDBStorage extends AbstractRocksDBStorage {
             setUseDirectReads(true);
     }
 
-    private static String getDBLogDir() {
+    public static String getDBLogDir() {
         String rootPath = System.getProperty("user.home");
         if (StringUtils.isEmpty(rootPath)) {
             return "";
diff --git a/common/src/main/java/org/apache/rocketmq/common/message/MessageExtBrokerInner.java b/common/src/main/java/org/apache/rocketmq/common/message/MessageExtBrokerInner.java
index 0c72ebb7b..91599653c 100644
--- a/common/src/main/java/org/apache/rocketmq/common/message/MessageExtBrokerInner.java
+++ b/common/src/main/java/org/apache/rocketmq/common/message/MessageExtBrokerInner.java
@@ -70,4 +70,17 @@ public class MessageExtBrokerInner extends MessageExt {
     public void setVersion(MessageVersion version) {
         this.version = version;
     }
+
+    public void removeWaitStorePropertyString() {
+        if (this.getProperties().containsKey(MessageConst.PROPERTY_WAIT_STORE_MSG_OK)) {
+            // There is no need to store "WAIT=true", remove it from propertiesString to save 9 bytes for each message.
+            // It works for most case. In some cases msgInner.setPropertiesString invoked later and replace it.
+            String waitStoreMsgOKValue = this.getProperties().remove(MessageConst.PROPERTY_WAIT_STORE_MSG_OK);
+            this.setPropertiesString(MessageDecoder.messageProperties2String(this.getProperties()));
+            // Reput to properties, since msgInner.isWaitStoreMsgOK() will be invoked later
+            this.getProperties().put(MessageConst.PROPERTY_WAIT_STORE_MSG_OK, waitStoreMsgOKValue);
+        } else {
+            this.setPropertiesString(MessageDecoder.messageProperties2String(this.getProperties()));
+        }
+    }
 }
diff --git a/common/src/main/java/org/apache/rocketmq/common/topic/TopicValidator.java b/common/src/main/java/org/apache/rocketmq/common/topic/TopicValidator.java
index 61265c05d..c19592a44 100644
--- a/common/src/main/java/org/apache/rocketmq/common/topic/TopicValidator.java
+++ b/common/src/main/java/org/apache/rocketmq/common/topic/TopicValidator.java
@@ -31,6 +31,7 @@ public class TopicValidator {
     public static final String RMQ_SYS_TRANS_CHECK_MAX_TIME_TOPIC = "TRANS_CHECK_MAX_TIME_TOPIC";
     public static final String RMQ_SYS_SELF_TEST_TOPIC = "SELF_TEST_TOPIC";
     public static final String RMQ_SYS_OFFSET_MOVED_EVENT = "OFFSET_MOVED_EVENT";
+    public static final String RMQ_SYS_ROCKSDB_OFFSET_TOPIC = "CHECKPOINT_TOPIC";
 
     public static final String SYSTEM_TOPIC_PREFIX = "rmq_sys_";
     public static final String SYNC_BROKER_MEMBER_GROUP_PREFIX = SYSTEM_TOPIC_PREFIX + "SYNC_BROKER_MEMBER_";
@@ -55,6 +56,7 @@ public class TopicValidator {
         SYSTEM_TOPIC_SET.add(RMQ_SYS_TRANS_CHECK_MAX_TIME_TOPIC);
         SYSTEM_TOPIC_SET.add(RMQ_SYS_SELF_TEST_TOPIC);
         SYSTEM_TOPIC_SET.add(RMQ_SYS_OFFSET_MOVED_EVENT);
+        SYSTEM_TOPIC_SET.add(RMQ_SYS_ROCKSDB_OFFSET_TOPIC);
 
         NOT_ALLOWED_SEND_TOPIC_SET.add(RMQ_SYS_SCHEDULE_TOPIC);
         NOT_ALLOWED_SEND_TOPIC_SET.add(RMQ_SYS_TRANS_HALF_TOPIC);
diff --git a/common/src/main/java/org/apache/rocketmq/common/utils/DataConverter.java b/common/src/main/java/org/apache/rocketmq/common/utils/DataConverter.java
index 8b50de12b..cc96770b2 100644
--- a/common/src/main/java/org/apache/rocketmq/common/utils/DataConverter.java
+++ b/common/src/main/java/org/apache/rocketmq/common/utils/DataConverter.java
@@ -20,7 +20,7 @@ import java.nio.ByteBuffer;
 import java.nio.charset.Charset;
 
 public class DataConverter {
-    public static Charset charset = Charset.forName("UTF-8");
+    public static final Charset CHARSET_UTF8 = Charset.forName("UTF-8");
 
     public static byte[] Long2Byte(Long v) {
         ByteBuffer tmp = ByteBuffer.allocate(8);
diff --git a/store/src/main/java/org/apache/rocketmq/store/CommitLog.java b/store/src/main/java/org/apache/rocketmq/store/CommitLog.java
index f98e9a284..93102799b 100644
--- a/store/src/main/java/org/apache/rocketmq/store/CommitLog.java
+++ b/store/src/main/java/org/apache/rocketmq/store/CommitLog.java
@@ -60,6 +60,8 @@ import org.apache.rocketmq.store.ha.HAService;
 import org.apache.rocketmq.store.ha.autoswitch.AutoSwitchHAService;
 import org.apache.rocketmq.store.logfile.MappedFile;
 import org.apache.rocketmq.store.util.LibC;
+import org.rocksdb.RocksDBException;
+
 import sun.nio.ch.DirectBuffer;
 
 /**
@@ -299,8 +301,9 @@ public class CommitLog implements Swappable {
 
     /**
      * When the normal exit, data recovery, all memory data have been flush
+     * @throws RocksDBException only in rocksdb mode
      */
-    public void recoverNormally(long maxPhyOffsetOfConsumeQueue) {
+    public void recoverNormally(long maxPhyOffsetOfConsumeQueue) throws RocksDBException {
         boolean checkCRCOnRecover = this.defaultMessageStore.getMessageStoreConfig().isCheckCRCOnRecover();
         boolean checkDupInfo = this.defaultMessageStore.getMessageStoreConfig().isDuplicationEnable();
         final List<MappedFile> mappedFiles = this.mappedFileQueue.getMappedFiles();
@@ -369,21 +372,22 @@ public class CommitLog implements Swappable {
                 this.setConfirmOffset(lastValidMsgPhyOffset);
             }
 
-            this.mappedFileQueue.setFlushedWhere(processOffset);
-            this.mappedFileQueue.setCommittedWhere(processOffset);
-            this.mappedFileQueue.truncateDirtyFiles(processOffset);
-
             // Clear ConsumeQueue redundant data
             if (maxPhyOffsetOfConsumeQueue >= processOffset) {
                 log.warn("maxPhyOffsetOfConsumeQueue({}) >= processOffset({}), truncate dirty logic files", maxPhyOffsetOfConsumeQueue, processOffset);
                 this.defaultMessageStore.truncateDirtyLogicFiles(processOffset);
             }
+
+            this.mappedFileQueue.setFlushedWhere(processOffset);
+            this.mappedFileQueue.setCommittedWhere(processOffset);
+            this.mappedFileQueue.truncateDirtyFiles(processOffset);
         } else {
             // Commitlog case files are deleted
             log.warn("The commitlog files are deleted, and delete the consume queue files");
             this.mappedFileQueue.setFlushedWhere(0);
             this.mappedFileQueue.setCommittedWhere(0);
-            this.defaultMessageStore.destroyLogics();
+            this.defaultMessageStore.getQueueStore().destroy();
+            this.defaultMessageStore.getQueueStore().loadAfterDestroy();
         }
     }
 
@@ -626,8 +630,10 @@ public class CommitLog implements Swappable {
         return -1;
     }
 
-    @Deprecated
-    public void recoverAbnormally(long maxPhyOffsetOfConsumeQueue) {
+    /**
+     * @throws RocksDBException only in rocksdb mode
+     */
+    public void recoverAbnormally(long maxPhyOffsetOfConsumeQueue) throws RocksDBException {
         // recover by the minimum time stamp
         boolean checkCRCOnRecover = this.defaultMessageStore.getMessageStoreConfig().isCheckCRCOnRecover();
         boolean checkDupInfo = this.defaultMessageStore.getMessageStoreConfig().isDuplicationEnable();
@@ -705,6 +711,9 @@ public class CommitLog implements Swappable {
                 }
             }
 
+            // only for rocksdb mode
+            this.getMessageStore().finishCommitLogDispatch();
+
             processOffset += mappedFileOffset;
             if (this.defaultMessageStore.getBrokerConfig().isEnableControllerMode()) {
                 if (this.defaultMessageStore.getConfirmOffset() < this.defaultMessageStore.getMinPhyOffset()) {
@@ -717,22 +726,24 @@ public class CommitLog implements Swappable {
             } else {
                 this.setConfirmOffset(lastValidMsgPhyOffset);
             }
-            this.mappedFileQueue.setFlushedWhere(processOffset);
-            this.mappedFileQueue.setCommittedWhere(processOffset);
-            this.mappedFileQueue.truncateDirtyFiles(processOffset);
 
             // Clear ConsumeQueue redundant data
             if (maxPhyOffsetOfConsumeQueue >= processOffset) {
                 log.warn("maxPhyOffsetOfConsumeQueue({}) >= processOffset({}), truncate dirty logic files", maxPhyOffsetOfConsumeQueue, processOffset);
                 this.defaultMessageStore.truncateDirtyLogicFiles(processOffset);
             }
+
+            this.mappedFileQueue.setFlushedWhere(processOffset);
+            this.mappedFileQueue.setCommittedWhere(processOffset);
+            this.mappedFileQueue.truncateDirtyFiles(processOffset);
         }
         // Commitlog case files are deleted
         else {
             log.warn("The commitlog files are deleted, and delete the consume queue files");
             this.mappedFileQueue.setFlushedWhere(0);
             this.mappedFileQueue.setCommittedWhere(0);
-            this.defaultMessageStore.destroyLogics();
+            this.defaultMessageStore.getQueueStore().destroy();
+            this.defaultMessageStore.getQueueStore().loadAfterDestroy();
         }
     }
 
@@ -755,7 +766,7 @@ public class CommitLog implements Swappable {
         this.getMessageStore().onCommitLogAppend(msg, result, commitLogFile);
     }
 
-    private boolean isMappedFileMatchedRecover(final MappedFile mappedFile) {
+    private boolean isMappedFileMatchedRecover(final MappedFile mappedFile) throws RocksDBException {
         ByteBuffer byteBuffer = mappedFile.sliceByteBuffer();
 
         int magicCode = byteBuffer.getInt(MessageDecoder.MESSAGE_MAGIC_CODE_POSITION);
@@ -763,28 +774,37 @@ public class CommitLog implements Swappable {
             return false;
         }
 
-        int sysFlag = byteBuffer.getInt(MessageDecoder.SYSFLAG_POSITION);
-        int bornhostLength = (sysFlag & MessageSysFlag.BORNHOST_V6_FLAG) == 0 ? 8 : 20;
-        int msgStoreTimePos = 4 + 4 + 4 + 4 + 4 + 8 + 8 + 4 + 8 + bornhostLength;
-        long storeTimestamp = byteBuffer.getLong(msgStoreTimePos);
-        if (0 == storeTimestamp) {
-            return false;
-        }
-
-        if (this.defaultMessageStore.getMessageStoreConfig().isMessageIndexEnable()
-            && this.defaultMessageStore.getMessageStoreConfig().isMessageIndexSafe()) {
-            if (storeTimestamp <= this.defaultMessageStore.getStoreCheckpoint().getMinTimestampIndex()) {
-                log.info("find check timestamp, {} {}",
-                    storeTimestamp,
-                    UtilAll.timeMillisToHumanString(storeTimestamp));
+        if (this.defaultMessageStore.getMessageStoreConfig().isEnableRocksDBStore()) {
+            final long maxPhyOffsetInConsumeQueue = this.defaultMessageStore.getQueueStore().getMaxPhyOffsetInConsumeQueue();
+            long phyOffset = byteBuffer.getLong(MessageDecoder.MESSAGE_PHYSIC_OFFSET_POSITION);
+            if (phyOffset <= maxPhyOffsetInConsumeQueue) {
+                log.info("find check. beginPhyOffset: {}, maxPhyOffsetInConsumeQueue: {}", phyOffset, maxPhyOffsetInConsumeQueue);
                 return true;
             }
         } else {
-            if (storeTimestamp <= this.defaultMessageStore.getStoreCheckpoint().getMinTimestamp()) {
-                log.info("find check timestamp, {} {}",
-                    storeTimestamp,
-                    UtilAll.timeMillisToHumanString(storeTimestamp));
-                return true;
+            int sysFlag = byteBuffer.getInt(MessageDecoder.SYSFLAG_POSITION);
+            int bornHostLength = (sysFlag & MessageSysFlag.BORNHOST_V6_FLAG) == 0 ? 8 : 20;
+            int msgStoreTimePos = 4 + 4 + 4 + 4 + 4 + 8 + 8 + 4 + 8 + bornHostLength;
+            long storeTimestamp = byteBuffer.getLong(msgStoreTimePos);
+            if (0 == storeTimestamp) {
+                return false;
+            }
+
+            if (this.defaultMessageStore.getMessageStoreConfig().isMessageIndexEnable()
+                && this.defaultMessageStore.getMessageStoreConfig().isMessageIndexSafe()) {
+                if (storeTimestamp <= this.defaultMessageStore.getStoreCheckpoint().getMinTimestampIndex()) {
+                    log.info("find check timestamp, {} {}",
+                        storeTimestamp,
+                        UtilAll.timeMillisToHumanString(storeTimestamp));
+                    return true;
+                }
+            } else {
+                if (storeTimestamp <= this.defaultMessageStore.getStoreCheckpoint().getMinTimestamp()) {
+                    log.info("find check timestamp, {} {}",
+                        storeTimestamp,
+                        UtilAll.timeMillisToHumanString(storeTimestamp));
+                    return true;
+                }
             }
         }
 
@@ -958,8 +978,6 @@ public class CommitLog implements Swappable {
                         beginTimeInLock = 0;
                         return CompletableFuture.completedFuture(new PutMessageResult(PutMessageStatus.MESSAGE_ILLEGAL, result));
                     case UNKNOWN_ERROR:
-                        beginTimeInLock = 0;
-                        return CompletableFuture.completedFuture(new PutMessageResult(PutMessageStatus.UNKNOWN_ERROR, result));
                     default:
                         beginTimeInLock = 0;
                         return CompletableFuture.completedFuture(new PutMessageResult(PutMessageStatus.UNKNOWN_ERROR, result));
@@ -974,6 +992,8 @@ public class CommitLog implements Swappable {
             if (AppendMessageStatus.PUT_OK.equals(result.getStatus())) {
                 this.defaultMessageStore.increaseOffset(msg, getMessageNum(msg));
             }
+        } catch (RocksDBException e) {
+            return CompletableFuture.completedFuture(new PutMessageResult(PutMessageStatus.UNKNOWN_ERROR, result));
         } finally {
             topicQueueLock.unlock(topicQueueKey);
         }
@@ -997,7 +1017,7 @@ public class CommitLog implements Swappable {
 
     public CompletableFuture<PutMessageResult> asyncPutMessages(final MessageExtBatch messageExtBatch) {
         messageExtBatch.setStoreTimestamp(System.currentTimeMillis());
-        AppendMessageResult result;
+        AppendMessageResult result = null;
 
         StoreStatsService storeStatsService = this.defaultMessageStore.getStoreStatsService();
 
@@ -1133,7 +1153,9 @@ public class CommitLog implements Swappable {
             if (AppendMessageStatus.PUT_OK.equals(result.getStatus())) {
                 this.defaultMessageStore.increaseOffset(messageExtBatch, (short) putMessageContext.getBatchSize());
             }
-        } finally {
+        } catch (RocksDBException e) {
+            return CompletableFuture.completedFuture(new PutMessageResult(PutMessageStatus.UNKNOWN_ERROR, result));
+        }  finally {
             topicQueueLock.unlock(topicQueueKey);
         }
 
diff --git a/store/src/main/java/org/apache/rocketmq/store/CommitLogDispatcher.java b/store/src/main/java/org/apache/rocketmq/store/CommitLogDispatcher.java
index 9d6fa6ad9..f3a7b7c5c 100644
--- a/store/src/main/java/org/apache/rocketmq/store/CommitLogDispatcher.java
+++ b/store/src/main/java/org/apache/rocketmq/store/CommitLogDispatcher.java
@@ -17,6 +17,8 @@
 
 package org.apache.rocketmq.store;
 
+import org.rocksdb.RocksDBException;
+
 /**
  * Dispatcher of commit log.
  */
@@ -25,6 +27,7 @@ public interface CommitLogDispatcher {
     /**
      *  Dispatch messages from store to build consume queues, indexes, and filter data
      * @param request dispatch message request
+     * @throws RocksDBException only in rocksdb mode
      */
-    void dispatch(final DispatchRequest request);
+    void dispatch(final DispatchRequest request) throws RocksDBException;
 }
diff --git a/store/src/main/java/org/apache/rocketmq/store/ConsumeQueue.java b/store/src/main/java/org/apache/rocketmq/store/ConsumeQueue.java
index 56bee2af3..623509c8b 100644
--- a/store/src/main/java/org/apache/rocketmq/store/ConsumeQueue.java
+++ b/store/src/main/java/org/apache/rocketmq/store/ConsumeQueue.java
@@ -24,13 +24,12 @@ import java.util.Map;
 import org.apache.commons.lang3.StringUtils;
 import org.apache.rocketmq.common.BoundaryType;
 import org.apache.rocketmq.common.MixAll;
+import org.apache.rocketmq.common.Pair;
 import org.apache.rocketmq.common.attribute.CQType;
 import org.apache.rocketmq.common.constant.LoggerName;
 import org.apache.rocketmq.common.message.MessageAccessor;
 import org.apache.rocketmq.common.message.MessageConst;
-import org.apache.rocketmq.common.message.MessageDecoder;
 import org.apache.rocketmq.common.message.MessageExtBrokerInner;
-import org.apache.rocketmq.common.topic.TopicValidator;
 import org.apache.rocketmq.logging.org.slf4j.Logger;
 import org.apache.rocketmq.logging.org.slf4j.LoggerFactory;
 import org.apache.rocketmq.store.config.BrokerRole;
@@ -39,9 +38,9 @@ import org.apache.rocketmq.store.logfile.MappedFile;
 import org.apache.rocketmq.store.queue.ConsumeQueueInterface;
 import org.apache.rocketmq.store.queue.CqUnit;
 import org.apache.rocketmq.store.queue.FileQueueLifeCycle;
+import org.apache.rocketmq.store.queue.MultiDispatch;
 import org.apache.rocketmq.store.queue.QueueOffsetOperator;
 import org.apache.rocketmq.store.queue.ReferredIterator;
-import org.apache.rocketmq.store.timer.TimerMessageStore;
 
 public class ConsumeQueue implements ConsumeQueueInterface, FileQueueLifeCycle {
     private static final Logger log = LoggerFactory.getLogger(LoggerName.STORE_LOGGER_NAME);
@@ -703,7 +702,7 @@ public class ConsumeQueue implements ConsumeQueueInterface, FileQueueLifeCycle {
                     this.messageStore.getStoreCheckpoint().setPhysicMsgTimestamp(request.getStoreTimestamp());
                 }
                 this.messageStore.getStoreCheckpoint().setLogicsMsgTimestamp(request.getStoreTimestamp());
-                if (checkMultiDispatchQueue(request)) {
+                if (MultiDispatch.checkMultiDispatchQueue(this.messageStore.getMessageStoreConfig(), request)) {
                     multiDispatchLmqQueue(request, maxRetries);
                 }
                 return;
@@ -725,25 +724,6 @@ public class ConsumeQueue implements ConsumeQueueInterface, FileQueueLifeCycle {
         this.messageStore.getRunningFlags().makeLogicsQueueError();
     }
 
-    private boolean checkMultiDispatchQueue(DispatchRequest dispatchRequest) {
-        if (!this.messageStore.getMessageStoreConfig().isEnableMultiDispatch()
-            || dispatchRequest.getTopic().startsWith(MixAll.RETRY_GROUP_TOPIC_PREFIX)
-            || dispatchRequest.getTopic().equals(TimerMessageStore.TIMER_TOPIC)
-            || dispatchRequest.getTopic().equals(TopicValidator.RMQ_SYS_SCHEDULE_TOPIC)) {
-            return false;
-        }
-        Map<String, String> prop = dispatchRequest.getPropertiesMap();
-        if (prop == null || prop.isEmpty()) {
-            return false;
-        }
-        String multiDispatchQueue = prop.get(MessageConst.PROPERTY_INNER_MULTI_DISPATCH);
-        String multiQueueOffset = prop.get(MessageConst.PROPERTY_INNER_MULTI_QUEUE_OFFSET);
-        if (StringUtils.isBlank(multiDispatchQueue) || StringUtils.isBlank(multiQueueOffset)) {
-            return false;
-        }
-        return true;
-    }
-
     private void multiDispatchLmqQueue(DispatchRequest request, int maxRetries) {
         Map<String, String> prop = request.getPropertiesMap();
         String multiDispatchQueue = prop.get(MessageConst.PROPERTY_INNER_MULTI_DISPATCH);
@@ -765,9 +745,7 @@ public class ConsumeQueue implements ConsumeQueueInterface, FileQueueLifeCycle {
                 queueId = 0;
             }
             doDispatchLmqQueue(request, maxRetries, queueName, queueOffset, queueId);
-
         }
-        return;
     }
 
     private void doDispatchLmqQueue(DispatchRequest request, int maxRetries, String queueName, long queueOffset,
@@ -802,7 +780,7 @@ public class ConsumeQueue implements ConsumeQueueInterface, FileQueueLifeCycle {
 
         // Handling the multi dispatch message. In the context of a light message queue (as defined in RIP-28),
         // light message queues are constructed based on message properties, which requires special handling of queue offset of the light message queue.
-        if (!isNeedHandleMultiDispatch(msg)) {
+        if (!MultiDispatch.isNeedHandleMultiDispatch(this.messageStore.getMessageStoreConfig(), msg.getTopic())) {
             return;
         }
         String multiDispatchQueue = msg.getProperty(MessageConst.PROPERTY_INNER_MULTI_DISPATCH);
@@ -812,14 +790,14 @@ public class ConsumeQueue implements ConsumeQueueInterface, FileQueueLifeCycle {
         String[] queues = multiDispatchQueue.split(MixAll.MULTI_DISPATCH_QUEUE_SPLITTER);
         Long[] queueOffsets = new Long[queues.length];
         for (int i = 0; i < queues.length; i++) {
-            String key = queueKey(queues[i], msg);
-            if (messageStore.getMessageStoreConfig().isEnableLmq() && MixAll.isLmq(key)) {
+            if (this.messageStore.getMessageStoreConfig().isEnableLmq() && MixAll.isLmq(queues[i])) {
+                String key = MultiDispatch.lmqQueueKey(queues[i]);
                 queueOffsets[i] = queueOffsetOperator.getLmqOffset(key);
             }
         }
         MessageAccessor.putProperty(msg, MessageConst.PROPERTY_INNER_MULTI_QUEUE_OFFSET,
             StringUtils.join(queueOffsets, MixAll.MULTI_DISPATCH_QUEUE_SPLITTER));
-        removeWaitStorePropertyString(msg);
+        msg.removeWaitStorePropertyString();
     }
 
     @Override
@@ -830,7 +808,7 @@ public class ConsumeQueue implements ConsumeQueueInterface, FileQueueLifeCycle {
 
         // Handling the multi dispatch message. In the context of a light message queue (as defined in RIP-28),
         // light message queues are constructed based on message properties, which requires special handling of queue offset of the light message queue.
-        if (!isNeedHandleMultiDispatch(msg)) {
+        if (!MultiDispatch.isNeedHandleMultiDispatch(this.messageStore.getMessageStoreConfig(), msg.getTopic())) {
             return;
         }
         String multiDispatchQueue = msg.getProperty(MessageConst.PROPERTY_INNER_MULTI_DISPATCH);
@@ -839,45 +817,13 @@ public class ConsumeQueue implements ConsumeQueueInterface, FileQueueLifeCycle {
         }
         String[] queues = multiDispatchQueue.split(MixAll.MULTI_DISPATCH_QUEUE_SPLITTER);
         for (int i = 0; i < queues.length; i++) {
-            String key = queueKey(queues[i], msg);
-            if (messageStore.getMessageStoreConfig().isEnableLmq() && MixAll.isLmq(key)) {
+            if (this.messageStore.getMessageStoreConfig().isEnableLmq() && MixAll.isLmq(queues[i])) {
+                String key = MultiDispatch.lmqQueueKey(queues[i]);
                 queueOffsetOperator.increaseLmqOffset(key, (short) 1);
             }
         }
     }
 
-    public boolean isNeedHandleMultiDispatch(MessageExtBrokerInner msg) {
-        return messageStore.getMessageStoreConfig().isEnableMultiDispatch()
-            && !msg.getTopic().startsWith(MixAll.RETRY_GROUP_TOPIC_PREFIX)
-            && !msg.getTopic().equals(TimerMessageStore.TIMER_TOPIC)
-            && !msg.getTopic().equals(TopicValidator.RMQ_SYS_SCHEDULE_TOPIC);
-    }
-
-    public String queueKey(String queueName, MessageExtBrokerInner msgInner) {
-        StringBuilder keyBuilder = new StringBuilder();
-        keyBuilder.append(queueName);
-        keyBuilder.append('-');
-        int queueId = msgInner.getQueueId();
-        if (messageStore.getMessageStoreConfig().isEnableLmq() && MixAll.isLmq(queueName)) {
-            queueId = 0;
-        }
-        keyBuilder.append(queueId);
-        return keyBuilder.toString();
-    }
-
-    private void removeWaitStorePropertyString(MessageExtBrokerInner msgInner) {
-        if (msgInner.getProperties().containsKey(MessageConst.PROPERTY_WAIT_STORE_MSG_OK)) {
-            // There is no need to store "WAIT=true", remove it from propertiesString to save 9 bytes for each message.
-            // It works for most case. In some cases msgInner.setPropertiesString invoked later and replace it.
-            String waitStoreMsgOKValue = msgInner.getProperties().remove(MessageConst.PROPERTY_WAIT_STORE_MSG_OK);
-            msgInner.setPropertiesString(MessageDecoder.messageProperties2String(msgInner.getProperties()));
-            // Reput to properties, since msgInner.isWaitStoreMsgOK() will be invoked later
-            msgInner.getProperties().put(MessageConst.PROPERTY_WAIT_STORE_MSG_OK, waitStoreMsgOKValue);
-        } else {
-            msgInner.setPropertiesString(MessageDecoder.messageProperties2String(msgInner.getProperties()));
-        }
-    }
-
     private boolean putMessagePositionInfo(final long offset, final int size, final long tagsCode,
         final long cqOffset) {
 
@@ -965,6 +911,11 @@ public class ConsumeQueue implements ConsumeQueueInterface, FileQueueLifeCycle {
         return new ConsumeQueueIterator(sbr);
     }
 
+    @Override
+    public ReferredIterator<CqUnit> iterateFrom(long startIndex, int count) {
+        return iterateFrom(startIndex);
+    }
+
     @Override
     public CqUnit get(long offset) {
         ReferredIterator<CqUnit> it = iterateFrom(offset);
@@ -974,6 +925,20 @@ public class ConsumeQueue implements ConsumeQueueInterface, FileQueueLifeCycle {
         return it.nextAndRelease();
     }
 
+    @Override
+    public Pair<CqUnit, Long> getCqUnitAndStoreTime(long index) {
+        CqUnit cqUnit = get(index);
+        Long messageStoreTime = this.messageStore.getQueueStore().getStoreTime(cqUnit);
+        return new Pair<>(cqUnit, messageStoreTime);
+    }
+
+    @Override
+    public Pair<CqUnit, Long> getEarliestUnitAndStoreTime() {
+        CqUnit cqUnit = getEarliestUnit();
+        Long messageStoreTime = this.messageStore.getQueueStore().getStoreTime(cqUnit);
+        return new Pair<>(cqUnit, messageStoreTime);
+    }
+
     @Override
     public CqUnit getEarliestUnit() {
         /**
diff --git a/store/src/main/java/org/apache/rocketmq/store/DefaultMessageStore.java b/store/src/main/java/org/apache/rocketmq/store/DefaultMessageStore.java
index 02ea47f13..99a54e2d7 100644
--- a/store/src/main/java/org/apache/rocketmq/store/DefaultMessageStore.java
+++ b/store/src/main/java/org/apache/rocketmq/store/DefaultMessageStore.java
@@ -105,32 +105,35 @@ import org.apache.rocketmq.store.logfile.MappedFile;
 import org.apache.rocketmq.store.metrics.DefaultStoreMetricsManager;
 import org.apache.rocketmq.store.queue.ConsumeQueueInterface;
 import org.apache.rocketmq.store.queue.ConsumeQueueStore;
+import org.apache.rocketmq.store.queue.ConsumeQueueStoreInterface;
 import org.apache.rocketmq.store.queue.CqUnit;
 import org.apache.rocketmq.store.queue.ReferredIterator;
 import org.apache.rocketmq.store.stats.BrokerStatsManager;
 import org.apache.rocketmq.store.timer.TimerMessageStore;
 import org.apache.rocketmq.store.util.PerfCounter;
+import org.rocksdb.RocksDBException;
 
 public class DefaultMessageStore implements MessageStore {
-    private static final Logger LOGGER = LoggerFactory.getLogger(LoggerName.STORE_LOGGER_NAME);
+    protected static final Logger LOGGER = LoggerFactory.getLogger(LoggerName.STORE_LOGGER_NAME);
+    protected static final Logger ERROR_LOG = LoggerFactory.getLogger(LoggerName.STORE_ERROR_LOGGER_NAME);
 
     public final PerfCounter.Ticks perfs = new PerfCounter.Ticks(LOGGER);
 
     private final MessageStoreConfig messageStoreConfig;
     // CommitLog
-    private final CommitLog commitLog;
+    protected final CommitLog commitLog;
 
-    private final ConsumeQueueStore consumeQueueStore;
+    protected final ConsumeQueueStoreInterface consumeQueueStore;
 
     private final FlushConsumeQueueService flushConsumeQueueService;
 
-    private final CleanCommitLogService cleanCommitLogService;
+    protected final CleanCommitLogService cleanCommitLogService;
 
     private final CleanConsumeQueueService cleanConsumeQueueService;
 
     private final CorrectLogicOffsetService correctLogicOffsetService;
 
-    private final IndexService indexService;
+    protected final IndexService indexService;
 
     private final AllocateMappedFileService allocateMappedFileService;
 
@@ -147,7 +150,7 @@ public class DefaultMessageStore implements MessageStore {
 
     private final TransientStorePool transientStorePool;
 
-    private final RunningFlags runningFlags = new RunningFlags();
+    protected final RunningFlags runningFlags = new RunningFlags();
     private final SystemClock systemClock = new SystemClock();
 
     private final ScheduledExecutorService scheduledExecutorService;
@@ -156,6 +159,7 @@ public class DefaultMessageStore implements MessageStore {
     private final BrokerConfig brokerConfig;
 
     private volatile boolean shutdown = true;
+    protected boolean notifyMessageArriveInBatch = false;
 
     private StoreCheckpoint storeCheckpoint;
     private TimerMessageStore timerMessageStore;
@@ -182,7 +186,7 @@ public class DefaultMessageStore implements MessageStore {
 
     private volatile long brokerInitMaxOffset = -1L;
 
-    protected List<PutMessageHook> putMessageHookList = new ArrayList<>();
+    private List<PutMessageHook> putMessageHookList = new ArrayList<>();
 
     private SendMessageBackHook sendMessageBackHook;
 
@@ -222,12 +226,12 @@ public class DefaultMessageStore implements MessageStore {
             this.commitLog = new CommitLog(this);
         }
 
-        this.consumeQueueStore = new ConsumeQueueStore(this, this.messageStoreConfig);
+        this.consumeQueueStore = createConsumeQueueStore();
 
-        this.flushConsumeQueueService = new FlushConsumeQueueService();
+        this.flushConsumeQueueService = createFlushConsumeQueueService();
         this.cleanCommitLogService = new CleanCommitLogService();
-        this.cleanConsumeQueueService = new CleanConsumeQueueService();
-        this.correctLogicOffsetService = new CorrectLogicOffsetService();
+        this.cleanConsumeQueueService = createCleanConsumeQueueService();
+        this.correctLogicOffsetService = createCorrectLogicOffsetService();
         this.storeStatsService = new StoreStatsService(getBrokerIdentity());
         this.indexService = new IndexService(this);
 
@@ -273,6 +277,22 @@ public class DefaultMessageStore implements MessageStore {
         parseDelayLevel();
     }
 
+    public ConsumeQueueStoreInterface createConsumeQueueStore() {
+        return new ConsumeQueueStore(this);
+    }
+
+    public CleanConsumeQueueService createCleanConsumeQueueService() {
+        return new CleanConsumeQueueService();
+    }
+
+    public FlushConsumeQueueService createFlushConsumeQueueService() {
+        return new FlushConsumeQueueService();
+    }
+
+    public CorrectLogicOffsetService createCorrectLogicOffsetService() {
+        return new CorrectLogicOffsetService();
+    }
+
     public boolean parseDelayLevel() {
         HashMap<String, Long> timeUnitTable = new HashMap<>();
         timeUnitTable.put("s", 1000L);
@@ -305,7 +325,7 @@ public class DefaultMessageStore implements MessageStore {
     }
 
     @Override
-    public void truncateDirtyLogicFiles(long phyOffset) {
+    public void truncateDirtyLogicFiles(long phyOffset) throws RocksDBException {
         this.consumeQueueStore.truncateDirty(phyOffset);
     }
 
@@ -393,6 +413,7 @@ public class DefaultMessageStore implements MessageStore {
 
         this.flushConsumeQueueService.start();
         this.commitLog.start();
+        this.consumeQueueStore.start();
         this.storeStatsService.start();
 
         if (this.haService != null) {
@@ -481,6 +502,7 @@ public class DefaultMessageStore implements MessageStore {
             this.storeStatsService.shutdown();
             this.commitLog.shutdown();
             this.reputMessageService.shutdown();
+            this.consumeQueueStore.shutdown();
             // dispatch-related services must be shut down after reputMessageService
             this.indexService.shutdown();
             if (this.compactionService != null) {
@@ -515,7 +537,7 @@ public class DefaultMessageStore implements MessageStore {
 
     @Override
     public void destroy() {
-        this.destroyLogics();
+        this.consumeQueueStore.destroy();
         this.commitLog.destroy();
         this.indexService.destroy();
         this.deleteFile(StorePathConfigHelper.getAbortFile(this.messageStoreConfig.getStorePathRootDir()));
@@ -541,11 +563,6 @@ public class DefaultMessageStore implements MessageStore {
         return commitLogSize + consumeQueueSize + indexFileSize;
     }
 
-    @Override
-    public void destroyLogics() {
-        this.consumeQueueStore.destroy();
-    }
-
     @Override
     public CompletableFuture<PutMessageResult> asyncPutMessage(MessageExtBrokerInner msg) {
 
@@ -687,7 +704,7 @@ public class DefaultMessageStore implements MessageStore {
         return commitLog;
     }
 
-    public void truncateDirtyFiles(long offsetToTruncate) {
+    public void truncateDirtyFiles(long offsetToTruncate) throws RocksDBException {
 
         LOGGER.info("truncate dirty files to {}", offsetToTruncate);
 
@@ -700,12 +717,12 @@ public class DefaultMessageStore implements MessageStore {
 
         long oldReputFromOffset = this.reputMessageService.getReputFromOffset();
 
-        // truncate commitLog
-        this.commitLog.truncateDirtyFiles(offsetToTruncate);
-
         // truncate consume queue
         this.truncateDirtyLogicFiles(offsetToTruncate);
 
+        // truncate commitLog
+        this.commitLog.truncateDirtyFiles(offsetToTruncate);
+
         this.recoverTopicQueueTable();
 
         if (!messageStoreConfig.isEnableBuildConsumeQueueConcurrently()) {
@@ -723,7 +740,7 @@ public class DefaultMessageStore implements MessageStore {
     }
 
     @Override
-    public boolean truncateFiles(long offsetToTruncate) {
+    public boolean truncateFiles(long offsetToTruncate) throws RocksDBException {
         if (offsetToTruncate >= this.getMaxPhyOffset()) {
             LOGGER.info("no need to truncate files, truncate offset is {}, max physical offset is {}", offsetToTruncate, this.getMaxPhyOffset());
             return true;
@@ -825,17 +842,19 @@ public class DefaultMessageStore implements MessageStore {
                 while (getResult.getBufferTotalSize() <= 0
                     && nextBeginOffset < maxOffset
                     && cqFileNum++ < this.messageStoreConfig.getTravelCqFileNumWhenGetMessage()) {
-                    ReferredIterator<CqUnit> bufferConsumeQueue = consumeQueue.iterateFrom(nextBeginOffset);
-
-                    if (bufferConsumeQueue == null) {
-                        status = GetMessageStatus.OFFSET_FOUND_NULL;
-                        nextBeginOffset = nextOffsetCorrection(nextBeginOffset, this.consumeQueueStore.rollNextFile(consumeQueue, nextBeginOffset));
-                        LOGGER.warn("consumer request topic: " + topic + "offset: " + offset + " minOffset: " + minOffset + " maxOffset: "
-                            + maxOffset + ", but access logic queue failed. Correct nextBeginOffset to " + nextBeginOffset);
-                        break;
-                    }
+                    ReferredIterator<CqUnit> bufferConsumeQueue = null;
 
                     try {
+                        bufferConsumeQueue = consumeQueue.iterateFrom(nextBeginOffset, maxMsgNums);
+
+                        if (bufferConsumeQueue == null) {
+                            status = GetMessageStatus.OFFSET_FOUND_NULL;
+                            nextBeginOffset = nextOffsetCorrection(nextBeginOffset, this.consumeQueueStore.rollNextFile(consumeQueue, nextBeginOffset));
+                            LOGGER.warn("consumer request topic: " + topic + ", offset: " + offset + ", minOffset: " + minOffset + ", maxOffset: "
+                                + maxOffset + ", but access logic queue failed. Correct nextBeginOffset to " + nextBeginOffset);
+                            break;
+                        }
+
                         long nextPhyFileStartOffset = Long.MIN_VALUE;
                         while (bufferConsumeQueue.hasNext()
                             && nextBeginOffset < maxOffset) {
@@ -905,8 +924,13 @@ public class DefaultMessageStore implements MessageStore {
                             status = GetMessageStatus.FOUND;
                             nextPhyFileStartOffset = Long.MIN_VALUE;
                         }
+                    } catch (RocksDBException e) {
+                        ERROR_LOG.error("getMessage Failed. cid: {}, topic: {}, queueId: {}, offset: {}, minOffset: {}, maxOffset: {}, {}",
+                            group, topic, queueId, offset, minOffset, maxOffset, e.getMessage());
                     } finally {
-                        bufferConsumeQueue.release();
+                        if (bufferConsumeQueue != null) {
+                            bufferConsumeQueue.release();
+                        }
                     }
                 }
 
@@ -975,12 +999,12 @@ public class DefaultMessageStore implements MessageStore {
 
     @Override
     public long getMinOffsetInQueue(String topic, int queueId) {
-        ConsumeQueueInterface logic = this.findConsumeQueue(topic, queueId);
-        if (logic != null) {
-            return logic.getMinOffsetInQueue();
+        try {
+            return this.consumeQueueStore.getMinOffsetInQueue(topic, queueId);
+        } catch (RocksDBException e) {
+            ERROR_LOG.error("getMinOffsetInQueue Failed. topic: {}, queueId: {}", topic, queueId, e);
+            return -1;
         }
-
-        return -1;
     }
 
     @Override
@@ -997,38 +1021,27 @@ public class DefaultMessageStore implements MessageStore {
     public long getCommitLogOffsetInQueue(String topic, int queueId, long consumeQueueOffset) {
         ConsumeQueueInterface consumeQueue = findConsumeQueue(topic, queueId);
         if (consumeQueue != null) {
-
-            ReferredIterator<CqUnit> bufferConsumeQueue = consumeQueue.iterateFrom(consumeQueueOffset);
-            if (bufferConsumeQueue != null) {
-                try {
-                    if (bufferConsumeQueue.hasNext()) {
-                        long offsetPy = bufferConsumeQueue.next().getPos();
-                        return offsetPy;
-                    }
-                } finally {
-                    bufferConsumeQueue.release();
-                }
+            CqUnit cqUnit = consumeQueue.get(consumeQueueOffset);
+            if (cqUnit != null) {
+                return cqUnit.getPos();
             }
         }
-
         return 0;
     }
 
     @Override
     public long getOffsetInQueueByTime(String topic, int queueId, long timestamp) {
-        return getOffsetInQueueByTime(topic, queueId, timestamp, BoundaryType.LOWER);
+        return this.getOffsetInQueueByTime(topic, queueId, timestamp, BoundaryType.LOWER);
     }
 
+    @Override
     public long getOffsetInQueueByTime(String topic, int queueId, long timestamp, BoundaryType boundaryType) {
-        ConsumeQueueInterface logic = this.findConsumeQueue(topic, queueId);
-        if (logic != null) {
-            long resultOffset = logic.getOffsetInQueueByTime(timestamp, boundaryType);
-            // Make sure the result offset is in valid range.
-            resultOffset = Math.max(resultOffset, logic.getMinOffsetInQueue());
-            resultOffset = Math.min(resultOffset, logic.getMaxOffsetInQueue());
-            return resultOffset;
+        try {
+            return this.consumeQueueStore.getOffsetInQueueByTime(topic, queueId, timestamp, boundaryType);
+        } catch (RocksDBException e) {
+            ERROR_LOG.error("getOffsetInQueueByTime Failed. topic: {}, queueId: {}, timestamp: {} boundaryType: {}, {}",
+                topic, queueId, timestamp, boundaryType, e.getMessage());
         }
-
         return 0;
     }
 
@@ -1088,6 +1101,10 @@ public class DefaultMessageStore implements MessageStore {
         return StorePathConfigHelper.getStorePathConsumeQueue(this.messageStoreConfig.getStorePathRootDir());
     }
 
+    public MessageArrivingListener getMessageArrivingListener() {
+        return messageArrivingListener;
+    }
+
     @Override
     public HashMap<String, String> getRuntimeInfo() {
         HashMap<String, String> result = this.storeStatsService.getRuntimeInfo();
@@ -1121,7 +1138,6 @@ public class DefaultMessageStore implements MessageStore {
         return this.commitLog.getMaxOffset();
     }
 
-
     @Override
     public long getMinPhyOffset() {
         return this.commitLog.getMinOffset();
@@ -1141,7 +1157,10 @@ public class DefaultMessageStore implements MessageStore {
     public long getEarliestMessageTime(String topic, int queueId) {
         ConsumeQueueInterface logicQueue = this.findConsumeQueue(topic, queueId);
         if (logicQueue != null) {
-            return getStoreTime(logicQueue.getEarliestUnit());
+            Pair<CqUnit, Long> pair = logicQueue.getEarliestUnitAndStoreTime();
+            if (pair != null && pair.getObject2() != null) {
+                return pair.getObject2();
+            }
         }
 
         return -1;
@@ -1152,19 +1171,6 @@ public class DefaultMessageStore implements MessageStore {
         return CompletableFuture.completedFuture(getEarliestMessageTime(topic, queueId));
     }
 
-    protected long getStoreTime(CqUnit result) {
-        if (result != null) {
-            try {
-                final long phyOffset = result.getPos();
-                final int size = result.getSize();
-                long storeTime = this.getCommitLog().pickupStoreTimestamp(phyOffset, size);
-                return storeTime;
-            } catch (Exception e) {
-            }
-        }
-        return -1;
-    }
-
     @Override
     public long getEarliestMessageTime() {
         long minPhyOffset = this.getMinPhyOffset();
@@ -1179,13 +1185,16 @@ public class DefaultMessageStore implements MessageStore {
     public long getMessageStoreTimeStamp(String topic, int queueId, long consumeQueueOffset) {
         ConsumeQueueInterface logicQueue = this.findConsumeQueue(topic, queueId);
         if (logicQueue != null) {
-            return getStoreTime(logicQueue.get(consumeQueueOffset));
+            Pair<CqUnit, Long> pair = logicQueue.getCqUnitAndStoreTime(consumeQueueOffset);
+            if (pair != null && pair.getObject2() != null) {
+                return pair.getObject2();
+            }
         }
-
         return -1;
     }
 
-    @Override public CompletableFuture<Long> getMessageStoreTimeStampAsync(String topic, int queueId,
+    @Override
+    public CompletableFuture<Long> getMessageStoreTimeStampAsync(String topic, int queueId,
         long consumeQueueOffset) {
         return CompletableFuture.completedFuture(getMessageStoreTimeStamp(topic, queueId, consumeQueueOffset));
     }
@@ -1354,6 +1363,7 @@ public class DefaultMessageStore implements MessageStore {
      * If offset table is cleaned, and old messages are dispatching after the old consume queue is cleaned,
      * consume queue will be created with old offset, then later message with new offset table can not be
      * dispatched to consume queue.
+     * @throws RocksDBException only in rocksdb mode
      */
     @Override
     public int deleteTopics(final Set<String> deleteTopics) {
@@ -1363,17 +1373,19 @@ public class DefaultMessageStore implements MessageStore {
 
         int deleteCount = 0;
         for (String topic : deleteTopics) {
-            ConcurrentMap<Integer, ConsumeQueueInterface> queueTable =
-                this.consumeQueueStore.getConsumeQueueTable().get(topic);
+            ConcurrentMap<Integer, ConsumeQueueInterface> queueTable = this.consumeQueueStore.findConsumeQueueMap(topic);
 
             if (queueTable == null || queueTable.isEmpty()) {
                 continue;
             }
 
             for (ConsumeQueueInterface cq : queueTable.values()) {
-                this.consumeQueueStore.destroy(cq);
-                LOGGER.info("DeleteTopic: ConsumeQueue has been cleaned, topic={}, queueId={}",
-                    cq.getTopic(), cq.getQueueId());
+                try {
+                    this.consumeQueueStore.destroy(cq);
+                } catch (RocksDBException e) {
+                    LOGGER.error("DeleteTopic: ConsumeQueue cleans error!, topic={}, queueId={}", cq.getTopic(), cq.getQueueId(), e);
+                }
+                LOGGER.info("DeleteTopic: ConsumeQueue has been cleaned, topic={}, queueId={}", cq.getTopic(), cq.getQueueId());
                 this.consumeQueueStore.removeTopicQueueTable(cq.getTopic(), cq.getQueueId());
             }
 
@@ -1852,14 +1864,18 @@ public class DefaultMessageStore implements MessageStore {
         return file.exists();
     }
 
-    private void recover(final boolean lastExitOK) {
-        boolean recoverConcurrently = this.brokerConfig.isRecoverConcurrently();
+    private boolean isRecoverConcurrently() {
+        return this.brokerConfig.isRecoverConcurrently() && !this.messageStoreConfig.isEnableRocksDBStore();
+    }
+
+    private void recover(final boolean lastExitOK) throws RocksDBException {
+        boolean recoverConcurrently = this.isRecoverConcurrently();
         LOGGER.info("message store recover mode: {}", recoverConcurrently ? "concurrent" : "normal");
 
         // recover consume queue
         long recoverConsumeQueueStart = System.currentTimeMillis();
         this.recoverConsumeQueue();
-        long maxPhyOffsetOfConsumeQueue = this.getMaxOffsetInConsumeQueue();
+        long maxPhyOffsetOfConsumeQueue = this.consumeQueueStore.getMaxPhyOffsetInConsumeQueue();
         long recoverConsumeQueueEnd = System.currentTimeMillis();
 
         // recover commitlog
@@ -1894,23 +1910,25 @@ public class DefaultMessageStore implements MessageStore {
         return messageStoreConfig;
     }
 
+    @Override
+    public void finishCommitLogDispatch() {
+        // ignore
+    }
+
     @Override
     public TransientStorePool getTransientStorePool() {
         return transientStorePool;
     }
 
     private void recoverConsumeQueue() {
-        if (!this.brokerConfig.isRecoverConcurrently()) {
+        if (!this.isRecoverConcurrently()) {
             this.consumeQueueStore.recover();
         } else {
             this.consumeQueueStore.recoverConcurrently();
         }
     }
 
-    private long getMaxOffsetInConsumeQueue() {
-        return this.consumeQueueStore.getMaxOffsetInConsumeQueue();
-    }
-
+    @Override
     public void recoverTopicQueueTable() {
         long minPhyOffset = this.commitLog.getMinOffset();
         this.consumeQueueStore.recoverOffsetTable(minPhyOffset);
@@ -1949,13 +1967,17 @@ public class DefaultMessageStore implements MessageStore {
         return runningFlags;
     }
 
-    public void doDispatch(DispatchRequest req) {
+    public void doDispatch(DispatchRequest req) throws RocksDBException {
         for (CommitLogDispatcher dispatcher : this.dispatcherList) {
             dispatcher.dispatch(req);
         }
     }
 
-    public void putMessagePositionInfo(DispatchRequest dispatchRequest) {
+    /**
+     * @param dispatchRequest
+     * @throws RocksDBException only in rocksdb mode
+     */
+    protected void putMessagePositionInfo(DispatchRequest dispatchRequest) throws RocksDBException {
         this.consumeQueueStore.putMessagePositionInfoWrapper(dispatchRequest);
     }
 
@@ -2054,7 +2076,7 @@ public class DefaultMessageStore implements MessageStore {
     }
 
     @Override
-    public ConsumeQueueStore getQueueStore() {
+    public ConsumeQueueStoreInterface getQueueStore() {
         return consumeQueueStore;
     }
 
@@ -2065,7 +2087,7 @@ public class DefaultMessageStore implements MessageStore {
 
     @Override
     public void onCommitLogDispatch(DispatchRequest dispatchRequest, boolean doDispatch, MappedFile commitLogFile,
-        boolean isRecover, boolean isFileEnd) {
+        boolean isRecover, boolean isFileEnd) throws RocksDBException {
         if (doDispatch && !isFileEnd) {
             this.doDispatch(dispatchRequest);
         }
@@ -2082,7 +2104,7 @@ public class DefaultMessageStore implements MessageStore {
     }
 
     @Override
-    public void assignOffset(MessageExtBrokerInner msg) {
+    public void assignOffset(MessageExtBrokerInner msg) throws RocksDBException {
         final int tranType = MessageSysFlag.getTransactionValue(msg.getSysFlag());
 
         if (tranType == MessageSysFlag.TRANSACTION_NOT_TYPE || tranType == MessageSysFlag.TRANSACTION_COMMIT_TYPE) {
@@ -2127,12 +2149,12 @@ public class DefaultMessageStore implements MessageStore {
     class CommitLogDispatcherBuildConsumeQueue implements CommitLogDispatcher {
 
         @Override
-        public void dispatch(DispatchRequest request) {
+        public void dispatch(DispatchRequest request) throws RocksDBException {
             final int tranType = MessageSysFlag.getTransactionValue(request.getSysFlag());
             switch (tranType) {
                 case MessageSysFlag.TRANSACTION_NOT_TYPE:
                 case MessageSysFlag.TRANSACTION_COMMIT_TYPE:
-                    DefaultMessageStore.this.putMessagePositionInfo(request);
+                    putMessagePositionInfo(request);
                     break;
                 case MessageSysFlag.TRANSACTION_PREPARED_TYPE:
                 case MessageSysFlag.TRANSACTION_ROLLBACK_TYPE:
@@ -2278,7 +2300,7 @@ public class DefaultMessageStore implements MessageStore {
             return DefaultMessageStore.this.brokerConfig.getIdentifier() + CleanCommitLogService.class.getSimpleName();
         }
 
-        private boolean isTimeToDelete() {
+        protected boolean isTimeToDelete() {
             String when = DefaultMessageStore.this.getMessageStoreConfig().getDeleteWhen();
             if (UtilAll.isItTimeToDo(when)) {
                 DefaultMessageStore.LOGGER.info("it's time to reclaim disk space, " + when);
@@ -2436,7 +2458,7 @@ public class DefaultMessageStore implements MessageStore {
     }
 
     class CleanConsumeQueueService {
-        private long lastPhysicalMinOffset = 0;
+        protected long lastPhysicalMinOffset = 0;
 
         public void run() {
             try {
@@ -2446,7 +2468,7 @@ public class DefaultMessageStore implements MessageStore {
             }
         }
 
-        private void deleteExpiredFiles() {
+        protected void deleteExpiredFiles() {
             int deleteLogicsFilesInterval = DefaultMessageStore.this.getMessageStoreConfig().getDeleteConsumeQueueFilesInterval();
 
             long minOffset = DefaultMessageStore.this.commitLog.getMinOffset();
@@ -2551,7 +2573,7 @@ public class DefaultMessageStore implements MessageStore {
 
                 if (cqUnit.getPos() >= minPhyOffset) {
 
-                    // Normal case, do not need correct.
+                    // Normal case, do not need to correct.
                     return false;
                 }
             }
@@ -2741,6 +2763,18 @@ public class DefaultMessageStore implements MessageStore {
 
     }
 
+    @Override
+    public void notifyMessageArriveIfNecessary(DispatchRequest dispatchRequest) {
+        if (DefaultMessageStore.this.brokerConfig.isLongPollingEnable()
+            && DefaultMessageStore.this.messageArrivingListener != null) {
+            DefaultMessageStore.this.messageArrivingListener.arriving(dispatchRequest.getTopic(),
+                dispatchRequest.getQueueId(), dispatchRequest.getConsumeQueueOffset() + 1,
+                dispatchRequest.getTagsCode(), dispatchRequest.getStoreTimestamp(),
+                dispatchRequest.getBitMap(), dispatchRequest.getPropertiesMap());
+            DefaultMessageStore.this.reputMessageService.notifyMessageArrive4MultiQueue(dispatchRequest);
+        }
+    }
+
     class ReputMessageService extends ServiceThread {
 
         protected volatile long reputFromOffset = 0;
@@ -2810,13 +2844,8 @@ public class DefaultMessageStore implements MessageStore {
                             if (size > 0) {
                                 DefaultMessageStore.this.doDispatch(dispatchRequest);
 
-                                if (DefaultMessageStore.this.brokerConfig.isLongPollingEnable()
-                                    && DefaultMessageStore.this.messageArrivingListener != null) {
-                                    DefaultMessageStore.this.messageArrivingListener.arriving(dispatchRequest.getTopic(),
-                                        dispatchRequest.getQueueId(), dispatchRequest.getConsumeQueueOffset() + 1,
-                                        dispatchRequest.getTagsCode(), dispatchRequest.getStoreTimestamp(),
-                                        dispatchRequest.getBitMap(), dispatchRequest.getPropertiesMap());
-                                    notifyMessageArrive4MultiQueue(dispatchRequest);
+                                if (!notifyMessageArriveInBatch) {
+                                    notifyMessageArriveIfNecessary(dispatchRequest);
                                 }
 
                                 this.reputFromOffset += size;
@@ -2850,9 +2879,14 @@ public class DefaultMessageStore implements MessageStore {
                             }
                         }
                     }
+                } catch (RocksDBException e) {
+                    ERROR_LOG.info("dispatch message to cq exception. reputFromOffset: {}", this.reputFromOffset, e);
+                    return;
                 } finally {
                     result.release();
                 }
+
+                finishCommitLogDispatch();
             }
         }
 
@@ -2989,7 +3023,7 @@ public class DefaultMessageStore implements MessageStore {
         // dispatchRequestsList:[
         //      {dispatchRequests:[{dispatchRequest}, {dispatchRequest}]},
         //      {dispatchRequests:[{dispatchRequest}, {dispatchRequest}]}]
-        private void dispatch() {
+        private void dispatch() throws Exception {
             dispatchRequestsList.clear();
             dispatchRequestOrderlyQueue.get(dispatchRequestsList);
             if (!dispatchRequestsList.isEmpty()) {
@@ -2997,21 +3031,15 @@ public class DefaultMessageStore implements MessageStore {
                     for (DispatchRequest dispatchRequest : dispatchRequests) {
                         DefaultMessageStore.this.doDispatch(dispatchRequest);
                         // wake up long-polling
-                        if (DefaultMessageStore.this.brokerConfig.isLongPollingEnable()
-                                && DefaultMessageStore.this.messageArrivingListener != null) {
-                            DefaultMessageStore.this.messageArrivingListener.arriving(dispatchRequest.getTopic(),
-                                    dispatchRequest.getQueueId(), dispatchRequest.getConsumeQueueOffset() + 1,
-                                    dispatchRequest.getTagsCode(), dispatchRequest.getStoreTimestamp(),
-                                    dispatchRequest.getBitMap(), dispatchRequest.getPropertiesMap());
-                            DefaultMessageStore.this.reputMessageService.notifyMessageArrive4MultiQueue(dispatchRequest);
-                        }
+                        DefaultMessageStore.this.notifyMessageArriveIfNecessary(dispatchRequest);
+
                         if (!DefaultMessageStore.this.getMessageStoreConfig().isDuplicationEnable() &&
-                                DefaultMessageStore.this.getMessageStoreConfig().getBrokerRole() == BrokerRole.SLAVE) {
+                            DefaultMessageStore.this.getMessageStoreConfig().getBrokerRole() == BrokerRole.SLAVE) {
                             DefaultMessageStore.this.storeStatsService
-                                    .getSinglePutMessageTopicTimesTotal(dispatchRequest.getTopic()).add(1);
+                                .getSinglePutMessageTopicTimesTotal(dispatchRequest.getTopic()).add(1);
                             DefaultMessageStore.this.storeStatsService
-                                    .getSinglePutMessageTopicSizeTotal(dispatchRequest.getTopic())
-                                    .add(dispatchRequest.getMsgSize());
+                                .getSinglePutMessageTopicSizeTotal(dispatchRequest.getTopic())
+                                .add(dispatchRequest.getMsgSize());
                         }
                     }
                 }
@@ -3079,7 +3107,7 @@ public class DefaultMessageStore implements MessageStore {
         public void doReput() {
             if (this.reputFromOffset < DefaultMessageStore.this.commitLog.getMinOffset()) {
                 LOGGER.warn("The reputFromOffset={} is smaller than minPyOffset={}, this usually indicate that the dispatch behind too much and the commitlog has expired.",
-                        this.reputFromOffset, DefaultMessageStore.this.commitLog.getMinOffset());
+                    this.reputFromOffset, DefaultMessageStore.this.commitLog.getMinOffset());
                 this.reputFromOffset = DefaultMessageStore.this.commitLog.getMinOffset();
             }
             for (boolean doNext = true; this.isCommitLogAvailable() && doNext; ) {
@@ -3138,6 +3166,9 @@ public class DefaultMessageStore implements MessageStore {
                     result.release();
                 }
             }
+
+            // only for rocksdb mode
+            finishCommitLogDispatch();
         }
 
         /**
@@ -3180,8 +3211,8 @@ public class DefaultMessageStore implements MessageStore {
 
             if (this.isCommitLogAvailable()) {
                 LOGGER.warn("shutdown concurrentReputMessageService, but CommitLog have not finish to be dispatched, CommitLog max" +
-                                " offset={}, reputFromOffset={}", DefaultMessageStore.this.commitLog.getMaxOffset(),
-                        this.reputFromOffset);
+                        " offset={}, reputFromOffset={}", DefaultMessageStore.this.commitLog.getMaxOffset(),
+                    this.reputFromOffset);
             }
 
             this.mainBatchDispatchRequestService.shutdown();
diff --git a/store/src/main/java/org/apache/rocketmq/store/MessageStore.java b/store/src/main/java/org/apache/rocketmq/store/MessageStore.java
index 989cbbe31..814c6d1bf 100644
--- a/store/src/main/java/org/apache/rocketmq/store/MessageStore.java
+++ b/store/src/main/java/org/apache/rocketmq/store/MessageStore.java
@@ -16,10 +16,6 @@
  */
 package org.apache.rocketmq.store;
 
-import io.opentelemetry.api.common.AttributesBuilder;
-import io.opentelemetry.api.metrics.Meter;
-import io.opentelemetry.sdk.metrics.InstrumentSelector;
-import io.opentelemetry.sdk.metrics.ViewBuilder;
 import java.nio.ByteBuffer;
 import java.util.HashMap;
 import java.util.LinkedList;
@@ -40,10 +36,15 @@ import org.apache.rocketmq.store.hook.PutMessageHook;
 import org.apache.rocketmq.store.hook.SendMessageBackHook;
 import org.apache.rocketmq.store.logfile.MappedFile;
 import org.apache.rocketmq.store.queue.ConsumeQueueInterface;
-import org.apache.rocketmq.store.queue.ConsumeQueueStore;
+import org.apache.rocketmq.store.queue.ConsumeQueueStoreInterface;
 import org.apache.rocketmq.store.stats.BrokerStatsManager;
 import org.apache.rocketmq.store.timer.TimerMessageStore;
 import org.apache.rocketmq.store.util.PerfCounter;
+import org.rocksdb.RocksDBException;
+import io.opentelemetry.api.common.AttributesBuilder;
+import io.opentelemetry.api.metrics.Meter;
+import io.opentelemetry.sdk.metrics.InstrumentSelector;
+import io.opentelemetry.sdk.metrics.ViewBuilder;
 
 /**
  * This class defines contracting interfaces to implement, allowing third-party vendor to use customized message store.
@@ -545,7 +546,7 @@ public interface MessageStore {
     void setConfirmOffset(long phyOffset);
 
     /**
-     * Check if the operation system page cache is busy or not.
+     * Check if the operating system page cache is busy or not.
      *
      * @return true if the OS page cache is busy; false otherwise.
      */
@@ -620,9 +621,18 @@ public interface MessageStore {
      * @param commitLogFile   commit log file
      * @param isRecover       is from recover process
      * @param isFileEnd       if the dispatch request represents 'file end'
+     * @throws RocksDBException      only in rocksdb mode
      */
     void onCommitLogDispatch(DispatchRequest dispatchRequest, boolean doDispatch, MappedFile commitLogFile,
-        boolean isRecover, boolean isFileEnd);
+        boolean isRecover, boolean isFileEnd) throws RocksDBException;
+
+    /**
+     * Only used in rocksdb mode, because we build consumeQueue in batch(default 16 dispatchRequests)
+     * It will be triggered in two cases:
+     * @see org.apache.rocketmq.store.DefaultMessageStore.ReputMessageService#doReput
+     * @see CommitLog#recoverAbnormally
+     */
+    void finishCommitLogDispatch();
 
     /**
      * Get the message store config
@@ -691,13 +701,9 @@ public interface MessageStore {
      * Truncate dirty logic files
      *
      * @param phyOffset physical offset
+     * @throws RocksDBException only in rocksdb mode
      */
-    void truncateDirtyLogicFiles(long phyOffset);
-
-    /**
-     * Destroy logics files
-     */
-    void destroyLogics();
+    void truncateDirtyLogicFiles(long phyOffset) throws RocksDBException;
 
     /**
      * Unlock mappedFile
@@ -718,7 +724,7 @@ public interface MessageStore {
      *
      * @return the queue store
      */
-    ConsumeQueueStore getQueueStore();
+    ConsumeQueueStoreInterface getQueueStore();
 
     /**
      * If 'sync disk flush' is configured in this message store
@@ -739,8 +745,9 @@ public interface MessageStore {
      * yourself.
      *
      * @param msg        message
+     * @throws RocksDBException
      */
-    void assignOffset(MessageExtBrokerInner msg);
+    void assignOffset(MessageExtBrokerInner msg) throws RocksDBException;
 
     /**
      * Increase queue offset in memory table. If there is a race condition, you need to lock/unlock this method
@@ -835,14 +842,15 @@ public interface MessageStore {
      *
      * @param offsetToTruncate offset to truncate
      * @return true if truncate succeed, false otherwise
+     * @throws RocksDBException only in rocksdb mode
      */
-    boolean truncateFiles(long offsetToTruncate);
+    boolean truncateFiles(long offsetToTruncate) throws RocksDBException;
 
     /**
-     * Check if the offset is align with one message.
+     * Check if the offset is aligned with one message.
      *
      * @param offset offset to check
-     * @return true if align, false otherwise
+     * @return true if aligned, false otherwise
      */
     boolean isOffsetAligned(long offset);
 
@@ -971,4 +979,14 @@ public interface MessageStore {
      * @param attributesBuilderSupplier metrics attributes builder
      */
     void initMetrics(Meter meter, Supplier<AttributesBuilder> attributesBuilderSupplier);
+
+    /**
+     * Recover topic queue table
+     */
+    void recoverTopicQueueTable();
+
+    /**
+     * notify message arrive if necessary
+     */
+    void notifyMessageArriveIfNecessary(DispatchRequest dispatchRequest);
 }
diff --git a/store/src/main/java/org/apache/rocketmq/store/RocksDBMessageStore.java b/store/src/main/java/org/apache/rocketmq/store/RocksDBMessageStore.java
new file mode 100644
index 000000000..87ccb5474
--- /dev/null
+++ b/store/src/main/java/org/apache/rocketmq/store/RocksDBMessageStore.java
@@ -0,0 +1,169 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.rocketmq.store;
+
+import java.io.IOException;
+import java.util.concurrent.ConcurrentHashMap;
+import java.util.concurrent.ConcurrentMap;
+
+import org.apache.rocketmq.common.BrokerConfig;
+import org.apache.rocketmq.common.TopicConfig;
+import org.apache.rocketmq.common.UtilAll;
+import org.apache.rocketmq.store.config.MessageStoreConfig;
+import org.apache.rocketmq.store.config.StorePathConfigHelper;
+import org.apache.rocketmq.store.queue.ConsumeQueueInterface;
+import org.apache.rocketmq.store.queue.ConsumeQueueStoreInterface;
+import org.apache.rocketmq.store.queue.RocksDBConsumeQueue;
+import org.apache.rocketmq.store.queue.RocksDBConsumeQueueStore;
+import org.apache.rocketmq.store.stats.BrokerStatsManager;
+import org.rocksdb.RocksDBException;
+
+public class RocksDBMessageStore extends DefaultMessageStore {
+
+    public RocksDBMessageStore(final MessageStoreConfig messageStoreConfig, final BrokerStatsManager brokerStatsManager,
+        final MessageArrivingListener messageArrivingListener, final BrokerConfig brokerConfig, final ConcurrentMap<String, TopicConfig> topicConfigTable) throws
+        IOException {
+        super(messageStoreConfig, brokerStatsManager, messageArrivingListener, brokerConfig, topicConfigTable);
+        notifyMessageArriveInBatch = true;
+    }
+
+    @Override
+    public ConsumeQueueStoreInterface createConsumeQueueStore() {
+        return new RocksDBConsumeQueueStore(this);
+    }
+
+    @Override
+    public CleanConsumeQueueService createCleanConsumeQueueService() {
+        return new RocksDBCleanConsumeQueueService();
+    }
+
+    @Override
+    public FlushConsumeQueueService createFlushConsumeQueueService() {
+        return new RocksDBFlushConsumeQueueService();
+    }
+
+    @Override
+    public CorrectLogicOffsetService createCorrectLogicOffsetService() {
+        return new RocksDBCorrectLogicOffsetService();
+    }
+
+    /**
+     * Try to set topicQueueTable = new HashMap<>(), otherwise it will cause bug when broker role changes.
+     * And unlike method in DefaultMessageStore, we don't need to really recover topic queue table advance,
+     * because we can recover topic queue table from rocksdb when we need to use it.
+     * @see RocksDBConsumeQueue#assignQueueOffset
+     */
+    @Override
+    public void recoverTopicQueueTable() {
+        this.consumeQueueStore.setTopicQueueTable(new ConcurrentHashMap<>());
+    }
+
+    @Override
+    public void finishCommitLogDispatch() {
+        try {
+            putMessagePositionInfo(null);
+        } catch (RocksDBException e) {
+            ERROR_LOG.info("try to finish commitlog dispatch error.", e);
+        }
+    }
+
+    @Override
+    public ConsumeQueueInterface getConsumeQueue(String topic, int queueId) {
+        return findConsumeQueue(topic, queueId);
+    }
+
+    class RocksDBCleanConsumeQueueService extends CleanConsumeQueueService {
+        private final double diskSpaceWarningLevelRatio =
+            Double.parseDouble(System.getProperty("rocketmq.broker.diskSpaceWarningLevelRatio", "0.90"));
+
+        private final double diskSpaceCleanForciblyRatio =
+            Double.parseDouble(System.getProperty("rocketmq.broker.diskSpaceCleanForciblyRatio", "0.85"));
+
+        @Override
+        protected void deleteExpiredFiles() {
+
+            long minOffset = RocksDBMessageStore.this.commitLog.getMinOffset();
+            if (minOffset > this.lastPhysicalMinOffset) {
+                this.lastPhysicalMinOffset = minOffset;
+
+                boolean spaceFull = isSpaceToDelete();
+                boolean timeUp = cleanCommitLogService.isTimeToDelete();
+                if (spaceFull || timeUp) {
+                    RocksDBMessageStore.this.consumeQueueStore.cleanExpired(minOffset);
+                }
+
+                RocksDBMessageStore.this.indexService.deleteExpiredFile(minOffset);
+            }
+        }
+
+        private boolean isSpaceToDelete() {
+            double ratio = RocksDBMessageStore.this.getMessageStoreConfig().getDiskMaxUsedSpaceRatio() / 100.0;
+
+            String storePathLogics = StorePathConfigHelper
+                .getStorePathConsumeQueue(RocksDBMessageStore.this.getMessageStoreConfig().getStorePathRootDir());
+            double logicsRatio = UtilAll.getDiskPartitionSpaceUsedPercent(storePathLogics);
+            if (logicsRatio > diskSpaceWarningLevelRatio) {
+                boolean diskOk = RocksDBMessageStore.this.runningFlags.getAndMakeLogicDiskFull();
+                if (diskOk) {
+                    RocksDBMessageStore.LOGGER.error("logics disk maybe full soon " + logicsRatio + ", so mark disk full");
+                }
+            } else if (logicsRatio > diskSpaceCleanForciblyRatio) {
+            } else {
+                boolean diskOk = RocksDBMessageStore.this.runningFlags.getAndMakeLogicDiskOK();
+                if (!diskOk) {
+                    RocksDBMessageStore.LOGGER.info("logics disk space OK " + logicsRatio + ", so mark disk ok");
+                }
+            }
+
+            if (logicsRatio < 0 || logicsRatio > ratio) {
+                RocksDBMessageStore.LOGGER.info("logics disk maybe full soon, so reclaim space, " + logicsRatio);
+                return true;
+            }
+
+            return false;
+        }
+    }
+
+    class RocksDBFlushConsumeQueueService extends FlushConsumeQueueService {
+        /**
+         * There is no need to flush consume queue,
+         * we put all consume queues in RocksDBConsumeQueueStore,
+         * it depends on rocksdb to flush consume queue to disk(sorted string table),
+         * we even don't flush WAL of consume store, since we think it can recover consume queue from commitlog.
+         */
+        @Override
+        public void run() {
+
+        }
+    }
+
+    class RocksDBCorrectLogicOffsetService extends CorrectLogicOffsetService {
+        /**
+         * There is no need to correct min offset of consume queue, we already fix this problem.
+         *  @see org.apache.rocketmq.store.queue.RocksDBConsumeQueueOffsetTable#getMinCqOffset
+         */
+        public void run() {
+
+        }
+    }
+
+    @Override
+    public long estimateMessageCount(String topic, int queueId, long from, long to, MessageFilter filter) {
+        // todo
+        return 0;
+    }
+}
diff --git a/store/src/main/java/org/apache/rocketmq/store/RunningFlags.java b/store/src/main/java/org/apache/rocketmq/store/RunningFlags.java
index 2ae6879aa..91fcb155a 100644
--- a/store/src/main/java/org/apache/rocketmq/store/RunningFlags.java
+++ b/store/src/main/java/org/apache/rocketmq/store/RunningFlags.java
@@ -30,6 +30,8 @@ public class RunningFlags {
 
     private static final int FENCED_BIT = 1 << 5;
 
+    private static final int LOGIC_DISK_FULL_BIT = 1 << 5;
+
     private volatile int flagBits = 0;
 
     public RunningFlags() {
@@ -63,6 +65,10 @@ public class RunningFlags {
         return result;
     }
 
+    public void clearLogicsQueueError() {
+        this.flagBits &= ~WRITE_LOGICS_QUEUE_ERROR_BIT;
+    }
+
     public boolean getAndMakeWriteable() {
         boolean result = this.isWriteable();
         if (!result) {
@@ -72,7 +78,7 @@ public class RunningFlags {
     }
 
     public boolean isWriteable() {
-        if ((this.flagBits & (NOT_WRITEABLE_BIT | WRITE_LOGICS_QUEUE_ERROR_BIT | DISK_FULL_BIT | WRITE_INDEX_FILE_ERROR_BIT | FENCED_BIT)) == 0) {
+        if ((this.flagBits & (NOT_WRITEABLE_BIT | WRITE_LOGICS_QUEUE_ERROR_BIT | DISK_FULL_BIT | WRITE_INDEX_FILE_ERROR_BIT | FENCED_BIT | LOGIC_DISK_FULL_BIT)) == 0) {
             return true;
         }
 
@@ -81,7 +87,7 @@ public class RunningFlags {
 
     //for consume queue, just ignore the DISK_FULL_BIT
     public boolean isCQWriteable() {
-        if ((this.flagBits & (NOT_WRITEABLE_BIT | WRITE_LOGICS_QUEUE_ERROR_BIT | WRITE_INDEX_FILE_ERROR_BIT)) == 0) {
+        if ((this.flagBits & (NOT_WRITEABLE_BIT | WRITE_LOGICS_QUEUE_ERROR_BIT | WRITE_INDEX_FILE_ERROR_BIT | LOGIC_DISK_FULL_BIT)) == 0) {
             return true;
         }
 
@@ -139,4 +145,16 @@ public class RunningFlags {
         this.flagBits &= ~DISK_FULL_BIT;
         return result;
     }
+
+    public boolean getAndMakeLogicDiskFull() {
+        boolean result = !((this.flagBits & LOGIC_DISK_FULL_BIT) == LOGIC_DISK_FULL_BIT);
+        this.flagBits |= LOGIC_DISK_FULL_BIT;
+        return result;
+    }
+
+    public boolean getAndMakeLogicDiskOK() {
+        boolean result = !((this.flagBits & LOGIC_DISK_FULL_BIT) == LOGIC_DISK_FULL_BIT);
+        this.flagBits &= ~LOGIC_DISK_FULL_BIT;
+        return result;
+    }
 }
diff --git a/store/src/main/java/org/apache/rocketmq/store/config/MessageStoreConfig.java b/store/src/main/java/org/apache/rocketmq/store/config/MessageStoreConfig.java
index 9fa448043..028facbdc 100644
--- a/store/src/main/java/org/apache/rocketmq/store/config/MessageStoreConfig.java
+++ b/store/src/main/java/org/apache/rocketmq/store/config/MessageStoreConfig.java
@@ -397,8 +397,10 @@ public class MessageStoreConfig {
     private int batchDispatchRequestThreadPoolNums = 16;
 
     // rocksdb mode
+    private long cleanRocksDBDirtyCQIntervalMin = 60;
+    private long statRocksDBCQIntervalSec = 10;
+    private long memTableFlushIntervalMs = 60 * 60 * 1000L;
     private boolean realTimePersistRocksDBConfig = true;
-    private long memTableFlushInterval = 60 * 60 * 1000L;
     private boolean enableRocksDBLog = false;
 
     private int topicQueueLockNum = 32;
@@ -499,6 +501,10 @@ public class MessageStoreConfig {
         this.mappedFileSizeCommitLog = mappedFileSizeCommitLog;
     }
 
+    public boolean isEnableRocksDBStore() {
+        return StoreType.DEFAULT_ROCKSDB.getStoreType().equalsIgnoreCase(this.storeType);
+    }
+
     public String getStoreType() {
         return storeType;
     }
@@ -508,7 +514,6 @@ public class MessageStoreConfig {
     }
 
     public int getMappedFileSizeConsumeQueue() {
-
         int factor = (int) Math.ceil(this.mappedFileSizeConsumeQueue / (ConsumeQueue.CQ_STORE_UNIT_SIZE * 1.0));
         return (int) (factor * ConsumeQueue.CQ_STORE_UNIT_SIZE);
     }
@@ -1738,12 +1743,28 @@ public class MessageStoreConfig {
         this.realTimePersistRocksDBConfig = realTimePersistRocksDBConfig;
     }
 
-    public long getMemTableFlushInterval() {
-        return memTableFlushInterval;
+    public long getStatRocksDBCQIntervalSec() {
+        return statRocksDBCQIntervalSec;
+    }
+
+    public void setStatRocksDBCQIntervalSec(long statRocksDBCQIntervalSec) {
+        this.statRocksDBCQIntervalSec = statRocksDBCQIntervalSec;
+    }
+
+    public long getCleanRocksDBDirtyCQIntervalMin() {
+        return cleanRocksDBDirtyCQIntervalMin;
+    }
+
+    public void setCleanRocksDBDirtyCQIntervalMin(long cleanRocksDBDirtyCQIntervalMin) {
+        this.cleanRocksDBDirtyCQIntervalMin = cleanRocksDBDirtyCQIntervalMin;
+    }
+
+    public long getMemTableFlushIntervalMs() {
+        return memTableFlushIntervalMs;
     }
 
-    public void setMemTableFlushInterval(long memTableFlushInterval) {
-        this.memTableFlushInterval = memTableFlushInterval;
+    public void setMemTableFlushIntervalMs(long memTableFlushIntervalMs) {
+        this.memTableFlushIntervalMs = memTableFlushIntervalMs;
     }
 
     public boolean isEnableRocksDBLog() {
diff --git a/store/src/main/java/org/apache/rocketmq/store/dledger/DLedgerCommitLog.java b/store/src/main/java/org/apache/rocketmq/store/dledger/DLedgerCommitLog.java
index d5f6acdc0..70371d83b 100644
--- a/store/src/main/java/org/apache/rocketmq/store/dledger/DLedgerCommitLog.java
+++ b/store/src/main/java/org/apache/rocketmq/store/dledger/DLedgerCommitLog.java
@@ -16,26 +16,13 @@
  */
 package org.apache.rocketmq.store.dledger;
 
-import io.openmessaging.storage.dledger.AppendFuture;
-import io.openmessaging.storage.dledger.BatchAppendFuture;
-import io.openmessaging.storage.dledger.DLedgerConfig;
-import io.openmessaging.storage.dledger.DLedgerServer;
-import io.openmessaging.storage.dledger.entry.DLedgerEntry;
-import io.openmessaging.storage.dledger.protocol.AppendEntryRequest;
-import io.openmessaging.storage.dledger.protocol.AppendEntryResponse;
-import io.openmessaging.storage.dledger.protocol.BatchAppendEntryRequest;
-import io.openmessaging.storage.dledger.protocol.DLedgerResponseCode;
-import io.openmessaging.storage.dledger.store.file.DLedgerMmapFileStore;
-import io.openmessaging.storage.dledger.store.file.MmapFile;
-import io.openmessaging.storage.dledger.store.file.MmapFileList;
-import io.openmessaging.storage.dledger.store.file.SelectMmapBufferResult;
-import io.openmessaging.storage.dledger.utils.DLedgerUtils;
 import java.net.Inet6Address;
 import java.net.InetSocketAddress;
 import java.nio.ByteBuffer;
 import java.util.LinkedList;
 import java.util.List;
 import java.util.concurrent.CompletableFuture;
+
 import org.apache.rocketmq.common.UtilAll;
 import org.apache.rocketmq.common.message.MessageDecoder;
 import org.apache.rocketmq.common.message.MessageExtBatch;
@@ -54,6 +41,22 @@ import org.apache.rocketmq.store.SelectMappedBufferResult;
 import org.apache.rocketmq.store.StoreStatsService;
 import org.apache.rocketmq.store.config.MessageStoreConfig;
 import org.apache.rocketmq.store.logfile.MappedFile;
+import org.rocksdb.RocksDBException;
+
+import io.openmessaging.storage.dledger.AppendFuture;
+import io.openmessaging.storage.dledger.BatchAppendFuture;
+import io.openmessaging.storage.dledger.DLedgerConfig;
+import io.openmessaging.storage.dledger.DLedgerServer;
+import io.openmessaging.storage.dledger.entry.DLedgerEntry;
+import io.openmessaging.storage.dledger.protocol.AppendEntryRequest;
+import io.openmessaging.storage.dledger.protocol.AppendEntryResponse;
+import io.openmessaging.storage.dledger.protocol.BatchAppendEntryRequest;
+import io.openmessaging.storage.dledger.protocol.DLedgerResponseCode;
+import io.openmessaging.storage.dledger.store.file.DLedgerMmapFileStore;
+import io.openmessaging.storage.dledger.store.file.MmapFile;
+import io.openmessaging.storage.dledger.store.file.MmapFileList;
+import io.openmessaging.storage.dledger.store.file.SelectMmapBufferResult;
+import io.openmessaging.storage.dledger.utils.DLedgerUtils;
 
 /**
  * Store all metadata downtime for recovery, data protection reliability
@@ -269,7 +272,7 @@ public class DLedgerCommitLog extends CommitLog {
 
         return null;
     }
-     
+
     @Override
     public boolean getData(final long offset, final int size, final ByteBuffer byteBuffer) {
         if (offset < dividedCommitlogOffset) {
@@ -287,7 +290,7 @@ public class DLedgerCommitLog extends CommitLog {
         return false;
     }
 
-    private void recover(long maxPhyOffsetOfConsumeQueue) {
+    private void recover(long maxPhyOffsetOfConsumeQueue) throws RocksDBException {
         dLedgerFileStore.load();
         if (dLedgerFileList.getMappedFiles().size() > 0) {
             dLedgerFileStore.recover();
@@ -341,12 +344,12 @@ public class DLedgerCommitLog extends CommitLog {
     }
 
     @Override
-    public void recoverNormally(long maxPhyOffsetOfConsumeQueue) {
+    public void recoverNormally(long maxPhyOffsetOfConsumeQueue) throws RocksDBException {
         recover(maxPhyOffsetOfConsumeQueue);
     }
 
     @Override
-    public void recoverAbnormally(long maxPhyOffsetOfConsumeQueue) {
+    public void recoverAbnormally(long maxPhyOffsetOfConsumeQueue) throws RocksDBException {
         recover(maxPhyOffsetOfConsumeQueue);
     }
 
@@ -469,9 +472,6 @@ public class DLedgerCommitLog extends CommitLog {
                 String msgId = MessageDecoder.createMessageId(buffer, msg.getStoreHostBytes(), wroteOffset);
                 elapsedTimeInLock = this.defaultMessageStore.getSystemClock().now() - beginTimeInDledgerLock;
                 appendResult = new AppendMessageResult(AppendMessageStatus.PUT_OK, wroteOffset, encodeResult.getData().length, msgId, System.currentTimeMillis(), queueOffset, elapsedTimeInLock);
-            } catch (Exception e) {
-                log.error("Put message error", e);
-                return CompletableFuture.completedFuture(new PutMessageResult(PutMessageStatus.UNKNOWN_ERROR, new AppendMessageResult(AppendMessageStatus.UNKNOWN_ERROR)));
             } finally {
                 beginTimeInDledgerLock = 0;
                 putMessageLock.unlock();
@@ -482,6 +482,9 @@ public class DLedgerCommitLog extends CommitLog {
             }
 
             defaultMessageStore.increaseOffset(msg, getMessageNum(msg));
+        } catch (Exception e) {
+            log.error("Put message error", e);
+            return CompletableFuture.completedFuture(new PutMessageResult(PutMessageStatus.UNKNOWN_ERROR, new AppendMessageResult(AppendMessageStatus.UNKNOWN_ERROR)));
         } finally {
             topicQueueLock.unlock(topicQueueKey);
         }
@@ -611,9 +614,6 @@ public class DLedgerCommitLog extends CommitLog {
                 appendResult = new AppendMessageResult(AppendMessageStatus.PUT_OK, firstWroteOffset, encodeResult.totalMsgLen,
                     msgIdBuilder.toString(), System.currentTimeMillis(), queueOffset, elapsedTimeInLock);
                 appendResult.setMsgNum(msgNum);
-            } catch (Exception e) {
-                log.error("Put message error", e);
-                return CompletableFuture.completedFuture(new PutMessageResult(PutMessageStatus.UNKNOWN_ERROR, new AppendMessageResult(AppendMessageStatus.UNKNOWN_ERROR)));
             } finally {
                 beginTimeInDledgerLock = 0;
                 putMessageLock.unlock();
@@ -626,7 +626,10 @@ public class DLedgerCommitLog extends CommitLog {
 
             defaultMessageStore.increaseOffset(messageExtBatch, (short) batchNum);
 
-        } finally {
+        } catch (Exception e) {
+            log.error("Put message error", e);
+            return CompletableFuture.completedFuture(new PutMessageResult(PutMessageStatus.UNKNOWN_ERROR, new AppendMessageResult(AppendMessageStatus.UNKNOWN_ERROR)));
+        }  finally {
             topicQueueLock.unlock(encodeResult.queueOffsetKey);
         }
 
diff --git a/store/src/main/java/org/apache/rocketmq/store/ha/HAService.java b/store/src/main/java/org/apache/rocketmq/store/ha/HAService.java
index 467da603d..aaea7d690 100644
--- a/store/src/main/java/org/apache/rocketmq/store/ha/HAService.java
+++ b/store/src/main/java/org/apache/rocketmq/store/ha/HAService.java
@@ -25,6 +25,7 @@ import org.apache.rocketmq.remoting.protocol.body.HARuntimeInfo;
 import org.apache.rocketmq.store.CommitLog;
 import org.apache.rocketmq.store.DefaultMessageStore;
 import org.apache.rocketmq.store.config.MessageStoreConfig;
+import org.rocksdb.RocksDBException;
 
 public interface HAService {
 
@@ -53,7 +54,7 @@ public interface HAService {
      *
      * @param masterEpoch the new masterEpoch
      */
-    default boolean changeToMaster(int masterEpoch) {
+    default boolean changeToMaster(int masterEpoch) throws RocksDBException {
         return false;
     }
 
diff --git a/store/src/main/java/org/apache/rocketmq/store/ha/autoswitch/AutoSwitchHAClient.java b/store/src/main/java/org/apache/rocketmq/store/ha/autoswitch/AutoSwitchHAClient.java
index 936db0c4c..176c25a96 100644
--- a/store/src/main/java/org/apache/rocketmq/store/ha/autoswitch/AutoSwitchHAClient.java
+++ b/store/src/main/java/org/apache/rocketmq/store/ha/autoswitch/AutoSwitchHAClient.java
@@ -432,7 +432,7 @@ public class AutoSwitchHAClient extends ServiceThread implements HAClient {
     /**
      * Compare the master and slave's epoch file, find consistent point, do truncate.
      */
-    private boolean doTruncate(List<EpochEntry> masterEpochEntries, long masterEndOffset) throws IOException {
+    private boolean doTruncate(List<EpochEntry> masterEpochEntries, long masterEndOffset) throws Exception {
         if (this.epochCache.getEntrySize() == 0) {
             // If epochMap is empty, means the broker is a new replicas
             LOGGER.info("Slave local epochCache is empty, skip truncate log");
diff --git a/store/src/main/java/org/apache/rocketmq/store/ha/autoswitch/AutoSwitchHAService.java b/store/src/main/java/org/apache/rocketmq/store/ha/autoswitch/AutoSwitchHAService.java
index f20bc3e28..64dad9aef 100644
--- a/store/src/main/java/org/apache/rocketmq/store/ha/autoswitch/AutoSwitchHAService.java
+++ b/store/src/main/java/org/apache/rocketmq/store/ha/autoswitch/AutoSwitchHAService.java
@@ -51,6 +51,7 @@ import org.apache.rocketmq.store.ha.GroupTransferService;
 import org.apache.rocketmq.store.ha.HAClient;
 import org.apache.rocketmq.store.ha.HAConnection;
 import org.apache.rocketmq.store.ha.HAConnectionStateNotificationService;
+import org.rocksdb.RocksDBException;
 
 /**
  * SwitchAble ha service, support switch role to master or slave.
@@ -111,7 +112,7 @@ public class AutoSwitchHAService extends DefaultHAService {
     }
 
     @Override
-    public boolean changeToMaster(int masterEpoch) {
+    public boolean changeToMaster(int masterEpoch) throws RocksDBException {
         final int lastEpoch = this.epochCache.lastEpoch();
         if (masterEpoch < lastEpoch) {
             LOGGER.warn("newMasterEpoch {} < lastEpoch {}, fail to change to master", masterEpoch, lastEpoch);
@@ -315,7 +316,7 @@ public class AutoSwitchHAService extends DefaultHAService {
             final EpochEntry currentLeaderEpoch = this.epochCache.lastEntry();
             if (slaveMaxOffset >= currentLeaderEpoch.getStartOffset()) {
                 LOGGER.info("The slave {} has caught up, slaveMaxOffset: {}, confirmOffset: {}, epoch: {}, leader epoch startOffset: {}.",
-                        slaveBrokerId, slaveMaxOffset, confirmOffset, currentLeaderEpoch.getEpoch(), currentLeaderEpoch.getStartOffset());
+                    slaveBrokerId, slaveMaxOffset, confirmOffset, currentLeaderEpoch.getEpoch(), currentLeaderEpoch.getStartOffset());
                 currentSyncStateSet.add(slaveBrokerId);
                 markSynchronizingSyncStateSet(currentSyncStateSet);
                 // Notify the upper layer that syncStateSet changed.
@@ -491,7 +492,7 @@ public class AutoSwitchHAService extends DefaultHAService {
     /**
      * Try to truncate incomplete msg transferred from master.
      */
-    public long truncateInvalidMsg() {
+    public long truncateInvalidMsg() throws RocksDBException {
         long dispatchBehind = this.defaultMessageStore.dispatchBehindBytes();
         if (dispatchBehind <= 0) {
             LOGGER.info("Dispatch complete, skip truncate");
diff --git a/store/src/main/java/org/apache/rocketmq/store/plugin/AbstractPluginMessageStore.java b/store/src/main/java/org/apache/rocketmq/store/plugin/AbstractPluginMessageStore.java
index ab9fc6da7..2f2ce9812 100644
--- a/store/src/main/java/org/apache/rocketmq/store/plugin/AbstractPluginMessageStore.java
+++ b/store/src/main/java/org/apache/rocketmq/store/plugin/AbstractPluginMessageStore.java
@@ -17,10 +17,6 @@
 
 package org.apache.rocketmq.store.plugin;
 
-import io.opentelemetry.api.common.AttributesBuilder;
-import io.opentelemetry.api.metrics.Meter;
-import io.opentelemetry.sdk.metrics.InstrumentSelector;
-import io.opentelemetry.sdk.metrics.ViewBuilder;
 import java.nio.ByteBuffer;
 import java.util.HashMap;
 import java.util.LinkedList;
@@ -55,10 +51,16 @@ import org.apache.rocketmq.store.hook.PutMessageHook;
 import org.apache.rocketmq.store.hook.SendMessageBackHook;
 import org.apache.rocketmq.store.logfile.MappedFile;
 import org.apache.rocketmq.store.queue.ConsumeQueueInterface;
-import org.apache.rocketmq.store.queue.ConsumeQueueStore;
+import org.apache.rocketmq.store.queue.ConsumeQueueStoreInterface;
 import org.apache.rocketmq.store.stats.BrokerStatsManager;
 import org.apache.rocketmq.store.timer.TimerMessageStore;
 import org.apache.rocketmq.store.util.PerfCounter;
+import org.rocksdb.RocksDBException;
+
+import io.opentelemetry.api.common.AttributesBuilder;
+import io.opentelemetry.api.metrics.Meter;
+import io.opentelemetry.sdk.metrics.InstrumentSelector;
+import io.opentelemetry.sdk.metrics.ViewBuilder;
 
 public abstract class AbstractPluginMessageStore implements MessageStore {
     protected MessageStore next = null;
@@ -457,7 +459,7 @@ public abstract class AbstractPluginMessageStore implements MessageStore {
     }
 
     @Override
-    public boolean truncateFiles(long offsetToTruncate) {
+    public boolean truncateFiles(long offsetToTruncate) throws RocksDBException {
         return next.truncateFiles(offsetToTruncate);
     }
 
@@ -511,7 +513,7 @@ public abstract class AbstractPluginMessageStore implements MessageStore {
 
     @Override
     public void onCommitLogDispatch(DispatchRequest dispatchRequest, boolean doDispatch, MappedFile commitLogFile,
-        boolean isRecover, boolean isFileEnd) {
+        boolean isRecover, boolean isFileEnd) throws RocksDBException {
         next.onCommitLogDispatch(dispatchRequest, doDispatch, commitLogFile, isRecover, isFileEnd);
     }
 
@@ -551,15 +553,10 @@ public abstract class AbstractPluginMessageStore implements MessageStore {
     }
 
     @Override
-    public void truncateDirtyLogicFiles(long phyOffset) {
+    public void truncateDirtyLogicFiles(long phyOffset) throws RocksDBException {
         next.truncateDirtyLogicFiles(phyOffset);
     }
 
-    @Override
-    public void destroyLogics() {
-        next.destroyLogics();
-    }
-
     @Override
     public void unlockMappedFile(MappedFile unlockMappedFile) {
         next.unlockMappedFile(unlockMappedFile);
@@ -571,7 +568,7 @@ public abstract class AbstractPluginMessageStore implements MessageStore {
     }
 
     @Override
-    public ConsumeQueueStore getQueueStore() {
+    public ConsumeQueueStoreInterface getQueueStore() {
         return next.getQueueStore();
     }
 
@@ -586,7 +583,7 @@ public abstract class AbstractPluginMessageStore implements MessageStore {
     }
 
     @Override
-    public void assignOffset(MessageExtBrokerInner msg) {
+    public void assignOffset(MessageExtBrokerInner msg) throws RocksDBException {
         next.assignOffset(msg);
     }
 
@@ -649,4 +646,19 @@ public abstract class AbstractPluginMessageStore implements MessageStore {
     public void initMetrics(Meter meter, Supplier<AttributesBuilder> attributesBuilderSupplier) {
         next.initMetrics(meter, attributesBuilderSupplier);
     }
+
+    @Override
+    public void finishCommitLogDispatch() {
+        next.finishCommitLogDispatch();
+    }
+
+    @Override
+    public void recoverTopicQueueTable() {
+        next.recoverTopicQueueTable();
+    }
+
+    @Override
+    public void notifyMessageArriveIfNecessary(DispatchRequest dispatchRequest) {
+        next.notifyMessageArriveIfNecessary(dispatchRequest);
+    }
 }
diff --git a/store/src/main/java/org/apache/rocketmq/store/queue/AbstractConsumeQueueStore.java b/store/src/main/java/org/apache/rocketmq/store/queue/AbstractConsumeQueueStore.java
new file mode 100644
index 000000000..30054fa50
--- /dev/null
+++ b/store/src/main/java/org/apache/rocketmq/store/queue/AbstractConsumeQueueStore.java
@@ -0,0 +1,105 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.rocketmq.store.queue;
+
+import java.util.concurrent.ConcurrentHashMap;
+import java.util.concurrent.ConcurrentMap;
+import org.apache.rocketmq.common.constant.LoggerName;
+import org.apache.rocketmq.common.message.MessageExtBrokerInner;
+import org.apache.rocketmq.logging.org.slf4j.Logger;
+import org.apache.rocketmq.logging.org.slf4j.LoggerFactory;
+import org.apache.rocketmq.store.DefaultMessageStore;
+import org.apache.rocketmq.store.DispatchRequest;
+import org.apache.rocketmq.store.config.MessageStoreConfig;
+import org.rocksdb.RocksDBException;
+
+public abstract class AbstractConsumeQueueStore implements ConsumeQueueStoreInterface {
+    protected static final Logger log = LoggerFactory.getLogger(LoggerName.STORE_LOGGER_NAME);
+
+    protected final DefaultMessageStore messageStore;
+    protected final MessageStoreConfig messageStoreConfig;
+    protected final QueueOffsetOperator queueOffsetOperator = new QueueOffsetOperator();
+    protected final ConcurrentMap<String/* topic */, ConcurrentMap<Integer/* queueId */, ConsumeQueueInterface>> consumeQueueTable;
+
+    public AbstractConsumeQueueStore(DefaultMessageStore messageStore) {
+        this.messageStore = messageStore;
+        this.messageStoreConfig = messageStore.getMessageStoreConfig();
+        this.consumeQueueTable = new ConcurrentHashMap<>(32);
+    }
+
+    @Override
+    public void putMessagePositionInfoWrapper(ConsumeQueueInterface consumeQueue, DispatchRequest request) {
+        consumeQueue.putMessagePositionInfoWrapper(request);
+    }
+
+    @Override
+    public Long getMaxOffset(String topic, int queueId) {
+        return this.queueOffsetOperator.currentQueueOffset(topic + "-" + queueId);
+    }
+
+    @Override
+    public void setTopicQueueTable(ConcurrentMap<String, Long> topicQueueTable) {
+        this.queueOffsetOperator.setTopicQueueTable(topicQueueTable);
+        this.queueOffsetOperator.setLmqTopicQueueTable(topicQueueTable);
+    }
+
+    @Override
+    public ConcurrentMap getTopicQueueTable() {
+        return this.queueOffsetOperator.getTopicQueueTable();
+    }
+
+    @Override
+    public void assignQueueOffset(MessageExtBrokerInner msg) throws RocksDBException {
+        ConsumeQueueInterface consumeQueue = findOrCreateConsumeQueue(msg.getTopic(), msg.getQueueId());
+        consumeQueue.assignQueueOffset(this.queueOffsetOperator, msg);
+    }
+
+    @Override
+    public void increaseQueueOffset(MessageExtBrokerInner msg, short messageNum) {
+        ConsumeQueueInterface consumeQueue = findOrCreateConsumeQueue(msg.getTopic(), msg.getQueueId());
+        consumeQueue.increaseQueueOffset(this.queueOffsetOperator, msg, messageNum);
+    }
+
+    @Override
+    public void removeTopicQueueTable(String topic, Integer queueId) {
+        this.queueOffsetOperator.remove(topic, queueId);
+    }
+
+    @Override
+    public ConcurrentMap<String, ConcurrentMap<Integer, ConsumeQueueInterface>> getConsumeQueueTable() {
+        return this.consumeQueueTable;
+    }
+
+    @Override
+    public ConcurrentMap<Integer, ConsumeQueueInterface> findConsumeQueueMap(String topic) {
+        return this.consumeQueueTable.get(topic);
+    }
+
+    @Override
+    public long getStoreTime(CqUnit cqUnit) {
+        if (cqUnit != null) {
+            try {
+                final long phyOffset = cqUnit.getPos();
+                final int size = cqUnit.getSize();
+                long storeTime = this.messageStore.getCommitLog().pickupStoreTimestamp(phyOffset, size);
+                return storeTime;
+            } catch (Exception e) {
+            }
+        }
+        return -1;
+    }
+}
diff --git a/store/src/main/java/org/apache/rocketmq/store/queue/BatchConsumeQueue.java b/store/src/main/java/org/apache/rocketmq/store/queue/BatchConsumeQueue.java
index 387c233bf..7108c835c 100644
--- a/store/src/main/java/org/apache/rocketmq/store/queue/BatchConsumeQueue.java
+++ b/store/src/main/java/org/apache/rocketmq/store/queue/BatchConsumeQueue.java
@@ -24,6 +24,7 @@ import java.util.Map;
 import java.util.concurrent.ConcurrentSkipListMap;
 import java.util.function.Function;
 import org.apache.commons.lang3.StringUtils;
+import org.apache.rocketmq.common.Pair;
 import org.apache.rocketmq.common.BoundaryType;
 import org.apache.rocketmq.common.attribute.CQType;
 import org.apache.rocketmq.common.constant.LoggerName;
@@ -311,6 +312,11 @@ public class BatchConsumeQueue implements ConsumeQueueInterface {
         return new BatchConsumeQueueIterator(sbr);
     }
 
+    @Override
+    public ReferredIterator<CqUnit> iterateFrom(long startIndex, int count) {
+        return iterateFrom(startIndex);
+    }
+
     @Override
     public CqUnit get(long offset) {
         ReferredIterator<CqUnit> it = iterateFrom(offset);
@@ -320,6 +326,20 @@ public class BatchConsumeQueue implements ConsumeQueueInterface {
         return it.nextAndRelease();
     }
 
+    @Override
+    public Pair<CqUnit, Long> getCqUnitAndStoreTime(long index) {
+        CqUnit cqUnit = get(index);
+        Long messageStoreTime = this.messageStore.getQueueStore().getStoreTime(cqUnit);
+        return new Pair<>(cqUnit, messageStoreTime);
+    }
+
+    @Override
+    public Pair<CqUnit, Long> getEarliestUnitAndStoreTime() {
+        CqUnit cqUnit = getEarliestUnit();
+        Long messageStoreTime = this.messageStore.getQueueStore().getStoreTime(cqUnit);
+        return new Pair<>(cqUnit, messageStoreTime);
+    }
+
     @Override
     public CqUnit getEarliestUnit() {
         return get(minOffsetInQueue);
diff --git a/store/src/main/java/org/apache/rocketmq/store/queue/ConsumeQueueInterface.java b/store/src/main/java/org/apache/rocketmq/store/queue/ConsumeQueueInterface.java
index 55d080829..c65f2a68b 100644
--- a/store/src/main/java/org/apache/rocketmq/store/queue/ConsumeQueueInterface.java
+++ b/store/src/main/java/org/apache/rocketmq/store/queue/ConsumeQueueInterface.java
@@ -18,10 +18,12 @@
 package org.apache.rocketmq.store.queue;
 
 import org.apache.rocketmq.common.BoundaryType;
+import org.apache.rocketmq.common.Pair;
 import org.apache.rocketmq.common.attribute.CQType;
 import org.apache.rocketmq.common.message.MessageExtBrokerInner;
 import org.apache.rocketmq.store.DispatchRequest;
 import org.apache.rocketmq.store.MessageFilter;
+import org.rocksdb.RocksDBException;
 
 public interface ConsumeQueueInterface extends FileQueueLifeCycle {
     /**
@@ -44,6 +46,16 @@ public interface ConsumeQueueInterface extends FileQueueLifeCycle {
      */
     ReferredIterator<CqUnit> iterateFrom(long startIndex);
 
+    /**
+     * Get the units from the start offset.
+     *
+     * @param startIndex start index
+     * @param count the unit counts will be iterated
+     * @return the unit iterateFrom
+     * @throws RocksDBException only in rocksdb mode
+     */
+    ReferredIterator<CqUnit> iterateFrom(long startIndex, int count) throws RocksDBException;
+
     /**
      * Get cq unit at specified index
      * @param index index
@@ -51,6 +63,18 @@ public interface ConsumeQueueInterface extends FileQueueLifeCycle {
      */
     CqUnit get(long index);
 
+    /**
+     * Get earliest cq unit
+     * @return the cq unit and message storeTime at index
+     */
+    Pair<CqUnit, Long> getCqUnitAndStoreTime(long index);
+
+    /**
+     * Get earliest cq unit
+     * @return earliest cq unit and message storeTime
+     */
+    Pair<CqUnit, Long> getEarliestUnitAndStoreTime();
+
     /**
      * Get earliest cq unit
      * @return earliest cq unit
@@ -153,8 +177,9 @@ public interface ConsumeQueueInterface extends FileQueueLifeCycle {
      * Assign queue offset.
      * @param queueOffsetAssigner the delegated queue offset assigner
      * @param msg message itself
+     * @throws RocksDBException only in rocksdb mode
      */
-    void assignQueueOffset(QueueOffsetOperator queueOffsetAssigner, MessageExtBrokerInner msg);
+    void assignQueueOffset(QueueOffsetOperator queueOffsetAssigner, MessageExtBrokerInner msg) throws RocksDBException;
 
 
     /**
diff --git a/store/src/main/java/org/apache/rocketmq/store/queue/ConsumeQueueStore.java b/store/src/main/java/org/apache/rocketmq/store/queue/ConsumeQueueStore.java
index d03d15d65..616511b67 100644
--- a/store/src/main/java/org/apache/rocketmq/store/queue/ConsumeQueueStore.java
+++ b/store/src/main/java/org/apache/rocketmq/store/queue/ConsumeQueueStore.java
@@ -16,64 +16,128 @@
  */
 package org.apache.rocketmq.store.queue;
 
+import java.io.File;
 import java.nio.ByteBuffer;
 import java.util.ArrayList;
+import java.util.Iterator;
 import java.util.List;
+import java.util.Map;
+import java.util.Map.Entry;
+import java.util.Objects;
+import java.util.Optional;
 import java.util.concurrent.BlockingQueue;
+import java.util.concurrent.ConcurrentHashMap;
+import java.util.concurrent.ConcurrentMap;
 import java.util.concurrent.CountDownLatch;
 import java.util.concurrent.ExecutorService;
 import java.util.concurrent.FutureTask;
 import java.util.concurrent.LinkedBlockingQueue;
 import java.util.concurrent.TimeUnit;
+import org.apache.rocketmq.common.BoundaryType;
 import org.apache.rocketmq.common.ThreadFactoryImpl;
 import org.apache.rocketmq.common.TopicConfig;
 import org.apache.rocketmq.common.attribute.CQType;
-import org.apache.rocketmq.common.constant.LoggerName;
 import org.apache.rocketmq.common.message.MessageDecoder;
 import org.apache.rocketmq.common.message.MessageExt;
 import org.apache.rocketmq.common.topic.TopicValidator;
 import org.apache.rocketmq.common.utils.QueueTypeUtils;
 import org.apache.rocketmq.common.utils.ThreadUtils;
-import org.apache.rocketmq.logging.org.slf4j.Logger;
-import org.apache.rocketmq.logging.org.slf4j.LoggerFactory;
 import org.apache.rocketmq.store.CommitLog;
 import org.apache.rocketmq.store.ConsumeQueue;
 import org.apache.rocketmq.store.DefaultMessageStore;
 import org.apache.rocketmq.store.DispatchRequest;
-import org.apache.rocketmq.common.message.MessageExtBrokerInner;
 import org.apache.rocketmq.store.SelectMappedBufferResult;
-import org.apache.rocketmq.store.config.MessageStoreConfig;
-
-import java.io.File;
-import java.util.Iterator;
-import java.util.Map;
-import java.util.Objects;
-import java.util.Optional;
-import java.util.concurrent.ConcurrentHashMap;
-import java.util.concurrent.ConcurrentMap;
 
 import static java.lang.String.format;
 import static org.apache.rocketmq.store.config.StorePathConfigHelper.getStorePathBatchConsumeQueue;
 import static org.apache.rocketmq.store.config.StorePathConfigHelper.getStorePathConsumeQueue;
 
-public class ConsumeQueueStore {
-    private static final Logger log = LoggerFactory.getLogger(LoggerName.STORE_LOGGER_NAME);
+public class ConsumeQueueStore extends AbstractConsumeQueueStore {
 
-    protected final DefaultMessageStore messageStore;
-    protected final MessageStoreConfig messageStoreConfig;
-    protected final QueueOffsetOperator queueOffsetOperator = new QueueOffsetOperator();
-    protected final ConcurrentMap<String/* topic */, ConcurrentMap<Integer/* queueId */, ConsumeQueueInterface>> consumeQueueTable;
+    public ConsumeQueueStore(DefaultMessageStore messageStore) {
+        super(messageStore);
+    }
 
-    public ConsumeQueueStore(DefaultMessageStore messageStore, MessageStoreConfig messageStoreConfig) {
-        this.messageStore = messageStore;
-        this.messageStoreConfig = messageStoreConfig;
-        this.consumeQueueTable = new ConcurrentHashMap<>(32);
+    @Override
+    public void start() {
+        log.info("Default ConsumeQueueStore start!");
     }
 
-    private FileQueueLifeCycle getLifeCycle(String topic, int queueId) {
-        return findOrCreateConsumeQueue(topic, queueId);
+    @Override
+    public boolean load() {
+        boolean cqLoadResult = loadConsumeQueues(getStorePathConsumeQueue(this.messageStoreConfig.getStorePathRootDir()), CQType.SimpleCQ);
+        boolean bcqLoadResult = loadConsumeQueues(getStorePathBatchConsumeQueue(this.messageStoreConfig.getStorePathRootDir()), CQType.BatchCQ);
+        return cqLoadResult && bcqLoadResult;
+    }
+
+    @Override
+    public boolean loadAfterDestroy() {
+        return true;
+    }
+
+    @Override
+    public void recover() {
+        for (ConcurrentMap<Integer, ConsumeQueueInterface> maps : this.consumeQueueTable.values()) {
+            for (ConsumeQueueInterface logic : maps.values()) {
+                this.recover(logic);
+            }
+        }
     }
 
+    @Override
+    public boolean recoverConcurrently() {
+        int count = 0;
+        for (ConcurrentMap<Integer, ConsumeQueueInterface> maps : this.consumeQueueTable.values()) {
+            count += maps.values().size();
+        }
+        final CountDownLatch countDownLatch = new CountDownLatch(count);
+        BlockingQueue<Runnable> recoverQueue = new LinkedBlockingQueue<>();
+        final ExecutorService executor = buildExecutorService(recoverQueue, "RecoverConsumeQueueThread_");
+        List<FutureTask<Boolean>> result = new ArrayList<>(count);
+        try {
+            for (ConcurrentMap<Integer, ConsumeQueueInterface> maps : this.consumeQueueTable.values()) {
+                for (final ConsumeQueueInterface logic : maps.values()) {
+                    FutureTask<Boolean> futureTask = new FutureTask<>(() -> {
+                        boolean ret = true;
+                        try {
+                            logic.recover();
+                        } catch (Throwable e) {
+                            ret = false;
+                            log.error("Exception occurs while recover consume queue concurrently, " +
+                                "topic={}, queueId={}", logic.getTopic(), logic.getQueueId(), e);
+                        } finally {
+                            countDownLatch.countDown();
+                        }
+                        return ret;
+                    });
+
+                    result.add(futureTask);
+                    executor.submit(futureTask);
+                }
+            }
+            countDownLatch.await();
+            for (FutureTask<Boolean> task : result) {
+                if (task != null && task.isDone()) {
+                    if (!task.get()) {
+                        return false;
+                    }
+                }
+            }
+        } catch (Exception e) {
+            log.error("Exception occurs while recover consume queue concurrently", e);
+            return false;
+        } finally {
+            executor.shutdown();
+        }
+        return true;
+    }
+
+    @Override
+    public boolean shutdown() {
+        return true;
+    }
+
+    @Override
     public long rollNextFile(ConsumeQueueInterface consumeQueue, final long offset) {
         FileQueueLifeCycle fileQueueLifeCycle = getLifeCycle(consumeQueue.getTopic(), consumeQueue.getQueueId());
         return fileQueueLifeCycle.rollNextFile(offset);
@@ -83,32 +147,53 @@ public class ConsumeQueueStore {
         consumeQueue.correctMinOffset(minCommitLogOffset);
     }
 
-    /**
-     * Apply the dispatched request and build the consume queue. This function should be idempotent.
-     *
-     * @param consumeQueue consume queue
-     * @param request dispatch request
-     */
-    public void putMessagePositionInfoWrapper(ConsumeQueueInterface consumeQueue, DispatchRequest request) {
-        consumeQueue.putMessagePositionInfoWrapper(request);
-    }
-
+    @Override
     public void putMessagePositionInfoWrapper(DispatchRequest dispatchRequest) {
         ConsumeQueueInterface cq = this.findOrCreateConsumeQueue(dispatchRequest.getTopic(), dispatchRequest.getQueueId());
         this.putMessagePositionInfoWrapper(cq, dispatchRequest);
     }
 
+    @Override
+    public List<ByteBuffer> rangeQuery(String topic, int queueId, long startIndex, int num) {
+        return null;
+    }
+
+    @Override
+    public ByteBuffer get(String topic, int queueId, long startIndex) {
+        return null;
+    }
+
+    @Override
+    public long getMaxOffsetInQueue(String topic, int queueId) {
+        ConsumeQueueInterface logic = findOrCreateConsumeQueue(topic, queueId);
+        if (logic != null) {
+            return logic.getMaxOffsetInQueue();
+        }
+        return 0;
+    }
+
+    @Override
+    public long getOffsetInQueueByTime(String topic, int queueId, long timestamp, BoundaryType boundaryType) {
+        ConsumeQueueInterface logic = findOrCreateConsumeQueue(topic, queueId);
+        if (logic != null) {
+            long resultOffset = logic.getOffsetInQueueByTime(timestamp, boundaryType);
+            // Make sure the result offset is in valid range.
+            resultOffset = Math.max(resultOffset, logic.getMinOffsetInQueue());
+            resultOffset = Math.min(resultOffset, logic.getMaxOffsetInQueue());
+            return resultOffset;
+        }
+        return 0;
+    }
+
+    private FileQueueLifeCycle getLifeCycle(String topic, int queueId) {
+        return findOrCreateConsumeQueue(topic, queueId);
+    }
+
     public boolean load(ConsumeQueueInterface consumeQueue) {
         FileQueueLifeCycle fileQueueLifeCycle = getLifeCycle(consumeQueue.getTopic(), consumeQueue.getQueueId());
         return fileQueueLifeCycle.load();
     }
 
-    public boolean load() {
-        boolean cqLoadResult = loadConsumeQueues(getStorePathConsumeQueue(this.messageStoreConfig.getStorePathRootDir()), CQType.SimpleCQ);
-        boolean bcqLoadResult = loadConsumeQueues(getStorePathBatchConsumeQueue(this.messageStoreConfig.getStorePathRootDir()), CQType.BatchCQ);
-        return cqLoadResult && bcqLoadResult;
-    }
-
     private boolean loadConsumeQueues(String storePath, CQType cqType) {
         File dirLogic = new File(storePath);
         File[] fileTopicList = dirLogic.listFiles();
@@ -189,62 +274,17 @@ public class ConsumeQueueStore {
         fileQueueLifeCycle.recover();
     }
 
-    public void recover() {
-        for (ConcurrentMap<Integer, ConsumeQueueInterface> maps : this.consumeQueueTable.values()) {
-            for (ConsumeQueueInterface logic : maps.values()) {
-                this.recover(logic);
-            }
-        }
-    }
-
-    public boolean recoverConcurrently() {
-        int count = 0;
-        for (ConcurrentMap<Integer, ConsumeQueueInterface> maps : this.consumeQueueTable.values()) {
-            count += maps.values().size();
-        }
-        final CountDownLatch countDownLatch = new CountDownLatch(count);
-        BlockingQueue<Runnable> recoverQueue = new LinkedBlockingQueue<>();
-        final ExecutorService executor = buildExecutorService(recoverQueue, "RecoverConsumeQueueThread_");
-        List<FutureTask<Boolean>> result = new ArrayList<>(count);
-        try {
-            for (ConcurrentMap<Integer, ConsumeQueueInterface> maps : this.consumeQueueTable.values()) {
-                for (final ConsumeQueueInterface logic : maps.values()) {
-                    FutureTask<Boolean> futureTask = new FutureTask<>(() -> {
-                        boolean ret = true;
-                        try {
-                            logic.recover();
-                        } catch (Throwable e) {
-                            ret = false;
-                            log.error("Exception occurs while recover consume queue concurrently, " +
-                                "topic={}, queueId={}", logic.getTopic(), logic.getQueueId(), e);
-                        } finally {
-                            countDownLatch.countDown();
-                        }
-                        return ret;
-                    });
-
-                    result.add(futureTask);
-                    executor.submit(futureTask);
-                }
-            }
-            countDownLatch.await();
-            for (FutureTask<Boolean> task : result) {
-                if (task != null && task.isDone()) {
-                    if (!task.get()) {
-                        return false;
-                    }
-                }
-            }
-        } catch (Exception e) {
-            log.error("Exception occurs while recover consume queue concurrently", e);
-            return false;
-        } finally {
-            executor.shutdown();
+    @Override
+    public Long getMaxPhyOffsetInConsumeQueue(String topic, int queueId) {
+        ConsumeQueueInterface logic = findOrCreateConsumeQueue(topic, queueId);
+        if (logic != null) {
+            return logic.getMaxPhysicOffset();
         }
-        return true;
+        return null;
     }
 
-    public long getMaxOffsetInConsumeQueue() {
+    @Override
+    public long getMaxPhyOffsetInConsumeQueue() {
         long maxPhysicOffset = -1L;
         for (ConcurrentMap<Integer, ConsumeQueueInterface> maps : this.consumeQueueTable.values()) {
             for (ConsumeQueueInterface logic : maps.values()) {
@@ -256,11 +296,22 @@ public class ConsumeQueueStore {
         return maxPhysicOffset;
     }
 
+    @Override
+    public long getMinOffsetInQueue(String topic, int queueId) {
+        ConsumeQueueInterface logic = findOrCreateConsumeQueue(topic, queueId);
+        if (logic != null) {
+            return logic.getMinOffsetInQueue();
+        }
+
+        return -1;
+    }
+
     public void checkSelf(ConsumeQueueInterface consumeQueue) {
         FileQueueLifeCycle fileQueueLifeCycle = getLifeCycle(consumeQueue.getTopic(), consumeQueue.getQueueId());
         fileQueueLifeCycle.checkSelf();
     }
 
+    @Override
     public void checkSelf() {
         for (Map.Entry<String, ConcurrentMap<Integer, ConsumeQueueInterface>> topicEntry : this.consumeQueueTable.entrySet()) {
             for (Map.Entry<Integer, ConsumeQueueInterface> cqEntry : topicEntry.getValue().entrySet()) {
@@ -269,16 +320,19 @@ public class ConsumeQueueStore {
         }
     }
 
+    @Override
     public boolean flush(ConsumeQueueInterface consumeQueue, int flushLeastPages) {
         FileQueueLifeCycle fileQueueLifeCycle = getLifeCycle(consumeQueue.getTopic(), consumeQueue.getQueueId());
         return fileQueueLifeCycle.flush(flushLeastPages);
     }
 
+    @Override
     public void destroy(ConsumeQueueInterface consumeQueue) {
         FileQueueLifeCycle fileQueueLifeCycle = getLifeCycle(consumeQueue.getTopic(), consumeQueue.getQueueId());
         fileQueueLifeCycle.destroy();
     }
 
+    @Override
     public int deleteExpiredFile(ConsumeQueueInterface consumeQueue, long minCommitLogPos) {
         FileQueueLifeCycle fileQueueLifeCycle = getLifeCycle(consumeQueue.getTopic(), consumeQueue.getQueueId());
         return fileQueueLifeCycle.deleteExpiredFile(minCommitLogPos);
@@ -300,21 +354,20 @@ public class ConsumeQueueStore {
         fileQueueLifeCycle.cleanSwappedMap(forceCleanSwapIntervalMs);
     }
 
+    @Override
     public boolean isFirstFileAvailable(ConsumeQueueInterface consumeQueue) {
         FileQueueLifeCycle fileQueueLifeCycle = getLifeCycle(consumeQueue.getTopic(), consumeQueue.getQueueId());
         return fileQueueLifeCycle.isFirstFileAvailable();
     }
 
+    @Override
     public boolean isFirstFileExist(ConsumeQueueInterface consumeQueue) {
         FileQueueLifeCycle fileQueueLifeCycle = getLifeCycle(consumeQueue.getTopic(), consumeQueue.getQueueId());
         return fileQueueLifeCycle.isFirstFileExist();
     }
 
+    @Override
     public ConsumeQueueInterface findOrCreateConsumeQueue(String topic, int queueId) {
-        return doFindOrCreateConsumeQueue(topic, queueId);
-    }
-
-    private ConsumeQueueInterface doFindOrCreateConsumeQueue(String topic, int queueId) {
         ConcurrentMap<Integer, ConsumeQueueInterface> map = consumeQueueTable.get(topic);
         if (null == map) {
             ConcurrentMap<Integer, ConsumeQueueInterface> newMap = new ConcurrentHashMap<>(128);
@@ -361,46 +414,15 @@ public class ConsumeQueueStore {
         return logic;
     }
 
-    public Long getMaxOffset(String topic, int queueId) {
-        return this.queueOffsetOperator.currentQueueOffset(topic + "-" + queueId);
-    }
-
-    public void setTopicQueueTable(ConcurrentMap<String, Long> topicQueueTable) {
-        this.queueOffsetOperator.setTopicQueueTable(topicQueueTable);
-        this.queueOffsetOperator.setLmqTopicQueueTable(topicQueueTable);
-    }
-
-    public ConcurrentMap getTopicQueueTable() {
-        return this.queueOffsetOperator.getTopicQueueTable();
-    }
-
     public void setBatchTopicQueueTable(ConcurrentMap<String, Long> batchTopicQueueTable) {
         this.queueOffsetOperator.setBatchTopicQueueTable(batchTopicQueueTable);
     }
 
-    public void assignQueueOffset(MessageExtBrokerInner msg) {
-        ConsumeQueueInterface consumeQueue = findOrCreateConsumeQueue(msg.getTopic(), msg.getQueueId());
-        consumeQueue.assignQueueOffset(this.queueOffsetOperator, msg);
-    }
-
-    public void increaseQueueOffset(MessageExtBrokerInner msg, short messageNum) {
-        ConsumeQueueInterface consumeQueue = findOrCreateConsumeQueue(msg.getTopic(), msg.getQueueId());
-        consumeQueue.increaseQueueOffset(this.queueOffsetOperator, msg, messageNum);
-    }
-
     public void updateQueueOffset(String topic, int queueId, long offset) {
         String topicQueueKey = topic + "-" + queueId;
         this.queueOffsetOperator.updateQueueOffset(topicQueueKey, offset);
     }
 
-    public void removeTopicQueueTable(String topic, Integer queueId) {
-        this.queueOffsetOperator.remove(topic, queueId);
-    }
-
-    public ConcurrentMap<String, ConcurrentMap<Integer, ConsumeQueueInterface>> getConsumeQueueTable() {
-        return consumeQueueTable;
-    }
-
     private void putConsumeQueue(final String topic, final int queueId, final ConsumeQueueInterface consumeQueue) {
         ConcurrentMap<Integer/* queueId */, ConsumeQueueInterface> map = this.consumeQueueTable.get(topic);
         if (null == map) {
@@ -412,6 +434,7 @@ public class ConsumeQueueStore {
         }
     }
 
+    @Override
     public void recoverOffsetTable(long minPhyOffset) {
         ConcurrentMap<String, Long> cqOffsetTable = new ConcurrentHashMap<>(1024);
         ConcurrentMap<String, Long> bcqOffsetTable = new ConcurrentHashMap<>(1024);
@@ -431,7 +454,7 @@ public class ConsumeQueueStore {
             }
         }
 
-        //Correct unSubmit consumeOffset
+        // Correct unSubmit consumeOffset
         if (messageStoreConfig.isDuplicationEnable()) {
             SelectMappedBufferResult lastBuffer = null;
             long startReadOffset = messageStore.getCommitLog().getConfirmOffset() == -1 ? 0 : messageStore.getCommitLog().getConfirmOffset();
@@ -476,6 +499,7 @@ public class ConsumeQueueStore {
         this.setBatchTopicQueueTable(bcqOffsetTable);
     }
 
+    @Override
     public void destroy() {
         for (ConcurrentMap<Integer, ConsumeQueueInterface> maps : this.consumeQueueTable.values()) {
             for (ConsumeQueueInterface logic : maps.values()) {
@@ -484,8 +508,9 @@ public class ConsumeQueueStore {
         }
     }
 
+    @Override
     public void cleanExpired(long minCommitLogOffset) {
-        Iterator<Map.Entry<String, ConcurrentMap<Integer, ConsumeQueueInterface>>> it = this.consumeQueueTable.entrySet().iterator();
+        Iterator<Entry<String, ConcurrentMap<Integer, ConsumeQueueInterface>>> it = this.consumeQueueTable.entrySet().iterator();
         while (it.hasNext()) {
             Map.Entry<String, ConcurrentMap<Integer, ConsumeQueueInterface>> next = it.next();
             String topic = next.getKey();
@@ -526,14 +551,16 @@ public class ConsumeQueueStore {
         }
     }
 
-    public void truncateDirty(long phyOffset) {
+    @Override
+    public void truncateDirty(long offsetToTruncate) {
         for (ConcurrentMap<Integer, ConsumeQueueInterface> maps : this.consumeQueueTable.values()) {
             for (ConsumeQueueInterface logic : maps.values()) {
-                this.truncateDirtyLogicFiles(logic, phyOffset);
+                this.truncateDirtyLogicFiles(logic, offsetToTruncate);
             }
         }
     }
 
+    @Override
     public long getTotalSize() {
         long totalSize = 0;
         for (ConcurrentMap<Integer, ConsumeQueueInterface> maps : this.consumeQueueTable.values()) {
diff --git a/store/src/main/java/org/apache/rocketmq/store/queue/ConsumeQueueStoreInterface.java b/store/src/main/java/org/apache/rocketmq/store/queue/ConsumeQueueStoreInterface.java
new file mode 100644
index 000000000..268803dcc
--- /dev/null
+++ b/store/src/main/java/org/apache/rocketmq/store/queue/ConsumeQueueStoreInterface.java
@@ -0,0 +1,289 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.rocketmq.store.queue;
+
+import java.nio.ByteBuffer;
+import java.util.List;
+import java.util.concurrent.ConcurrentMap;
+import org.apache.rocketmq.common.BoundaryType;
+import org.apache.rocketmq.common.message.MessageExtBrokerInner;
+import org.apache.rocketmq.store.DispatchRequest;
+import org.rocksdb.RocksDBException;
+
+public interface ConsumeQueueStoreInterface {
+
+    /**
+     * Start the consumeQueueStore
+     */
+    void start();
+
+    /**
+     * Load from file.
+     * @return true if loaded successfully.
+     */
+    boolean load();
+
+    /**
+     * load after destroy
+     */
+    boolean loadAfterDestroy();
+
+    /**
+     * Recover from file.
+     */
+    void recover();
+
+    /**
+     * Recover concurrently from file.
+     * @return true if recovered successfully.
+     */
+    boolean recoverConcurrently();
+
+    /**
+     * Shutdown the consumeQueueStore
+     * @return true if shutdown successfully.
+     */
+    boolean shutdown();
+
+    /**
+     * destroy all consumeQueues
+     */
+    void destroy();
+
+    /**
+     * destroy the specific consumeQueue
+     * @throws RocksDBException only in rocksdb mode
+     */
+    void destroy(ConsumeQueueInterface consumeQueue) throws RocksDBException;
+
+    /**
+     * Flush cache to file.
+     * @param consumeQueue the consumeQueue will be flushed
+     * @param flushLeastPages  the minimum number of pages to be flushed
+     * @return true if any data has been flushed.
+     */
+    boolean flush(ConsumeQueueInterface consumeQueue, int flushLeastPages);
+
+    /**
+     * clean expired data from minPhyOffset
+     * @param minPhyOffset
+     */
+    void cleanExpired(long minPhyOffset);
+
+    /**
+     * Check files.
+     */
+    void checkSelf();
+
+    /**
+     * Delete expired files ending at min commit log position.
+     * @param consumeQueue
+     * @param minCommitLogPos min commit log position
+     * @return deleted file numbers.
+     */
+    int deleteExpiredFile(ConsumeQueueInterface consumeQueue, long minCommitLogPos);
+
+    /**
+     * Is the first file available?
+     * @param consumeQueue
+     * @return true if it's available
+     */
+    boolean isFirstFileAvailable(ConsumeQueueInterface consumeQueue);
+
+    /**
+     * Does the first file exist?
+     * @param consumeQueue
+     * @return true if it exists
+     */
+    boolean isFirstFileExist(ConsumeQueueInterface consumeQueue);
+
+    /**
+     * Roll to next file.
+     * @param consumeQueue
+     * @param offset next beginning offset
+     * @return the beginning offset of the next file
+     */
+    long rollNextFile(ConsumeQueueInterface consumeQueue, final long offset);
+
+    /**
+     * truncate dirty data
+     * @param offsetToTruncate
+     * @throws RocksDBException only in rocksdb mode
+     */
+    void truncateDirty(long offsetToTruncate) throws RocksDBException;
+
+    /**
+     * Apply the dispatched request and build the consume queue. This function should be idempotent.
+     *
+     * @param consumeQueue consume queue
+     * @param request dispatch request
+     */
+    void putMessagePositionInfoWrapper(ConsumeQueueInterface consumeQueue, DispatchRequest request);
+
+    /**
+     * Apply the dispatched request. This function should be idempotent.
+     *
+     * @param request dispatch request
+     * @throws RocksDBException only in rocksdb mode will throw exception
+     */
+    void putMessagePositionInfoWrapper(DispatchRequest request) throws RocksDBException;
+
+    /**
+     * range query cqUnit(ByteBuffer) in rocksdb
+     * @param topic
+     * @param queueId
+     * @param startIndex
+     * @param num
+     * @return the byteBuffer list of the topic-queueId in rocksdb
+     * @throws RocksDBException only in rocksdb mode
+     */
+    List<ByteBuffer> rangeQuery(final String topic, final int queueId, final long startIndex, final int num) throws RocksDBException;
+
+    /**
+     * query cqUnit(ByteBuffer) in rocksdb
+     * @param topic
+     * @param queueId
+     * @param startIndex
+     * @return the byteBuffer of the topic-queueId in rocksdb
+     * @throws RocksDBException only in rocksdb mode
+     */
+    ByteBuffer get(final String topic, final int queueId, final long startIndex) throws RocksDBException;
+
+    /**
+     * get consumeQueue table
+     * @return the consumeQueue table
+     */
+    ConcurrentMap<String, ConcurrentMap<Integer, ConsumeQueueInterface>> getConsumeQueueTable();
+
+    /**
+     * Assign queue offset.
+     * @param msg message itself
+     * @throws RocksDBException only in rocksdb mode
+     */
+    void assignQueueOffset(MessageExtBrokerInner msg) throws RocksDBException;
+
+    /**
+     * Increase queue offset.
+     * @param msg message itself
+     * @param messageNum message number
+     */
+    void increaseQueueOffset(MessageExtBrokerInner msg, short messageNum);
+
+    /**
+     * recover topicQueue table by minPhyOffset
+     * @param minPhyOffset
+     */
+    void recoverOffsetTable(long minPhyOffset);
+
+    /**
+     * set topicQueue table
+     * @param topicQueueTable
+     */
+    void setTopicQueueTable(ConcurrentMap<String, Long> topicQueueTable);
+
+    /**
+     * remove topic-queueId from topicQueue table
+     * @param topic
+     * @param queueId
+     */
+    void removeTopicQueueTable(String topic, Integer queueId);
+
+    /**
+     * get topicQueue table
+     * @return the topicQueue table
+     */
+    ConcurrentMap getTopicQueueTable();
+
+    /**
+     * get the max physical offset in consumeQueue
+     * @param topic
+     * @param queueId
+     * @return
+     */
+    Long getMaxPhyOffsetInConsumeQueue(String topic, int queueId);
+
+    /**
+     * get maxOffset of specific topic-queueId in topicQueue table
+     * @param topic
+     * @param queueId
+     * @return the max offset in QueueOffsetOperator
+     */
+    Long getMaxOffset(String topic, int queueId);
+
+    /**
+     * get max physic offset in consumeQueue
+     * @return the max physic offset in consumeQueue
+     * @throws RocksDBException only in rocksdb mode
+     */
+    long getMaxPhyOffsetInConsumeQueue() throws RocksDBException;
+
+    /**
+     * get min logic offset of specific topic-queueId in consumeQueue
+     * @param topic
+     * @param queueId
+     * @return the min logic offset of specific topic-queueId in consumeQueue
+     * @throws RocksDBException only in rocksdb mode
+     */
+    long getMinOffsetInQueue(final String topic, final int queueId) throws RocksDBException;
+
+    /**
+     * get max logic offset of specific topic-queueId in consumeQueue
+     * @param topic
+     * @param queueId
+     * @return the max logic offset of specific topic-queueId in consumeQueue
+     * @throws RocksDBException only in rocksdb mode
+     */
+    long getMaxOffsetInQueue(final String topic, final int queueId) throws RocksDBException;
+
+    /**
+     * Get the message whose timestamp is the smallest, greater than or equal to the given time and when there are more
+     * than one message satisfy the condition, decide which one to return based on boundaryType.
+     * @param timestamp    timestamp
+     * @param boundaryType Lower or Upper
+     * @return the offset(index)
+     * @throws RocksDBException only in rocksdb mode
+     */
+    long getOffsetInQueueByTime(String topic, int queueId, long timestamp, BoundaryType boundaryType) throws RocksDBException;
+
+    /**
+     * find or create the consumeQueue
+     * @param topic
+     * @param queueId
+     * @return the consumeQueue
+     */
+    ConsumeQueueInterface findOrCreateConsumeQueue(String topic, int queueId);
+
+    /**
+     * find the consumeQueueMap of topic
+     * @param topic
+     * @return the consumeQueueMap of topic
+     */
+    ConcurrentMap<Integer, ConsumeQueueInterface> findConsumeQueueMap(String topic);
+
+    /**
+     * get the total size of all consumeQueue
+     * @return the total size of all consumeQueue
+     */
+    long getTotalSize();
+
+    /**
+     * Get store time from commitlog by cqUnit
+     * @param cqUnit
+     * @return
+     */
+    long getStoreTime(CqUnit cqUnit);
+}
diff --git a/store/src/main/java/org/apache/rocketmq/store/queue/MultiDispatch.java b/store/src/main/java/org/apache/rocketmq/store/queue/MultiDispatch.java
new file mode 100644
index 000000000..d6291d908
--- /dev/null
+++ b/store/src/main/java/org/apache/rocketmq/store/queue/MultiDispatch.java
@@ -0,0 +1,76 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.rocketmq.store.queue;
+
+import java.util.ArrayList;
+import java.util.List;
+import java.util.Map;
+
+import org.apache.commons.lang3.StringUtils;
+import org.apache.rocketmq.common.MixAll;
+import org.apache.rocketmq.common.message.MessageConst;
+import org.apache.rocketmq.common.topic.TopicValidator;
+import org.apache.rocketmq.store.DispatchRequest;
+import org.apache.rocketmq.store.config.MessageStoreConfig;
+
+public class MultiDispatch {
+
+    public static String lmqQueueKey(String queueName) {
+        StringBuilder keyBuilder = new StringBuilder();
+        keyBuilder.append(queueName);
+        keyBuilder.append('-');
+        int queueId = 0;
+        keyBuilder.append(queueId);
+        return keyBuilder.toString();
+    }
+
+    public static boolean isNeedHandleMultiDispatch(MessageStoreConfig messageStoreConfig, String topic) {
+        return messageStoreConfig.isEnableMultiDispatch()
+            && !topic.startsWith(MixAll.RETRY_GROUP_TOPIC_PREFIX)
+            && !topic.startsWith(TopicValidator.SYSTEM_TOPIC_PREFIX)
+            && !topic.equals(TopicValidator.RMQ_SYS_SCHEDULE_TOPIC);
+    }
+
+    public static boolean checkMultiDispatchQueue(MessageStoreConfig messageStoreConfig, DispatchRequest dispatchRequest) {
+        if (!isNeedHandleMultiDispatch(messageStoreConfig, dispatchRequest.getTopic())) {
+            return false;
+        }
+        Map<String, String> prop = dispatchRequest.getPropertiesMap();
+        if (prop == null || prop.isEmpty()) {
+            return false;
+        }
+        String multiDispatchQueue = prop.get(MessageConst.PROPERTY_INNER_MULTI_DISPATCH);
+        String multiQueueOffset = prop.get(MessageConst.PROPERTY_INNER_MULTI_QUEUE_OFFSET);
+        if (StringUtils.isBlank(multiDispatchQueue) || StringUtils.isBlank(multiQueueOffset)) {
+            return false;
+        }
+        return true;
+    }
+
+    public static List<DispatchRequest> checkMultiDispatchQueue(MessageStoreConfig messageStoreConfig, List<DispatchRequest> dispatchRequests) {
+        if (!messageStoreConfig.isEnableMultiDispatch() || dispatchRequests == null || dispatchRequests.size() == 0) {
+            return null;
+        }
+        List<DispatchRequest> result = new ArrayList<>();
+        for (DispatchRequest dispatchRequest : dispatchRequests) {
+            if (checkMultiDispatchQueue(messageStoreConfig, dispatchRequest)) {
+                result.add(dispatchRequest);
+            }
+        }
+        return dispatchRequests;
+    }
+}
diff --git a/store/src/main/java/org/apache/rocketmq/store/queue/QueueOffsetOperator.java b/store/src/main/java/org/apache/rocketmq/store/queue/QueueOffsetOperator.java
index 2545bbf52..8da374828 100644
--- a/store/src/main/java/org/apache/rocketmq/store/queue/QueueOffsetOperator.java
+++ b/store/src/main/java/org/apache/rocketmq/store/queue/QueueOffsetOperator.java
@@ -41,6 +41,10 @@ public class QueueOffsetOperator {
         return ConcurrentHashMapUtils.computeIfAbsent(this.topicQueueTable, topicQueueKey, k -> 0L);
     }
 
+    public Long getTopicQueueNextOffset(String topicQueueKey) {
+        return this.topicQueueTable.get(topicQueueKey);
+    }
+
     public void increaseQueueOffset(String topicQueueKey, short messageNum) {
         Long queueOffset = ConcurrentHashMapUtils.computeIfAbsent(this.topicQueueTable, topicQueueKey, k -> 0L);
         topicQueueTable.put(topicQueueKey, queueOffset + messageNum);
@@ -63,6 +67,10 @@ public class QueueOffsetOperator {
         return ConcurrentHashMapUtils.computeIfAbsent(this.lmqTopicQueueTable, topicQueueKey, k -> 0L);
     }
 
+    public Long getLmqTopicQueueNextOffset(String topicQueueKey) {
+        return this.lmqTopicQueueTable.get(topicQueueKey);
+    }
+
     public void increaseLmqOffset(String topicQueueKey, short messageNum) {
         Long lmqOffset = ConcurrentHashMapUtils.computeIfAbsent(this.lmqTopicQueueTable, topicQueueKey, k -> 0L);
         this.lmqTopicQueueTable.put(topicQueueKey, lmqOffset + messageNum);
diff --git a/store/src/main/java/org/apache/rocketmq/store/queue/RocksDBConsumeQueue.java b/store/src/main/java/org/apache/rocketmq/store/queue/RocksDBConsumeQueue.java
new file mode 100644
index 000000000..759be395d
--- /dev/null
+++ b/store/src/main/java/org/apache/rocketmq/store/queue/RocksDBConsumeQueue.java
@@ -0,0 +1,437 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.rocketmq.store.queue;
+
+import java.nio.ByteBuffer;
+import java.util.List;
+
+import org.apache.commons.lang3.StringUtils;
+import org.apache.rocketmq.common.BoundaryType;
+import org.apache.rocketmq.common.MixAll;
+import org.apache.rocketmq.common.Pair;
+import org.apache.rocketmq.common.attribute.CQType;
+import org.apache.rocketmq.common.constant.LoggerName;
+import org.apache.rocketmq.common.message.MessageAccessor;
+import org.apache.rocketmq.common.message.MessageConst;
+import org.apache.rocketmq.common.message.MessageExtBrokerInner;
+import org.apache.rocketmq.logging.org.slf4j.Logger;
+import org.apache.rocketmq.logging.org.slf4j.LoggerFactory;
+import org.apache.rocketmq.store.ConsumeQueue;
+import org.apache.rocketmq.store.DispatchRequest;
+import org.apache.rocketmq.store.MessageFilter;
+import org.apache.rocketmq.store.MessageStore;
+import org.rocksdb.RocksDBException;
+
+public class RocksDBConsumeQueue implements ConsumeQueueInterface {
+    private static final Logger log = LoggerFactory.getLogger(LoggerName.STORE_LOGGER_NAME);
+    private static final Logger ERROR_LOG = LoggerFactory.getLogger(LoggerName.STORE_ERROR_LOGGER_NAME);
+
+    private final MessageStore messageStore;
+    private final String topic;
+    private final int queueId;
+
+    public RocksDBConsumeQueue(final MessageStore messageStore, final String topic, final int queueId) {
+        this.messageStore = messageStore;
+        this.topic = topic;
+        this.queueId = queueId;
+    }
+
+    public RocksDBConsumeQueue(final String topic, final int queueId) {
+        this.messageStore = null;
+        this.topic = topic;
+        this.queueId = queueId;
+    }
+
+    @Override
+    public boolean load() {
+        return true;
+    }
+
+    @Override
+    public void recover() {
+        // ignore
+    }
+
+    @Override
+    public void checkSelf() {
+        // ignore
+    }
+
+    @Override
+    public boolean flush(final int flushLeastPages) {
+        return true;
+    }
+
+    @Override
+    public void destroy() {
+        // ignore
+    }
+
+    @Override
+    public void truncateDirtyLogicFiles(long maxCommitLogPos) {
+        // ignored
+    }
+
+    @Override
+    public int deleteExpiredFile(long minCommitLogPos) {
+        return 0;
+    }
+
+    @Override
+    public long rollNextFile(long nextBeginOffset) {
+        return 0;
+    }
+
+    @Override
+    public boolean isFirstFileAvailable() {
+        return true;
+    }
+
+    @Override
+    public boolean isFirstFileExist() {
+        return true;
+    }
+
+    @Override
+    public void swapMap(int reserveNum, long forceSwapIntervalMs, long normalSwapIntervalMs) {
+        // ignore
+    }
+
+    @Override
+    public void cleanSwappedMap(long forceCleanSwapIntervalMs) {
+        // ignore
+    }
+
+    @Override
+    public long getMaxOffsetInQueue() {
+        try {
+            return this.messageStore.getQueueStore().getMaxOffsetInQueue(topic, queueId);
+        } catch (RocksDBException e) {
+            ERROR_LOG.error("getMaxOffsetInQueue Failed. topic: {}, queueId: {}", topic, queueId, e);
+            return 0;
+        }
+    }
+
+    @Override
+    public long getMessageTotalInQueue() {
+        try {
+            long maxOffsetInQueue = this.messageStore.getQueueStore().getMaxOffsetInQueue(topic, queueId);
+            long minOffsetInQueue = this.messageStore.getQueueStore().getMinOffsetInQueue(topic, queueId);
+            return maxOffsetInQueue - minOffsetInQueue;
+        } catch (RocksDBException e) {
+            ERROR_LOG.error("getMessageTotalInQueue Failed. topic: {}, queueId: {}, {}", topic, queueId, e);
+        }
+        return -1;
+    }
+
+    /**
+     * We already implement it in RocksDBConsumeQueueStore.
+     * @see RocksDBConsumeQueueStore#getOffsetInQueueByTime
+     * @param timestamp timestamp
+     * @return
+     */
+    @Override
+    public long getOffsetInQueueByTime(long timestamp) {
+        return 0;
+    }
+
+    /**
+     * We already implement it in RocksDBConsumeQueueStore.
+     * @see RocksDBConsumeQueueStore#getOffsetInQueueByTime
+     * @param timestamp    timestamp
+     * @param boundaryType Lower or Upper
+     * @return
+     */
+    @Override
+    public long getOffsetInQueueByTime(long timestamp, BoundaryType boundaryType) {
+        return 0;
+    }
+
+    @Override
+    public long getMaxPhysicOffset() {
+        Long maxPhyOffset = this.messageStore.getQueueStore().getMaxPhyOffsetInConsumeQueue(topic, queueId);
+        return maxPhyOffset == null ? -1 : maxPhyOffset;
+    }
+
+    @Override
+    public long getMinLogicOffset() {
+        return 0;
+    }
+
+    @Override
+    public CQType getCQType() {
+        return CQType.RocksDBCQ;
+    }
+
+    @Override
+    public long getTotalSize() {
+        // ignored
+        return 0;
+    }
+
+    @Override
+    public int getUnitSize() {
+        // attention: unitSize should equal to 'ConsumeQueue.CQ_STORE_UNIT_SIZE'
+        return ConsumeQueue.CQ_STORE_UNIT_SIZE;
+    }
+
+    /**
+     * Ignored, we already implement this method
+     * @see org.apache.rocketmq.store.queue.RocksDBConsumeQueueOffsetTable#getMinCqOffset(String, int)
+     */
+    @Override
+    public void correctMinOffset(long minCommitLogOffset) {
+
+    }
+
+    /**
+     * Ignored, in rocksdb mode, we build cq in RocksDBConsumeQueueStore
+     * @see org.apache.rocketmq.store.queue.RocksDBConsumeQueueStore#putMessagePosition()
+     */
+    @Override
+    public void putMessagePositionInfoWrapper(DispatchRequest request) {
+
+    }
+
+    @Override
+    public void assignQueueOffset(QueueOffsetOperator queueOffsetOperator, MessageExtBrokerInner msg) throws RocksDBException {
+        String topicQueueKey = getTopic() + "-" + getQueueId();
+        Long queueOffset = queueOffsetOperator.getTopicQueueNextOffset(topicQueueKey);
+        if (queueOffset == null) {
+            // we will recover topic queue table from rocksdb when we use it.
+            queueOffset = this.messageStore.getQueueStore().getMaxOffsetInQueue(topic, queueId);
+            queueOffsetOperator.updateQueueOffset(topicQueueKey, queueOffset);
+        }
+        msg.setQueueOffset(queueOffset);
+
+        // Handling the multi dispatch message. In the context of a light message queue (as defined in RIP-28),
+        // light message queues are constructed based on message properties, which requires special handling of queue offset of the light message queue.
+        if (!MultiDispatch.isNeedHandleMultiDispatch(this.messageStore.getMessageStoreConfig(), msg.getTopic())) {
+            return;
+        }
+        String multiDispatchQueue = msg.getProperty(MessageConst.PROPERTY_INNER_MULTI_DISPATCH);
+        if (StringUtils.isBlank(multiDispatchQueue)) {
+            return;
+        }
+        String[] queues = multiDispatchQueue.split(MixAll.MULTI_DISPATCH_QUEUE_SPLITTER);
+        Long[] queueOffsets = new Long[queues.length];
+        for (int i = 0; i < queues.length; i++) {
+            if (this.messageStore.getMessageStoreConfig().isEnableLmq() && MixAll.isLmq(queues[i])) {
+                String key = MultiDispatch.lmqQueueKey(queues[i]);
+                queueOffsets[i] = queueOffsetOperator.getLmqTopicQueueNextOffset(key);
+            }
+        }
+        MessageAccessor.putProperty(msg, MessageConst.PROPERTY_INNER_MULTI_QUEUE_OFFSET,
+            StringUtils.join(queueOffsets, MixAll.MULTI_DISPATCH_QUEUE_SPLITTER));
+        msg.removeWaitStorePropertyString();
+    }
+
+    @Override
+    public void increaseQueueOffset(QueueOffsetOperator queueOffsetOperator, MessageExtBrokerInner msg, short messageNum) {
+        String topicQueueKey = getTopic() + "-" + getQueueId();
+        queueOffsetOperator.increaseQueueOffset(topicQueueKey, messageNum);
+
+        // Handling the multi dispatch message. In the context of a light message queue (as defined in RIP-28),
+        // light message queues are constructed based on message properties, which requires special handling of queue offset of the light message queue.
+        if (!MultiDispatch.isNeedHandleMultiDispatch(this.messageStore.getMessageStoreConfig(), msg.getTopic())) {
+            return;
+        }
+        String multiDispatchQueue = msg.getProperty(MessageConst.PROPERTY_INNER_MULTI_DISPATCH);
+        if (StringUtils.isBlank(multiDispatchQueue)) {
+            return;
+        }
+        String[] queues = multiDispatchQueue.split(MixAll.MULTI_DISPATCH_QUEUE_SPLITTER);
+        for (int i = 0; i < queues.length; i++) {
+            if (this.messageStore.getMessageStoreConfig().isEnableLmq() && MixAll.isLmq(queues[i])) {
+                String key = MultiDispatch.lmqQueueKey(queues[i]);
+                queueOffsetOperator.increaseLmqOffset(key, (short) 1);
+            }
+        }
+    }
+
+    @Override
+    public long estimateMessageCount(long from, long to, MessageFilter filter) {
+        // todo
+        return 0;
+    }
+
+    @Override
+    public long getMinOffsetInQueue() {
+        return this.messageStore.getMinOffsetInQueue(this.topic, this.queueId);
+    }
+
+    private int pullNum(long cqOffset, long maxCqOffset) {
+        long diffLong = maxCqOffset - cqOffset;
+        if (diffLong < Integer.MAX_VALUE) {
+            int diffInt = (int) diffLong;
+            return diffInt > 16 ? 16 : diffInt;
+        }
+        return 16;
+    }
+
+    @Override
+    public ReferredIterator<CqUnit> iterateFrom(final long startIndex) {
+        try {
+            long maxCqOffset = getMaxOffsetInQueue();
+            if (startIndex < maxCqOffset) {
+                int num = pullNum(startIndex, maxCqOffset);
+                return iterateFrom0(startIndex, num);
+            }
+        } catch (RocksDBException e) {
+            log.error("[RocksDBConsumeQueue] iterateFrom error!", e);
+        }
+        return null;
+    }
+
+    @Override
+    public ReferredIterator<CqUnit> iterateFrom(long startIndex, int count) throws RocksDBException {
+        long maxCqOffset = getMaxOffsetInQueue();
+        if (startIndex < maxCqOffset) {
+            int num = Math.min((int)(maxCqOffset - startIndex), count);
+            return iterateFrom0(startIndex, num);
+        }
+        return null;
+    }
+
+    @Override
+    public CqUnit get(long index) {
+        Pair<CqUnit, Long> pair = getCqUnitAndStoreTime(index);
+        return pair == null ? null : pair.getObject1();
+    }
+
+    @Override
+    public Pair<CqUnit, Long> getCqUnitAndStoreTime(long index) {
+        ByteBuffer byteBuffer;
+        try {
+            byteBuffer = this.messageStore.getQueueStore().get(topic, queueId, index);
+        } catch (RocksDBException e) {
+            ERROR_LOG.error("getUnitAndStoreTime Failed. topic: {}, queueId: {}", topic, queueId, e);
+            return null;
+        }
+        if (byteBuffer == null || byteBuffer.remaining() < RocksDBConsumeQueueTable.CQ_UNIT_SIZE) {
+            return null;
+        }
+        long phyOffset = byteBuffer.getLong();
+        int size = byteBuffer.getInt();
+        long tagCode = byteBuffer.getLong();
+        long messageStoreTime = byteBuffer.getLong();
+        return new Pair<>(new CqUnit(index, phyOffset, size, tagCode), messageStoreTime);
+    }
+
+    @Override
+    public Pair<CqUnit, Long> getEarliestUnitAndStoreTime() {
+        try {
+            long minOffset = this.messageStore.getQueueStore().getMinOffsetInQueue(topic, queueId);
+            return getCqUnitAndStoreTime(minOffset);
+        } catch (RocksDBException e) {
+            ERROR_LOG.error("getEarliestUnitAndStoreTime Failed. topic: {}, queueId: {}", topic, queueId, e);
+        }
+        return null;
+    }
+
+    @Override
+    public CqUnit getEarliestUnit() {
+        Pair<CqUnit, Long> pair = getEarliestUnitAndStoreTime();
+        return pair == null ? null : pair.getObject1();
+    }
+
+    @Override
+    public CqUnit getLatestUnit() {
+        try {
+            long maxOffset = this.messageStore.getQueueStore().getMaxOffsetInQueue(topic, queueId);
+            return get(maxOffset);
+        } catch (RocksDBException e) {
+            ERROR_LOG.error("getLatestUnit Failed. topic: {}, queueId: {}, {}", topic, queueId, e.getMessage());
+        }
+        return null;
+    }
+
+    @Override
+    public long getLastOffset() {
+        return getMaxPhysicOffset();
+    }
+
+    private ReferredIterator<CqUnit> iterateFrom0(final long startIndex, final int count) throws RocksDBException {
+        List<ByteBuffer> byteBufferList = this.messageStore.getQueueStore().rangeQuery(topic, queueId, startIndex, count);
+        if (byteBufferList == null || byteBufferList.isEmpty()) {
+            if (this.messageStore.getMessageStoreConfig().isEnableRocksDBLog()) {
+                log.warn("iterateFrom0 - find nothing, startIndex:{}, count:{}", startIndex, count);
+            }
+            return null;
+        }
+        return new RocksDBConsumeQueueIterator(byteBufferList, startIndex);
+    }
+
+    @Override
+    public String getTopic() {
+        return topic;
+    }
+
+    @Override
+    public int getQueueId() {
+        return queueId;
+    }
+
+    private class RocksDBConsumeQueueIterator implements ReferredIterator<CqUnit> {
+        private final List<ByteBuffer> byteBufferList;
+        private final long startIndex;
+        private final int totalCount;
+        private int currentIndex;
+
+        public RocksDBConsumeQueueIterator(final List<ByteBuffer> byteBufferList, final long startIndex) {
+            this.byteBufferList = byteBufferList;
+            this.startIndex = startIndex;
+            this.totalCount = byteBufferList.size();
+            this.currentIndex = 0;
+        }
+
+        @Override
+        public boolean hasNext() {
+            return this.currentIndex < this.totalCount;
+        }
+
+        @Override
+        public CqUnit next() {
+            if (!hasNext()) {
+                return null;
+            }
+            final int currentIndex = this.currentIndex;
+            final ByteBuffer byteBuffer = this.byteBufferList.get(currentIndex);
+            CqUnit cqUnit = new CqUnit(this.startIndex + currentIndex, byteBuffer.getLong(), byteBuffer.getInt(), byteBuffer.getLong());
+            this.currentIndex++;
+            return cqUnit;
+        }
+
+        @Override
+        public void remove() {
+            throw new UnsupportedOperationException("remove");
+        }
+
+        @Override
+        public void release() {
+        }
+
+        @Override
+        public CqUnit nextAndRelease() {
+            try {
+                return next();
+            } finally {
+                release();
+            }
+        }
+    }
+}
diff --git a/store/src/main/java/org/apache/rocketmq/store/queue/RocksDBConsumeQueueOffsetTable.java b/store/src/main/java/org/apache/rocketmq/store/queue/RocksDBConsumeQueueOffsetTable.java
new file mode 100644
index 000000000..6fa66282e
--- /dev/null
+++ b/store/src/main/java/org/apache/rocketmq/store/queue/RocksDBConsumeQueueOffsetTable.java
@@ -0,0 +1,641 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.rocketmq.store.queue;
+
+import java.nio.ByteBuffer;
+import java.util.HashMap;
+import java.util.HashSet;
+import java.util.Map;
+import java.util.Set;
+import java.util.concurrent.ConcurrentHashMap;
+import java.util.concurrent.ConcurrentMap;
+
+import org.apache.rocketmq.common.Pair;
+import org.apache.rocketmq.common.TopicConfig;
+import org.apache.rocketmq.common.constant.LoggerName;
+import org.apache.rocketmq.common.topic.TopicValidator;
+import org.apache.rocketmq.logging.org.slf4j.Logger;
+import org.apache.rocketmq.logging.org.slf4j.LoggerFactory;
+import org.apache.rocketmq.store.ConsumeQueue;
+import org.apache.rocketmq.store.DefaultMessageStore;
+import org.apache.rocketmq.store.DispatchRequest;
+import org.apache.rocketmq.store.rocksdb.ConsumeQueueRocksDBStorage;
+import org.rocksdb.ColumnFamilyHandle;
+import org.rocksdb.RocksDBException;
+import org.rocksdb.RocksIterator;
+import org.rocksdb.WriteBatch;
+
+import static org.apache.rocketmq.common.utils.DataConverter.CHARSET_UTF8;
+import static org.apache.rocketmq.store.queue.RocksDBConsumeQueueStore.CTRL_1;
+
+public class RocksDBConsumeQueueOffsetTable {
+    private static final Logger log = LoggerFactory.getLogger(LoggerName.STORE_LOGGER_NAME);
+    private static final Logger ERROR_LOG = LoggerFactory.getLogger(LoggerName.STORE_ERROR_LOGGER_NAME);
+    private static final Logger ROCKSDB_LOG = LoggerFactory.getLogger(LoggerName.ROCKSDB_LOGGER_NAME);
+
+    private static final byte[] MAX_BYTES = "max".getBytes(CHARSET_UTF8);
+    private static final byte[] MIN_BYTES = "min".getBytes(CHARSET_UTF8);
+
+    /**
+     * Rocksdb ConsumeQueue's Offset unit. Format:
+     *
+     * <pre>
+     * 
+     *  Topic Bytes Array Size    CTRL_1      Topic Bytes Array     CTRL_1     Max(Min)   CTRL_1      QueueId   
+     *         (4 Bytes)         (1 Bytes)        (n Bytes)        (1 Bytes)  (3 Bytes)  (1 Bytes)   (4 Bytes)  
+     * 
+     *                                                     Key Unit                                                   
+     *                                                                                                                
+     * </pre>
+     *
+     * <pre>
+     * 
+     *   CommitLog Physical Offset     ConsumeQueue Offset  
+     *         (8 Bytes)                (8 Bytes)           
+     * 
+     *                      Value Unit                       
+     *                                                       
+     * </pre>
+     * ConsumeQueue's Offset unit. Size: CommitLog Physical Offset(8) + ConsumeQueue Offset(8) =  16 Bytes
+     */
+    private static final int OFFSET_PHY_OFFSET = 0;
+    private static final int OFFSET_CQ_OFFSET = 8;
+    /**
+     *
+     * 
+     *  Topic Bytes Array Size    CTRL_1     CTRL_1     Max(Min)   CTRL_1      QueueId   
+     *         (4 Bytes)         (1 Bytes)  (1 Bytes)  (3 Bytes)  (1 Bytes)   (4 Bytes)  
+     * 
+     */
+    private static final int OFFSET_KEY_LENGTH_WITHOUT_TOPIC_BYTES = 4 + 1 + 1 + 3 + 1 + 4;
+    private static final int OFFSET_VALUE_LENGTH = 8 + 8;
+
+    /**
+     * We use a new system topic='CHECKPOINT_TOPIC' to record the maxPhyOffset built by CQ dispatch thread.
+     * @see ConsumeQueueStore#getMaxPhyOffsetInConsumeQueue(), we use it to find the maxPhyOffset built by CQ dispatch thread.
+     * If we do not record the maxPhyOffset, it may take us a long time to start traversing from the head of
+     * RocksDBConsumeQueueOffsetTable to find it.
+     */
+    private static final String MAX_PHYSICAL_OFFSET_CHECKPOINT = TopicValidator.RMQ_SYS_ROCKSDB_OFFSET_TOPIC;
+    private static final byte[] MAX_PHYSICAL_OFFSET_CHECKPOINT_BYTES = MAX_PHYSICAL_OFFSET_CHECKPOINT.getBytes(CHARSET_UTF8);
+    private static final int INNER_CHECKPOINT_TOPIC_LEN = OFFSET_KEY_LENGTH_WITHOUT_TOPIC_BYTES + MAX_PHYSICAL_OFFSET_CHECKPOINT_BYTES.length;
+    private static final ByteBuffer INNER_CHECKPOINT_TOPIC = ByteBuffer.allocateDirect(INNER_CHECKPOINT_TOPIC_LEN);
+    private static final byte[] MAX_PHYSICAL_OFFSET_CHECKPOINT_KEY = new byte[INNER_CHECKPOINT_TOPIC_LEN];
+    private final ByteBuffer maxPhyOffsetBB;
+    static {
+        buildOffsetKeyByteBuffer0(INNER_CHECKPOINT_TOPIC, MAX_PHYSICAL_OFFSET_CHECKPOINT_BYTES, 0, true);
+        INNER_CHECKPOINT_TOPIC.position(0).limit(INNER_CHECKPOINT_TOPIC_LEN);
+        INNER_CHECKPOINT_TOPIC.get(MAX_PHYSICAL_OFFSET_CHECKPOINT_KEY);
+    }
+
+    private final RocksDBConsumeQueueTable rocksDBConsumeQueueTable;
+    private final ConsumeQueueRocksDBStorage rocksDBStorage;
+    private final DefaultMessageStore messageStore;
+
+    private ColumnFamilyHandle offsetCFH;
+
+    /**
+     * Although we have already put max(min) consumeQueueOffset and physicalOffset in rocksdb, we still hope to get them
+     * from heap to avoid accessing rocksdb.
+     * @see ConsumeQueue#getMaxPhysicOffset(), maxPhysicOffset  --> topicQueueMaxCqOffset
+     * @see ConsumeQueue#getMinLogicOffset(),   minLogicOffset  --> topicQueueMinOffset
+     */
+    private final Map<String/* topic-queueId */, PhyAndCQOffset> topicQueueMinOffset;
+    private final Map<String/* topic-queueId */, Long> topicQueueMaxCqOffset;
+
+    public RocksDBConsumeQueueOffsetTable(RocksDBConsumeQueueTable rocksDBConsumeQueueTable,
+        ConsumeQueueRocksDBStorage rocksDBStorage, DefaultMessageStore messageStore) {
+        this.rocksDBConsumeQueueTable = rocksDBConsumeQueueTable;
+        this.rocksDBStorage = rocksDBStorage;
+        this.messageStore = messageStore;
+        this.topicQueueMinOffset = new ConcurrentHashMap(1024);
+        this.topicQueueMaxCqOffset = new ConcurrentHashMap(1024);
+
+        this.maxPhyOffsetBB = ByteBuffer.allocateDirect(8);
+    }
+
+    public void load() {
+        this.offsetCFH = this.rocksDBStorage.getOffsetCFHandle();
+    }
+
+    public void updateTempTopicQueueMaxOffset(final Pair<ByteBuffer, ByteBuffer> offsetBBPair,
+        final byte[] topicBytes, final DispatchRequest request,
+        final Map<ByteBuffer, Pair<ByteBuffer, DispatchRequest>> tempTopicQueueMaxOffsetMap) {
+        buildOffsetKeyAndValueByteBuffer(offsetBBPair, topicBytes, request);
+        ByteBuffer topicQueueId = offsetBBPair.getObject1();
+        ByteBuffer maxOffsetBB = offsetBBPair.getObject2();
+        Pair<ByteBuffer, DispatchRequest> old = tempTopicQueueMaxOffsetMap.get(topicQueueId);
+        if (old == null) {
+            tempTopicQueueMaxOffsetMap.put(topicQueueId, new Pair(maxOffsetBB, request));
+        } else {
+            long oldMaxOffset = old.getObject1().getLong(OFFSET_CQ_OFFSET);
+            long maxOffset = maxOffsetBB.getLong(OFFSET_CQ_OFFSET);
+            if (maxOffset >= oldMaxOffset) {
+                ERROR_LOG.error("cqOffset invalid1. old: {}, now: {}", oldMaxOffset, maxOffset);
+            }
+        }
+    }
+
+    public void putMaxPhyAndCqOffset(final Map<ByteBuffer, Pair<ByteBuffer, DispatchRequest>> tempTopicQueueMaxOffsetMap,
+        final WriteBatch writeBatch, final long maxPhyOffset) throws RocksDBException {
+        for (Map.Entry<ByteBuffer, Pair<ByteBuffer, DispatchRequest>> entry : tempTopicQueueMaxOffsetMap.entrySet()) {
+            writeBatch.put(this.offsetCFH, entry.getKey(), entry.getValue().getObject1());
+        }
+
+        appendMaxPhyOffset(writeBatch, maxPhyOffset);
+    }
+
+    public void putHeapMaxCqOffset(final Map<ByteBuffer, Pair<ByteBuffer, DispatchRequest>> tempTopicQueueMaxOffsetMap) {
+        for (Map.Entry<ByteBuffer, Pair<ByteBuffer, DispatchRequest>> entry : tempTopicQueueMaxOffsetMap.entrySet()) {
+            DispatchRequest request = entry.getValue().getObject2();
+            putHeapMaxCqOffset(request.getTopic(), request.getQueueId(), request.getConsumeQueueOffset());
+        }
+    }
+
+    /**
+     * When topic is deleted, we clean up its offset info in rocksdb.
+     * @param topic
+     * @param queueId
+     * @throws RocksDBException
+     */
+    public void destroyOffset(String topic, int queueId, WriteBatch writeBatch) throws RocksDBException {
+        final byte[] topicBytes = topic.getBytes(CHARSET_UTF8);
+        final ByteBuffer minOffsetKey = buildOffsetKeyByteBuffer(topicBytes, queueId, false);
+        byte[] minOffsetBytes = this.rocksDBStorage.getOffset(minOffsetKey.array());
+        Long startCQOffset = (minOffsetBytes != null) ? ByteBuffer.wrap(minOffsetBytes).getLong(OFFSET_CQ_OFFSET) : null;
+
+        final ByteBuffer maxOffsetKey = buildOffsetKeyByteBuffer(topicBytes, queueId, true);
+        byte[] maxOffsetBytes = this.rocksDBStorage.getOffset(maxOffsetKey.array());
+        Long endCQOffset = (maxOffsetBytes != null) ? ByteBuffer.wrap(maxOffsetBytes).getLong(OFFSET_CQ_OFFSET) : null;
+
+        writeBatch.delete(this.offsetCFH, minOffsetKey.array());
+        writeBatch.delete(this.offsetCFH, maxOffsetKey.array());
+
+        String topicQueueId = buildTopicQueueId(topic, queueId);
+        removeHeapMinCqOffset(topicQueueId);
+        removeHeapMaxCqOffset(topicQueueId);
+
+        log.info("RocksDB offset table delete topic: {}, queueId: {}, minOffset: {}, maxOffset: {}", topic, queueId,
+            startCQOffset, endCQOffset);
+    }
+
+    private void appendMaxPhyOffset(final WriteBatch writeBatch, final long maxPhyOffset) throws RocksDBException {
+        final ByteBuffer maxPhyOffsetBB = this.maxPhyOffsetBB;
+        maxPhyOffsetBB.position(0).limit(8);
+        maxPhyOffsetBB.putLong(maxPhyOffset);
+        maxPhyOffsetBB.flip();
+
+        INNER_CHECKPOINT_TOPIC.position(0).limit(INNER_CHECKPOINT_TOPIC_LEN);
+        writeBatch.put(this.offsetCFH, INNER_CHECKPOINT_TOPIC, maxPhyOffsetBB);
+    }
+
+    public long getMaxPhyOffset() throws RocksDBException {
+        byte[] valueBytes = this.rocksDBStorage.getOffset(MAX_PHYSICAL_OFFSET_CHECKPOINT_KEY);
+        if (valueBytes == null) {
+            return 0;
+        }
+        ByteBuffer valueBB = ByteBuffer.wrap(valueBytes);
+        return valueBB.getLong(0);
+    }
+
+    /**
+     * Traverse the offset table to find dirty topic
+     * @param existTopicSet
+     * @return
+     */
+    public Map<String, Set<Integer>> iterateOffsetTable2FindDirty(final Set<String> existTopicSet) {
+        Map<String/* topic */, Set<Integer/* queueId */>> topicQueueIdToBeDeletedMap = new HashMap<>();
+
+        RocksIterator iterator = null;
+        try {
+            iterator = rocksDBStorage.seekOffsetCF();
+            if (iterator == null) {
+                return topicQueueIdToBeDeletedMap;
+            }
+            for (iterator.seekToFirst(); iterator.isValid(); iterator.next()) {
+                byte[] key = iterator.key();
+                byte[] value = iterator.value();
+                if (key == null || key.length <= OFFSET_KEY_LENGTH_WITHOUT_TOPIC_BYTES
+                    || value == null || value.length != OFFSET_VALUE_LENGTH) {
+                    continue;
+                }
+                ByteBuffer keyBB = ByteBuffer.wrap(key);
+                int topicLen = keyBB.getInt(0);
+                byte[] topicBytes = new byte[topicLen];
+                /**
+                 * "Topic Bytes Array Size" + "CTRL_1" = 4 + 1
+                 */
+                keyBB.position(4 + 1);
+                keyBB.get(topicBytes);
+                String topic = new String(topicBytes, CHARSET_UTF8);
+                if (TopicValidator.isSystemTopic(topic)) {
+                    continue;
+                }
+
+                /**
+                 * "Topic Bytes Array Size" + "CTRL_1" + "Topic Bytes Array" + "CTRL_1"  + "Max(min)" + "CTRL_1"
+                 *  = 4 + 1 + topicLen + 1 + 3 + 1
+                 */
+                int queueId = keyBB.getInt(4 + 1 + topicLen + 1 + 3 + 1);
+
+                if (!existTopicSet.contains(topic)) {
+                    ByteBuffer valueBB = ByteBuffer.wrap(value);
+                    long cqOffset = valueBB.getLong(OFFSET_CQ_OFFSET);
+
+                    Set<Integer> topicQueueIdSet = topicQueueIdToBeDeletedMap.get(topic);
+                    if (topicQueueIdSet == null) {
+                        Set<Integer> newSet = new HashSet<>();
+                        newSet.add(queueId);
+                        topicQueueIdToBeDeletedMap.put(topic, newSet);
+                    } else {
+                        topicQueueIdSet.add(queueId);
+                    }
+                    ERROR_LOG.info("RocksDBConsumeQueueOffsetTable has dirty cqOffset. topic: {}, queueId: {}, cqOffset: {}",
+                        topic, queueId, cqOffset);
+                }
+            }
+        } catch (Exception e) {
+            ERROR_LOG.error("iterateOffsetTable2MarkDirtyCQ Failed.", e);
+        } finally {
+            if (iterator != null) {
+                iterator.close();
+            }
+        }
+        return topicQueueIdToBeDeletedMap;
+    }
+
+    public Long getMaxCqOffset(String topic, int queueId) throws RocksDBException {
+        Long maxCqOffset = getHeapMaxCqOffset(topic, queueId);
+
+        if (maxCqOffset == null) {
+            final ByteBuffer byteBuffer = getMaxPhyAndCqOffsetInKV(topic, queueId);
+            maxCqOffset = (byteBuffer != null) ? byteBuffer.getLong(OFFSET_CQ_OFFSET) : null;
+            String topicQueueId = buildTopicQueueId(topic, queueId);
+            this.topicQueueMaxCqOffset.putIfAbsent(topicQueueId, maxCqOffset != null ? maxCqOffset : -1L);
+            if (messageStore.getMessageStoreConfig().isEnableRocksDBLog()) {
+                ROCKSDB_LOG.warn("updateMaxOffsetInQueue. {}, {}", topicQueueId, maxCqOffset);
+            }
+        }
+
+        return maxCqOffset;
+    }
+
+    /**
+     * truncate dirty offset in rocksdb
+     * @param offsetToTruncate
+     * @throws RocksDBException
+     */
+    public void truncateDirty(long offsetToTruncate) throws RocksDBException {
+        correctMaxPyhOffset(offsetToTruncate);
+
+        ConcurrentMap<String, TopicConfig> allTopicConfigMap = this.messageStore.getTopicConfigs();
+        if (allTopicConfigMap == null) {
+            return;
+        }
+        for (TopicConfig topicConfig : allTopicConfigMap.values()) {
+            for (int i = 0; i < topicConfig.getWriteQueueNums(); i++) {
+                truncateDirtyOffset(topicConfig.getTopicName(), i);
+            }
+        }
+    }
+
+    private Pair<Boolean, Long> isMinOffsetOk(final String topic, final int queueId, final long minPhyOffset) throws RocksDBException {
+        PhyAndCQOffset phyAndCQOffset = getHeapMinOffset(topic, queueId);
+        if (phyAndCQOffset != null) {
+            final long phyOffset = phyAndCQOffset.getPhyOffset();
+            final long cqOffset = phyAndCQOffset.getCqOffset();
+
+            return (phyOffset >= minPhyOffset) ? new Pair(true, cqOffset) : new Pair(false, cqOffset);
+        }
+        ByteBuffer byteBuffer = getMinPhyAndCqOffsetInKV(topic, queueId);
+        if (byteBuffer == null) {
+            return new Pair(false, 0L);
+        }
+        final long phyOffset = byteBuffer.getLong(OFFSET_PHY_OFFSET);
+        final long cqOffset = byteBuffer.getLong(OFFSET_CQ_OFFSET);
+        if (phyOffset >= minPhyOffset) {
+            String topicQueueId = buildTopicQueueId(topic, queueId);
+            PhyAndCQOffset newPhyAndCQOffset = new PhyAndCQOffset(phyOffset, cqOffset);
+            this.topicQueueMinOffset.putIfAbsent(topicQueueId, newPhyAndCQOffset);
+            if (messageStore.getMessageStoreConfig().isEnableRocksDBLog()) {
+                ROCKSDB_LOG.warn("updateMinOffsetInQueue. {}, {}", topicQueueId, newPhyAndCQOffset);
+            }
+            return new Pair(true, cqOffset);
+        }
+        return new Pair(false, cqOffset);
+    }
+
+    private void truncateDirtyOffset(String topic, int queueId) throws RocksDBException {
+        final ByteBuffer byteBuffer = getMaxPhyAndCqOffsetInKV(topic, queueId);
+        if (byteBuffer == null) {
+            return;
+        }
+
+        long maxPhyOffset = byteBuffer.getLong(OFFSET_PHY_OFFSET);
+        long maxCqOffset = byteBuffer.getLong(OFFSET_CQ_OFFSET);
+        long maxPhyOffsetInCQ = getMaxPhyOffset();
+
+        if (maxPhyOffset >= maxPhyOffsetInCQ) {
+            correctMaxCqOffset(topic, queueId, maxCqOffset, maxPhyOffsetInCQ);
+            Long newMaxCqOffset = getHeapMaxCqOffset(topic, queueId);
+            ROCKSDB_LOG.warn("truncateDirtyLogicFile topic: {}, queueId: {} from {} to {}", topic, queueId,
+                maxPhyOffset, newMaxCqOffset);
+        }
+    }
+
+    private void correctMaxPyhOffset(long maxPhyOffset) throws RocksDBException {
+        if (!this.rocksDBStorage.hold()) {
+            return;
+        }
+        try {
+            WriteBatch writeBatch = new WriteBatch();
+            long oldMaxPhyOffset = getMaxPhyOffset();
+            if (oldMaxPhyOffset <= maxPhyOffset) {
+                return;
+            }
+            log.info("correctMaxPyhOffset, oldMaxPhyOffset={}, newMaxPhyOffset={}", oldMaxPhyOffset, maxPhyOffset);
+            appendMaxPhyOffset(writeBatch, maxPhyOffset);
+            this.rocksDBStorage.batchPut(writeBatch);
+        } catch (RocksDBException e) {
+            ERROR_LOG.error("correctMaxPyhOffset Failed.", e);
+            throw e;
+        } finally {
+            this.rocksDBStorage.release();
+        }
+    }
+
+    public long getMinCqOffset(String topic, int queueId) throws RocksDBException {
+        final long minPhyOffset = this.messageStore.getMinPhyOffset();
+        Pair<Boolean, Long> pair = isMinOffsetOk(topic, queueId, minPhyOffset);
+        final long cqOffset = pair.getObject2();
+        if (!pair.getObject1() && correctMinCqOffset(topic, queueId, cqOffset, minPhyOffset)) {
+            PhyAndCQOffset phyAndCQOffset = getHeapMinOffset(topic, queueId);
+            if (phyAndCQOffset != null) {
+                if (this.messageStore.getMessageStoreConfig().isEnableRocksDBLog()) {
+                    ROCKSDB_LOG.warn("getMinOffsetInQueue miss heap. topic: {}, queueId: {}, old: {}, new: {}",
+                        topic, queueId, cqOffset, phyAndCQOffset);
+                }
+                return phyAndCQOffset.getCqOffset();
+            }
+        }
+        return cqOffset;
+    }
+
+    public Long getMaxPhyOffset(String topic, int queueId) {
+        try {
+            ByteBuffer byteBuffer = getMaxPhyAndCqOffsetInKV(topic, queueId);
+            if (byteBuffer != null) {
+                return byteBuffer.getLong(OFFSET_PHY_OFFSET);
+            }
+        } catch (Exception e) {
+            ERROR_LOG.info("getMaxPhyOffset error. topic: {}, queueId: {}", topic, queueId);
+        }
+        return null;
+    }
+
+    private ByteBuffer getMinPhyAndCqOffsetInKV(String topic, int queueId) throws RocksDBException {
+        return getPhyAndCqOffsetInKV(topic, queueId, false);
+    }
+
+    private ByteBuffer getMaxPhyAndCqOffsetInKV(String topic, int queueId) throws RocksDBException {
+        return getPhyAndCqOffsetInKV(topic, queueId, true);
+    }
+
+    private ByteBuffer getPhyAndCqOffsetInKV(String topic, int queueId, boolean max) throws RocksDBException {
+        final byte[] topicBytes = topic.getBytes(CHARSET_UTF8);
+        final ByteBuffer keyBB = buildOffsetKeyByteBuffer(topicBytes, queueId, max);
+
+        byte[] value =  this.rocksDBStorage.getOffset(keyBB.array());
+        return (value != null) ? ByteBuffer.wrap(value) : null;
+    }
+
+    private String buildTopicQueueId(final String topic, final int queueId) {
+        return topic + "-" + queueId;
+    }
+
+    private void putHeapMinCqOffset(final String topic, final int queueId, final long minPhyOffset, final long minCQOffset) {
+        String topicQueueId = buildTopicQueueId(topic, queueId);
+        PhyAndCQOffset phyAndCQOffset = new PhyAndCQOffset(minPhyOffset, minCQOffset);
+        this.topicQueueMinOffset.put(topicQueueId, phyAndCQOffset);
+    }
+
+    private void putHeapMaxCqOffset(final String topic, final int queueId, final long maxCQOffset) {
+        String topicQueueId = buildTopicQueueId(topic, queueId);
+        Long oldMaxCqOffset = this.topicQueueMaxCqOffset.put(topicQueueId, maxCQOffset);
+        if (oldMaxCqOffset != null && oldMaxCqOffset > maxCQOffset) {
+            ERROR_LOG.error("cqOffset invalid0. old: {}, now: {}", oldMaxCqOffset, maxCQOffset);
+        }
+    }
+
+    private PhyAndCQOffset getHeapMinOffset(final String topic, final int queueId) {
+        return this.topicQueueMinOffset.get(buildTopicQueueId(topic, queueId));
+    }
+
+    private Long getHeapMaxCqOffset(final String topic, final int queueId) {
+        String topicQueueId = buildTopicQueueId(topic, queueId);
+        return this.topicQueueMaxCqOffset.get(topicQueueId);
+    }
+
+    private PhyAndCQOffset removeHeapMinCqOffset(String topicQueueId) {
+        return this.topicQueueMinOffset.remove(topicQueueId);
+    }
+
+    private Long removeHeapMaxCqOffset(String topicQueueId) {
+        return this.topicQueueMaxCqOffset.remove(topicQueueId);
+    }
+
+    private void updateCqOffset(final String topic, final int queueId, final long phyOffset,
+        final long cqOffset, boolean max) throws RocksDBException {
+        if (!this.rocksDBStorage.hold()) {
+            return;
+        }
+        WriteBatch writeBatch = new WriteBatch();
+        try {
+            final byte[] topicBytes = topic.getBytes(CHARSET_UTF8);
+            final ByteBuffer offsetKey = buildOffsetKeyByteBuffer(topicBytes, queueId, max);
+
+            final ByteBuffer offsetValue = buildOffsetValueByteBuffer(phyOffset, cqOffset);
+            writeBatch.put(this.offsetCFH, offsetKey.array(), offsetValue.array());
+            this.rocksDBStorage.batchPut(writeBatch);
+
+            if (max) {
+                putHeapMaxCqOffset(topic, queueId, cqOffset);
+            } else {
+                putHeapMinCqOffset(topic, queueId, phyOffset, cqOffset);
+            }
+        } catch (RocksDBException e) {
+            ERROR_LOG.error("updateCqOffset({}) failed.", max ? "max" : "min", e);
+            throw e;
+        } finally {
+            writeBatch.close();
+            this.rocksDBStorage.release();
+            if (messageStore.getMessageStoreConfig().isEnableRocksDBLog()) {
+                ROCKSDB_LOG.warn("updateCqOffset({}). topic: {}, queueId: {}, phyOffset: {}, cqOffset: {}",
+                    max ? "max" : "min", topic, queueId, phyOffset, cqOffset);
+            }
+        }
+    }
+
+    private boolean correctMaxCqOffset(final String topic, final int queueId, final long maxCQOffset,
+        final long maxPhyOffsetInCQ) throws RocksDBException {
+        // 'getMinOffsetInQueue' may correct minCqOffset and put it into heap
+        long minCQOffset = getMinCqOffset(topic, queueId);
+        PhyAndCQOffset minPhyAndCQOffset = getHeapMinOffset(topic, queueId);
+        if (minPhyAndCQOffset == null
+            || minPhyAndCQOffset.getCqOffset() != minCQOffset
+            || minPhyAndCQOffset.getPhyOffset() > maxPhyOffsetInCQ) {
+            ROCKSDB_LOG.info("[BUG] correctMaxCqOffset error! topic: {}, queueId: {}, maxPhyOffsetInCQ: {}, "
+                    + "minCqOffset: {}, phyAndCQOffset: {}",
+                topic, queueId, maxPhyOffsetInCQ, minCQOffset, minPhyAndCQOffset);
+            throw new RocksDBException("correctMaxCqOffset error");
+        }
+
+        long high = maxCQOffset;
+        long low = minCQOffset;
+        PhyAndCQOffset targetPhyAndCQOffset = this.rocksDBConsumeQueueTable.binarySearchInCQ(topic, queueId, high,
+            low, maxPhyOffsetInCQ, false);
+
+        long targetCQOffset = targetPhyAndCQOffset.getCqOffset();
+        long targetPhyOffset = targetPhyAndCQOffset.getPhyOffset();
+
+        if (targetCQOffset == -1) {
+            if (maxCQOffset != minCQOffset) {
+                updateCqOffset(topic, queueId, minPhyAndCQOffset.getPhyOffset(), minCQOffset, true);
+            }
+            if (messageStore.getMessageStoreConfig().isEnableRocksDBLog()) {
+                ROCKSDB_LOG.warn("correct error. {}, {}, {}, {}, {}", topic, queueId, minCQOffset, maxCQOffset, minPhyAndCQOffset.getPhyOffset());
+            }
+            return false;
+        } else {
+            updateCqOffset(topic, queueId, targetPhyOffset, targetCQOffset, true);
+            return true;
+        }
+    }
+
+    private boolean correctMinCqOffset(final String topic, final int queueId,
+        final long minCQOffset, final long minPhyOffset) throws RocksDBException {
+        final ByteBuffer maxBB = getMaxPhyAndCqOffsetInKV(topic, queueId);
+        if (maxBB == null) {
+            updateCqOffset(topic, queueId, minPhyOffset, 0L, false);
+            return true;
+        }
+        final long maxPhyOffset = maxBB.getLong(OFFSET_PHY_OFFSET);
+        final long maxCQOffset = maxBB.getLong(OFFSET_CQ_OFFSET);
+
+        if (maxPhyOffset < minPhyOffset) {
+            updateCqOffset(topic, queueId, minPhyOffset, maxCQOffset + 1, false);
+            return true;
+        }
+
+        long high = maxCQOffset;
+        long low = minCQOffset;
+        PhyAndCQOffset phyAndCQOffset = this.rocksDBConsumeQueueTable.binarySearchInCQ(topic, queueId, high, low,
+            minPhyOffset, true);
+        long targetCQOffset = phyAndCQOffset.getCqOffset();
+        long targetPhyOffset = phyAndCQOffset.getPhyOffset();
+
+        if (targetCQOffset == -1) {
+            if (maxCQOffset != minCQOffset) {
+                updateCqOffset(topic, queueId, maxPhyOffset, maxCQOffset, false);
+            }
+            if (messageStore.getMessageStoreConfig().isEnableRocksDBLog()) {
+                ROCKSDB_LOG.warn("correct error. {}, {}, {}, {}, {}", topic, queueId, minCQOffset, maxCQOffset, minPhyOffset);
+            }
+            return false;
+        } else {
+            updateCqOffset(topic, queueId, targetPhyOffset, targetCQOffset, false);
+            return true;
+        }
+    }
+
+    public static Pair<ByteBuffer, ByteBuffer> getOffsetByteBufferPair() {
+        ByteBuffer offsetKey = ByteBuffer.allocateDirect(RocksDBConsumeQueueStore.MAX_KEY_LEN);
+        ByteBuffer offsetValue = ByteBuffer.allocateDirect(OFFSET_VALUE_LENGTH);
+        return new Pair<>(offsetKey, offsetValue);
+    }
+
+    private void buildOffsetKeyAndValueByteBuffer(final Pair<ByteBuffer, ByteBuffer> offsetBBPair,
+        final byte[] topicBytes, final DispatchRequest request) {
+        final ByteBuffer offsetKey = offsetBBPair.getObject1();
+        buildOffsetKeyByteBuffer(offsetKey, topicBytes, request.getQueueId(), true);
+
+        final ByteBuffer offsetValue = offsetBBPair.getObject2();
+        buildOffsetValueByteBuffer(offsetValue, request.getCommitLogOffset(), request.getConsumeQueueOffset());
+    }
+
+    private ByteBuffer buildOffsetKeyByteBuffer(final byte[] topicBytes, final int queueId, final boolean max) {
+        ByteBuffer byteBuffer = ByteBuffer.allocate(OFFSET_KEY_LENGTH_WITHOUT_TOPIC_BYTES + topicBytes.length);
+        buildOffsetKeyByteBuffer0(byteBuffer, topicBytes, queueId, max);
+        return byteBuffer;
+    }
+
+    private void buildOffsetKeyByteBuffer(final ByteBuffer byteBuffer, final byte[] topicBytes, final int queueId, final boolean max) {
+        byteBuffer.position(0).limit(OFFSET_KEY_LENGTH_WITHOUT_TOPIC_BYTES + topicBytes.length);
+        buildOffsetKeyByteBuffer0(byteBuffer, topicBytes, queueId, max);
+    }
+
+    private static void buildOffsetKeyByteBuffer0(final ByteBuffer byteBuffer, final byte[] topicBytes, final int queueId,
+        final boolean max) {
+        byteBuffer.putInt(topicBytes.length).put(CTRL_1).put(topicBytes).put(CTRL_1);
+        if (max) {
+            byteBuffer.put(MAX_BYTES);
+        } else {
+            byteBuffer.put(MIN_BYTES);
+        }
+        byteBuffer.put(CTRL_1).putInt(queueId);
+        byteBuffer.flip();
+    }
+
+    private void buildOffsetValueByteBuffer(final ByteBuffer byteBuffer, final long phyOffset, final long cqOffset) {
+        byteBuffer.position(0).limit(OFFSET_VALUE_LENGTH);
+        buildOffsetValueByteBuffer0(byteBuffer, phyOffset, cqOffset);
+    }
+
+    private ByteBuffer buildOffsetValueByteBuffer(final long phyOffset, final long cqOffset) {
+        final ByteBuffer byteBuffer = ByteBuffer.allocate(OFFSET_VALUE_LENGTH);
+        buildOffsetValueByteBuffer0(byteBuffer, phyOffset, cqOffset);
+        return byteBuffer;
+    }
+
+    private void buildOffsetValueByteBuffer0(final ByteBuffer byteBuffer, final long phyOffset, final long cqOffset) {
+        byteBuffer.putLong(phyOffset).putLong(cqOffset);
+        byteBuffer.flip();
+    }
+
+    static class PhyAndCQOffset {
+        private final long phyOffset;
+        private final long cqOffset;
+
+        public PhyAndCQOffset(final long phyOffset, final long cqOffset) {
+            this.phyOffset = phyOffset;
+            this.cqOffset = cqOffset;
+        }
+
+        public long getPhyOffset() {
+            return this.phyOffset;
+        }
+
+        public long getCqOffset() {
+            return this.cqOffset;
+        }
+
+        @Override
+        public String toString() {
+            return "[cqOffset=" + cqOffset + ", phyOffset=" + phyOffset + "]";
+        }
+    }
+}
diff --git a/store/src/main/java/org/apache/rocketmq/store/queue/RocksDBConsumeQueueStore.java b/store/src/main/java/org/apache/rocketmq/store/queue/RocksDBConsumeQueueStore.java
new file mode 100644
index 000000000..78456cfcd
--- /dev/null
+++ b/store/src/main/java/org/apache/rocketmq/store/queue/RocksDBConsumeQueueStore.java
@@ -0,0 +1,441 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.rocketmq.store.queue;
+
+import java.io.File;
+import java.nio.ByteBuffer;
+import java.util.ArrayList;
+import java.util.HashMap;
+import java.util.List;
+import java.util.Map;
+import java.util.Set;
+import java.util.concurrent.ConcurrentHashMap;
+import java.util.concurrent.ConcurrentMap;
+import java.util.concurrent.Executors;
+import java.util.concurrent.ScheduledExecutorService;
+import java.util.concurrent.TimeUnit;
+
+import org.apache.commons.io.FileUtils;
+import org.apache.commons.lang3.StringUtils;
+import org.apache.rocketmq.common.BoundaryType;
+import org.apache.rocketmq.common.Pair;
+import org.apache.rocketmq.common.ThreadFactoryImpl;
+import org.apache.rocketmq.common.constant.LoggerName;
+import org.apache.rocketmq.common.message.MessageExtBrokerInner;
+import org.apache.rocketmq.common.utils.DataConverter;
+import org.apache.rocketmq.logging.org.slf4j.Logger;
+import org.apache.rocketmq.logging.org.slf4j.LoggerFactory;
+import org.apache.rocketmq.store.DefaultMessageStore;
+import org.apache.rocketmq.store.DispatchRequest;
+import org.apache.rocketmq.store.config.BrokerRole;
+import org.apache.rocketmq.store.config.StorePathConfigHelper;
+import org.apache.rocketmq.store.rocksdb.ConsumeQueueRocksDBStorage;
+import org.rocksdb.RocksDBException;
+import org.rocksdb.WriteBatch;
+
+public class RocksDBConsumeQueueStore extends AbstractConsumeQueueStore {
+    private static final Logger ERROR_LOG = LoggerFactory.getLogger(LoggerName.STORE_ERROR_LOGGER_NAME);
+    private static final Logger ROCKSDB_LOG = LoggerFactory.getLogger(LoggerName.ROCKSDB_LOGGER_NAME);
+
+    public static final byte CTRL_0 = '\u0000';
+    public static final byte CTRL_1 = '\u0001';
+    public static final byte CTRL_2 = '\u0002';
+
+    private static final int BATCH_SIZE = 16;
+    public static final int MAX_KEY_LEN = 300;
+
+    private final ScheduledExecutorService scheduledExecutorService;
+    private final String storePath;
+
+    /**
+     * we use two tables with different ColumnFamilyHandle, called RocksDBConsumeQueueTable and RocksDBConsumeQueueOffsetTable.
+     * 1.RocksDBConsumeQueueTable uses to store CqUnit[physicalOffset, msgSize, tagHashCode, msgStoreTime]
+     * 2.RocksDBConsumeQueueOffsetTable uses to store physicalOffset and consumeQueueOffset(@see PhyAndCQOffset) of topic-queueId
+     */
+    private final ConsumeQueueRocksDBStorage rocksDBStorage;
+    private final RocksDBConsumeQueueTable rocksDBConsumeQueueTable;
+    private final RocksDBConsumeQueueOffsetTable rocksDBConsumeQueueOffsetTable;
+
+    private final WriteBatch writeBatch;
+    private final List<DispatchRequest> bufferDRList;
+    private final List<Pair<ByteBuffer, ByteBuffer>> cqBBPairList;
+    private final List<Pair<ByteBuffer, ByteBuffer>> offsetBBPairList;
+    private final Map<ByteBuffer, Pair<ByteBuffer, DispatchRequest>> tempTopicQueueMaxOffsetMap;
+    private volatile boolean isCQError = false;
+
+    public RocksDBConsumeQueueStore(DefaultMessageStore messageStore) {
+        super(messageStore);
+
+        this.storePath = StorePathConfigHelper.getStorePathConsumeQueue(messageStoreConfig.getStorePathRootDir());
+        this.rocksDBStorage = new ConsumeQueueRocksDBStorage(messageStore, storePath, 4);
+        this.rocksDBConsumeQueueTable = new RocksDBConsumeQueueTable(rocksDBStorage, messageStore);
+        this.rocksDBConsumeQueueOffsetTable = new RocksDBConsumeQueueOffsetTable(rocksDBConsumeQueueTable, rocksDBStorage, messageStore);
+
+        this.writeBatch = new WriteBatch();
+        this.bufferDRList = new ArrayList(BATCH_SIZE);
+        this.cqBBPairList = new ArrayList(BATCH_SIZE);
+        this.offsetBBPairList = new ArrayList(BATCH_SIZE);
+        for (int i = 0; i < BATCH_SIZE; i++) {
+            this.cqBBPairList.add(RocksDBConsumeQueueTable.getCQByteBufferPair());
+            this.offsetBBPairList.add(RocksDBConsumeQueueOffsetTable.getOffsetByteBufferPair());
+        }
+
+        this.tempTopicQueueMaxOffsetMap = new HashMap<>();
+        this.scheduledExecutorService = Executors.newSingleThreadScheduledExecutor(
+            new ThreadFactoryImpl("RocksDBConsumeQueueStoreScheduledThread", messageStore.getBrokerIdentity()));
+    }
+
+    @Override
+    public void start() {
+        log.info("RocksDB ConsumeQueueStore start!");
+        this.scheduledExecutorService.scheduleAtFixedRate(() -> {
+            this.rocksDBStorage.statRocksdb(ROCKSDB_LOG);
+        }, 10, this.messageStoreConfig.getStatRocksDBCQIntervalSec(), TimeUnit.SECONDS);
+
+        this.scheduledExecutorService.scheduleWithFixedDelay(() -> {
+            cleanDirty(messageStore.getTopicConfigs().keySet());
+        }, 10, this.messageStoreConfig.getCleanRocksDBDirtyCQIntervalMin(), TimeUnit.MINUTES);
+    }
+
+    private void cleanDirty(final Set<String> existTopicSet) {
+        try {
+            Map<String, Set<Integer>> topicQueueIdToBeDeletedMap =
+                this.rocksDBConsumeQueueOffsetTable.iterateOffsetTable2FindDirty(existTopicSet);
+
+            for (Map.Entry<String, Set<Integer>> entry : topicQueueIdToBeDeletedMap.entrySet()) {
+                String topic = entry.getKey();
+                for (int queueId : entry.getValue()) {
+                    destroy(new RocksDBConsumeQueue(topic, queueId));
+                }
+            }
+        } catch (Exception e) {
+            log.error("cleanUnusedTopic Failed.", e);
+        }
+    }
+
+    @Override
+    public boolean load() {
+        boolean result = this.rocksDBStorage.start();
+        this.rocksDBConsumeQueueTable.load();
+        this.rocksDBConsumeQueueOffsetTable.load();
+        log.info("load rocksdb consume queue {}.", result ? "OK" : "Failed");
+        return result;
+    }
+
+    @Override
+    public boolean loadAfterDestroy() {
+        return this.load();
+    }
+
+    @Override
+    public void recover() {
+        // ignored
+    }
+
+    @Override
+    public boolean recoverConcurrently() {
+        return true;
+    }
+
+    @Override
+    public boolean shutdown() {
+        this.scheduledExecutorService.shutdown();
+        return shutdownInner();
+    }
+
+    private boolean shutdownInner() {
+        return this.rocksDBStorage.shutdown();
+    }
+
+    @Override
+    public void putMessagePositionInfoWrapper(DispatchRequest request) throws RocksDBException {
+        if (request == null || this.bufferDRList.size() >= BATCH_SIZE) {
+            putMessagePosition();
+        }
+        if (request != null) {
+            this.bufferDRList.add(request);
+        }
+    }
+
+    public void putMessagePosition() throws RocksDBException {
+        final int maxRetries = 30;
+        for (int i = 0; i < maxRetries; i++) {
+            if (putMessagePosition0()) {
+                if (this.isCQError) {
+                    this.messageStore.getRunningFlags().clearLogicsQueueError();
+                    this.isCQError = false;
+                }
+                return;
+            } else {
+                ERROR_LOG.warn("{} put cq Failed. retryTime: {}", i);
+                try {
+                    Thread.sleep(100);
+                } catch (InterruptedException ignored) {
+                }
+            }
+        }
+        if (!this.isCQError) {
+            ERROR_LOG.error("[BUG] put CQ Failed.");
+            this.messageStore.getRunningFlags().makeLogicsQueueError();
+            this.isCQError = true;
+        }
+        throw new RocksDBException("put CQ Failed");
+    }
+
+    private boolean putMessagePosition0() {
+        if (!this.rocksDBStorage.hold()) {
+            return false;
+        }
+
+        final Map<ByteBuffer, Pair<ByteBuffer, DispatchRequest>> tempTopicQueueMaxOffsetMap = this.tempTopicQueueMaxOffsetMap;
+        try {
+            final List<DispatchRequest> bufferDRList = this.bufferDRList;
+            final int size = bufferDRList.size();
+            if (size == 0) {
+                return true;
+            }
+            final List<Pair<ByteBuffer, ByteBuffer>> cqBBPairList = this.cqBBPairList;
+            final List<Pair<ByteBuffer, ByteBuffer>> offsetBBPairList = this.offsetBBPairList;
+            final WriteBatch writeBatch = this.writeBatch;
+
+            long maxPhyOffset = 0;
+            for (int i = size - 1; i >= 0; i--) {
+                final DispatchRequest request = bufferDRList.get(i);
+                final byte[] topicBytes = request.getTopic().getBytes(DataConverter.CHARSET_UTF8);
+
+                this.rocksDBConsumeQueueTable.buildAndPutCQByteBuffer(cqBBPairList.get(i), topicBytes, request, writeBatch);
+                this.rocksDBConsumeQueueOffsetTable.updateTempTopicQueueMaxOffset(offsetBBPairList.get(i),
+                    topicBytes, request, tempTopicQueueMaxOffsetMap);
+
+                final int msgSize = request.getMsgSize();
+                final long phyOffset = request.getCommitLogOffset();
+                if (phyOffset + msgSize >= maxPhyOffset) {
+                    maxPhyOffset = phyOffset + msgSize;
+                }
+            }
+
+            this.rocksDBConsumeQueueOffsetTable.putMaxPhyAndCqOffset(tempTopicQueueMaxOffsetMap, writeBatch, maxPhyOffset);
+
+            // clear writeBatch in batchPut
+            this.rocksDBStorage.batchPut(writeBatch);
+
+            this.rocksDBConsumeQueueOffsetTable.putHeapMaxCqOffset(tempTopicQueueMaxOffsetMap);
+
+            long storeTimeStamp = bufferDRList.get(size - 1).getStoreTimestamp();
+            if (this.messageStore.getMessageStoreConfig().getBrokerRole() == BrokerRole.SLAVE
+                || this.messageStore.getMessageStoreConfig().isEnableDLegerCommitLog()) {
+                this.messageStore.getStoreCheckpoint().setPhysicMsgTimestamp(storeTimeStamp);
+            }
+            this.messageStore.getStoreCheckpoint().setLogicsMsgTimestamp(storeTimeStamp);
+
+            notifyMessageArriveAndClear();
+            return true;
+        } catch (Exception e) {
+            ERROR_LOG.error("putMessagePosition0 Failed.", e);
+            return false;
+        } finally {
+            tempTopicQueueMaxOffsetMap.clear();
+            this.rocksDBStorage.release();
+        }
+    }
+
+    private void notifyMessageArriveAndClear() {
+        final List<DispatchRequest> bufferDRList = this.bufferDRList;
+        try {
+            for (DispatchRequest dp : bufferDRList) {
+                this.messageStore.notifyMessageArriveIfNecessary(dp);
+            }
+        } catch (Exception e) {
+            ERROR_LOG.error("notifyMessageArriveAndClear Failed.", e);
+        } finally {
+            bufferDRList.clear();
+        }
+    }
+
+    @Override
+    public List<ByteBuffer> rangeQuery(final String topic, final int queueId, final long startIndex, final int num) throws RocksDBException {
+        return this.rocksDBConsumeQueueTable.rangeQuery(topic, queueId, startIndex, num);
+    }
+
+    @Override
+    public ByteBuffer get(final String topic, final int queueId, final long cqOffset) throws RocksDBException {
+        return this.rocksDBConsumeQueueTable.getCQInKV(topic, queueId, cqOffset);
+    }
+
+    /**
+     * Ignored, we do not need to recover topicQueueTable and correct minLogicOffset. Because we will correct them
+     * when we use them, we call it lazy correction.
+     * @see RocksDBConsumeQueue#increaseQueueOffset(QueueOffsetOperator, MessageExtBrokerInner, short)
+     * @see org.apache.rocketmq.store.queue.RocksDBConsumeQueueOffsetTable#getMinCqOffset(String, int)
+     */
+    @Override
+    public void recoverOffsetTable(long minPhyOffset) {
+
+    }
+
+    @Override
+    public void destroy() {
+        try {
+            shutdownInner();
+            FileUtils.deleteDirectory(new File(this.storePath));
+        } catch (Exception e) {
+            ERROR_LOG.error("destroy cq Failed. {}", this.storePath, e);
+        }
+    }
+
+    @Override
+    public void destroy(ConsumeQueueInterface consumeQueue) throws RocksDBException {
+        String topic = consumeQueue.getTopic();
+        int queueId = consumeQueue.getQueueId();
+        if (StringUtils.isEmpty(topic) || queueId < 0 || !this.rocksDBStorage.hold()) {
+            return;
+        }
+
+        WriteBatch writeBatch = new WriteBatch();
+        try {
+            this.rocksDBConsumeQueueTable.destroyCQ(topic, queueId, writeBatch);
+            this.rocksDBConsumeQueueOffsetTable.destroyOffset(topic, queueId, writeBatch);
+
+            this.rocksDBStorage.batchPut(writeBatch);
+        } catch (RocksDBException e) {
+            ERROR_LOG.error("kv deleteTopic {} Failed.", topic, e);
+            throw e;
+        } finally {
+            writeBatch.close();
+            this.rocksDBStorage.release();
+        }
+    }
+
+    @Override
+    public boolean flush(ConsumeQueueInterface consumeQueue, int flushLeastPages) {
+        try {
+            this.rocksDBStorage.flushWAL();
+        } catch (Exception e) {
+        }
+        return true;
+    }
+
+    @Override
+    public void checkSelf() {
+        // ignored
+    }
+
+    @Override
+    public int deleteExpiredFile(ConsumeQueueInterface consumeQueue, long minCommitLogPos) {
+        // ignored
+        return 0;
+    }
+
+    /**
+     * We do not need to truncate dirty CQ in RocksDBConsumeQueueTable,  Because dirty CQ in RocksDBConsumeQueueTable
+     * will be rewritten by new KV when new messages are appended or will be cleaned up when topics are deleted.
+     * But dirty offset info in RocksDBConsumeQueueOffsetTable must be truncated, because we use offset info in
+     * RocksDBConsumeQueueOffsetTable to rebuild topicQueueTable(@see RocksDBConsumeQueue#increaseQueueOffset).
+     * @param offsetToTruncate
+     * @throws RocksDBException
+     */
+    @Override
+    public void truncateDirty(long offsetToTruncate) throws RocksDBException {
+        long maxPhyOffsetInRocksdb = getMaxPhyOffsetInConsumeQueue();
+        if (offsetToTruncate >= maxPhyOffsetInRocksdb) {
+            return;
+        }
+
+        this.rocksDBConsumeQueueOffsetTable.truncateDirty(offsetToTruncate);
+    }
+
+    @Override
+    public void cleanExpired(final long minPhyOffset) {
+        this.rocksDBStorage.manualCompaction(minPhyOffset);
+    }
+
+    @Override
+    public long getOffsetInQueueByTime(String topic, int queueId, long timestamp, BoundaryType boundaryType) throws RocksDBException {
+        final long minPhysicOffset = this.messageStore.getMinPhyOffset();
+        long low = this.rocksDBConsumeQueueOffsetTable.getMinCqOffset(topic, queueId);
+        Long high = this.rocksDBConsumeQueueOffsetTable.getMaxCqOffset(topic, queueId);
+        if (high == null || high == -1) {
+            return 0;
+        }
+        return this.rocksDBConsumeQueueTable.binarySearchInCQByTime(topic, queueId, high, low, timestamp, minPhysicOffset);
+    }
+
+    @Override
+    public long getMaxOffsetInQueue(String topic, int queueId) throws RocksDBException {
+        Long maxOffset = this.rocksDBConsumeQueueOffsetTable.getMaxCqOffset(topic, queueId);
+        return (maxOffset != null) ? maxOffset + 1 : 0;
+    }
+
+    @Override
+    public long getMinOffsetInQueue(String topic, int queueId) throws RocksDBException {
+        return this.rocksDBConsumeQueueOffsetTable.getMinCqOffset(topic, queueId);
+    }
+
+    @Override
+    public Long getMaxPhyOffsetInConsumeQueue(String topic, int queueId) {
+        return this.rocksDBConsumeQueueOffsetTable.getMaxPhyOffset(topic, queueId);
+    }
+
+    @Override
+    public long getMaxPhyOffsetInConsumeQueue() throws RocksDBException {
+        return this.rocksDBConsumeQueueOffsetTable.getMaxPhyOffset();
+    }
+
+    @Override
+    public ConsumeQueueInterface findOrCreateConsumeQueue(String topic, int queueId) {
+        ConcurrentMap<Integer, ConsumeQueueInterface> map = this.consumeQueueTable.get(topic);
+        if (null == map) {
+            ConcurrentMap<Integer, ConsumeQueueInterface> newMap = new ConcurrentHashMap<>(128);
+            ConcurrentMap<Integer, ConsumeQueueInterface> oldMap = this.consumeQueueTable.putIfAbsent(topic, newMap);
+            if (oldMap != null) {
+                map = oldMap;
+            } else {
+                map = newMap;
+            }
+        }
+
+        ConsumeQueueInterface logic = map.get(queueId);
+        if (logic != null) {
+            return logic;
+        }
+
+        ConsumeQueueInterface newLogic = new RocksDBConsumeQueue(this.messageStore, topic, queueId);
+        ConsumeQueueInterface oldLogic = map.putIfAbsent(queueId, newLogic);
+
+        return oldLogic != null ? oldLogic : newLogic;
+    }
+
+    @Override
+    public long rollNextFile(ConsumeQueueInterface consumeQueue, long offset) {
+        return 0;
+    }
+
+    @Override
+    public boolean isFirstFileExist(ConsumeQueueInterface consumeQueue) {
+        return true;
+    }
+
+    @Override
+    public boolean isFirstFileAvailable(ConsumeQueueInterface consumeQueue) {
+        return true;
+    }
+
+    @Override
+    public long getTotalSize() {
+        return 0;
+    }
+}
diff --git a/store/src/main/java/org/apache/rocketmq/store/queue/RocksDBConsumeQueueTable.java b/store/src/main/java/org/apache/rocketmq/store/queue/RocksDBConsumeQueueTable.java
new file mode 100644
index 000000000..0a735ea27
--- /dev/null
+++ b/store/src/main/java/org/apache/rocketmq/store/queue/RocksDBConsumeQueueTable.java
@@ -0,0 +1,312 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.rocketmq.store.queue;
+
+import java.nio.ByteBuffer;
+import java.util.ArrayList;
+import java.util.List;
+
+import org.apache.rocketmq.common.Pair;
+import org.apache.rocketmq.common.constant.LoggerName;
+import org.apache.rocketmq.logging.org.slf4j.Logger;
+import org.apache.rocketmq.logging.org.slf4j.LoggerFactory;
+import org.apache.rocketmq.store.DefaultMessageStore;
+import org.apache.rocketmq.store.DispatchRequest;
+import org.apache.rocketmq.store.queue.RocksDBConsumeQueueOffsetTable.PhyAndCQOffset;
+import org.apache.rocketmq.store.rocksdb.ConsumeQueueRocksDBStorage;
+import org.rocksdb.ColumnFamilyHandle;
+import org.rocksdb.RocksDBException;
+import org.rocksdb.WriteBatch;
+
+import static org.apache.rocketmq.common.utils.DataConverter.CHARSET_UTF8;
+import static org.apache.rocketmq.store.queue.RocksDBConsumeQueueStore.CTRL_0;
+import static org.apache.rocketmq.store.queue.RocksDBConsumeQueueStore.CTRL_1;
+import static org.apache.rocketmq.store.queue.RocksDBConsumeQueueStore.CTRL_2;
+
+/**
+ * We use RocksDBConsumeQueueTable to store cqUnit.
+ */
+public class RocksDBConsumeQueueTable {
+    private static final Logger log = LoggerFactory.getLogger(LoggerName.STORE_LOGGER_NAME);
+    private static final Logger ROCKSDB_LOG = LoggerFactory.getLogger(LoggerName.ROCKSDB_LOGGER_NAME);
+    private static final Logger ERROR_LOG = LoggerFactory.getLogger(LoggerName.STORE_ERROR_LOGGER_NAME);
+
+    /**
+     * Rocksdb ConsumeQueue's store unit. Format:
+     *
+     * <pre>
+     * 
+     *  Topic Bytes Array Size    CTRL_1      Topic Bytes Array     CTRL_1     QueueId    CTRL_1     ConsumeQueue Offset  
+     *         (4 Bytes)         (1 Bytes)        (n Bytes)        (1 Bytes)  (4 Bytes)  (1 Bytes)      (8 Bytes)         
+     * 
+     *                                                     Key Unit                                                             
+     *                                                                                                                          
+     * </pre>
+     *
+     * <pre>
+     * 
+     *   CommitLog Physical Offset        Body Size       Tag HashCode     Msg Store Time  
+     *         (8 Bytes)                  (4 Bytes)        (8 Bytes)         (8 Bytes)     
+     * 
+     *                                                     Value Unit                         
+     *                                                                                        
+     * </pre>
+     * ConsumeQueue's store unit. Size:
+     * CommitLog Physical Offset(8) + Body Size(4) + Tag HashCode(8) + Msg Store Time(8) = 28 Bytes
+     */
+    private static final int PHY_OFFSET_OFFSET = 0;
+    private static final int PHY_MSG_LEN_OFFSET = 8;
+    private static final int MSG_TAG_HASHCODE_OFFSET = 12;
+    private static final int MSG_STORE_TIME_SIZE_OFFSET = 20;
+    public static final int CQ_UNIT_SIZE = 8 + 4 + 8 + 8;
+
+    /**
+     * 
+     *  Topic Bytes Array Size    CTRL_1     CTRL_1     QueueId    CTRL_1     ConsumeQueue Offset  
+     *         (4 Bytes)         (1 Bytes)  (1 Bytes)  (4 Bytes)  (1 Bytes)      (8 Bytes)         
+     * 
+     */
+    private static final int CQ_KEY_LENGTH_WITHOUT_TOPIC_BYTES = 4 + 1 + 1 + 4 + 1 + 8;
+
+    /**
+     * 
+     *  Topic Bytes Array Size    CTRL_1     CTRL_1     QueueId    CTRL_0(CTRL_2)   
+     *         (4 Bytes)         (1 Bytes)  (1 Bytes)  (4 Bytes)      (1 Bytes)     
+     * 
+     */
+    private static final int DELETE_CQ_KEY_LENGTH_WITHOUT_TOPIC_BYTES = 4 + 1 + 1 + 4 + 1;
+
+    private final ConsumeQueueRocksDBStorage rocksDBStorage;
+    private final DefaultMessageStore messageStore;
+
+    private ColumnFamilyHandle defaultCFH;
+
+    public RocksDBConsumeQueueTable(ConsumeQueueRocksDBStorage rocksDBStorage, DefaultMessageStore messageStore) {
+        this.rocksDBStorage = rocksDBStorage;
+        this.messageStore = messageStore;
+    }
+
+    public void load() {
+        this.defaultCFH = this.rocksDBStorage.getDefaultCFHandle();
+    }
+
+    public void buildAndPutCQByteBuffer(final Pair<ByteBuffer, ByteBuffer> cqBBPair,
+        final byte[] topicBytes, final DispatchRequest request, final WriteBatch writeBatch) throws RocksDBException {
+        final ByteBuffer cqKey = cqBBPair.getObject1();
+        buildCQKeyByteBuffer(cqKey, topicBytes, request.getQueueId(), request.getConsumeQueueOffset());
+
+        final ByteBuffer cqValue = cqBBPair.getObject2();
+        buildCQValueByteBuffer(cqValue, request.getCommitLogOffset(), request.getMsgSize(), request.getTagsCode(), request.getStoreTimestamp());
+
+        writeBatch.put(this.defaultCFH, cqKey, cqValue);
+    }
+
+    public ByteBuffer getCQInKV(final String topic, final int queueId, final long cqOffset) throws RocksDBException {
+        final byte[] topicBytes = topic.getBytes(CHARSET_UTF8);
+        final ByteBuffer keyBB = buildCQKeyByteBuffer(topicBytes, queueId, cqOffset);
+        byte[] value = this.rocksDBStorage.getCQ(keyBB.array());
+        return (value != null) ? ByteBuffer.wrap(value) : null;
+    }
+
+    public List<ByteBuffer> rangeQuery(final String topic, final int queueId, final long startIndex, final int num) throws RocksDBException {
+        final byte[] topicBytes = topic.getBytes(CHARSET_UTF8);
+        final List<ColumnFamilyHandle> defaultCFHList = new ArrayList(num);
+        final ByteBuffer[] resultList = new ByteBuffer[num];
+        final List<Integer> kvIndexList = new ArrayList(num);
+        final List<byte[]> kvKeyList = new ArrayList(num);
+        for (int i = 0; i < num; i++) {
+            final ByteBuffer keyBB = buildCQKeyByteBuffer(topicBytes, queueId, startIndex + i);
+            kvIndexList.add(i);
+            kvKeyList.add(keyBB.array());
+            defaultCFHList.add(this.defaultCFH);
+        }
+        int keyNum = kvIndexList.size();
+        if (keyNum > 0) {
+            List<byte[]> kvValueList = this.rocksDBStorage.multiGet(defaultCFHList, kvKeyList);
+            final int valueNum = kvValueList.size();
+            if (keyNum != valueNum) {
+                throw new RocksDBException("rocksdb bug, multiGet");
+            }
+            for (int i = 0; i < valueNum; i++) {
+                byte[] value = kvValueList.get(i);
+                if (value == null) {
+                    continue;
+                }
+                ByteBuffer byteBuffer = ByteBuffer.wrap(value);
+                resultList[kvIndexList.get(i)] = byteBuffer;
+            }
+        }
+
+        final int resultSize = resultList.length;
+        List<ByteBuffer> bbValueList = new ArrayList(resultSize);
+        for (int i = 0; i < resultSize; i++) {
+            ByteBuffer byteBuffer = resultList[i];
+            if (byteBuffer == null) {
+                break;
+            }
+            bbValueList.add(byteBuffer);
+        }
+        return bbValueList;
+    }
+
+    /**
+     * When topic is deleted, we clean up its CqUnit in rocksdb.
+     * @param topic
+     * @param queueId
+     * @throws RocksDBException
+     */
+    public void destroyCQ(final String topic, final int queueId, WriteBatch writeBatch) throws RocksDBException {
+        final byte[] topicBytes = topic.getBytes(CHARSET_UTF8);
+        final ByteBuffer cqStartKey = buildDeleteCQKey(true, topicBytes, queueId);
+        final ByteBuffer cqEndKey = buildDeleteCQKey(false, topicBytes, queueId);
+
+        writeBatch.deleteRange(this.defaultCFH, cqStartKey.array(), cqEndKey.array());
+
+        log.info("Rocksdb consumeQueue table delete topic. {}, {}", topic, queueId);
+    }
+
+    public long binarySearchInCQByTime(String topic, int queueId, long high, long low, long timestamp,
+        long minPhysicOffset) throws RocksDBException {
+        long result = 0;
+        long targetOffset = -1L, leftOffset = -1L, rightOffset = -1L;
+        long leftValue = -1L, rightValue = -1L;
+        while (high >= low) {
+            long midOffset = low + ((high - low) >>> 1);
+            ByteBuffer byteBuffer = getCQInKV(topic, queueId, midOffset);
+            if (byteBuffer == null) {
+                ERROR_LOG.warn("binarySearchInCQByTimeStamp Failed. topic: {}, queueId: {}, timestamp: {}, result: null",
+                    topic, queueId, timestamp);
+                low = midOffset + 1;
+                continue;
+            }
+
+            long phyOffset = byteBuffer.getLong(PHY_OFFSET_OFFSET);
+            if (phyOffset < minPhysicOffset) {
+                low = midOffset + 1;
+                leftOffset = midOffset;
+                continue;
+            }
+            long storeTime = byteBuffer.getLong(MSG_STORE_TIME_SIZE_OFFSET);
+            if (storeTime < 0) {
+                return 0;
+            } else if (storeTime == timestamp) {
+                targetOffset = midOffset;
+                break;
+            } else if (storeTime > timestamp) {
+                high = midOffset - 1;
+                rightOffset = midOffset;
+                rightValue = storeTime;
+            } else {
+                low = midOffset + 1;
+                leftOffset = midOffset;
+                leftValue = storeTime;
+            }
+        }
+        if (targetOffset != -1) {
+            result = targetOffset;
+        } else {
+            if (leftValue == -1) {
+                result = rightOffset;
+            } else if (rightValue == -1) {
+                result = leftOffset;
+            } else {
+                result = Math.abs(timestamp - leftValue) > Math.abs(timestamp - rightValue) ? rightOffset : leftOffset;
+            }
+        }
+        return result;
+    }
+
+    public PhyAndCQOffset binarySearchInCQ(String topic, int queueId, long high, long low, long targetPhyOffset,
+        boolean min) throws RocksDBException {
+        long resultCQOffset = -1L;
+        long resultPhyOffset = -1L;
+        while (high >= low) {
+            long midCQOffset = low + ((high - low) >>> 1);
+            ByteBuffer byteBuffer = getCQInKV(topic, queueId, midCQOffset);
+            if (this.messageStore.getMessageStoreConfig().isEnableRocksDBLog()) {
+                ROCKSDB_LOG.warn("binarySearchInCQ. {}, {}, {}, {}, {}", topic, queueId, midCQOffset, low, high);
+            }
+            if (byteBuffer == null) {
+                low = midCQOffset + 1;
+                continue;
+            }
+
+            final long phyOffset = byteBuffer.getLong(PHY_OFFSET_OFFSET);
+            if (phyOffset == targetPhyOffset) {
+                if (min) {
+                    resultCQOffset =  midCQOffset;
+                    resultPhyOffset = phyOffset;
+                }
+                break;
+            } else if (phyOffset > targetPhyOffset) {
+                high = midCQOffset - 1;
+                if (min) {
+                    resultCQOffset = midCQOffset;
+                    resultPhyOffset = phyOffset;
+                }
+            } else {
+                low = midCQOffset + 1;
+                if (!min) {
+                    resultCQOffset = midCQOffset;
+                    resultPhyOffset = phyOffset;
+                }
+            }
+        }
+        return new PhyAndCQOffset(resultPhyOffset, resultCQOffset);
+    }
+
+    public static Pair<ByteBuffer, ByteBuffer> getCQByteBufferPair() {
+        ByteBuffer cqKey = ByteBuffer.allocateDirect(RocksDBConsumeQueueStore.MAX_KEY_LEN);
+        ByteBuffer cqValue = ByteBuffer.allocateDirect(CQ_UNIT_SIZE);
+        return new Pair<>(cqKey, cqValue);
+    }
+
+    private ByteBuffer buildCQKeyByteBuffer(final byte[] topicBytes, final int queueId, final long cqOffset) {
+        final ByteBuffer byteBuffer = ByteBuffer.allocate(CQ_KEY_LENGTH_WITHOUT_TOPIC_BYTES + topicBytes.length);
+        buildCQKeyByteBuffer0(byteBuffer, topicBytes, queueId, cqOffset);
+        return byteBuffer;
+    }
+
+    private void buildCQKeyByteBuffer(final ByteBuffer byteBuffer, final byte[] topicBytes, final int queueId, final long cqOffset) {
+        byteBuffer.position(0).limit(CQ_KEY_LENGTH_WITHOUT_TOPIC_BYTES + topicBytes.length);
+        buildCQKeyByteBuffer0(byteBuffer, topicBytes, queueId, cqOffset);
+    }
+
+    private void buildCQKeyByteBuffer0(final ByteBuffer byteBuffer, final byte[] topicBytes, final int queueId, final long cqOffset) {
+        byteBuffer.putInt(topicBytes.length).put(CTRL_1).put(topicBytes).put(CTRL_1).putInt(queueId).put(CTRL_1).putLong(cqOffset);
+        byteBuffer.flip();
+    }
+
+    private void buildCQValueByteBuffer(final ByteBuffer byteBuffer, final long phyOffset, final int msgSize, final long tagsCode, final long storeTimestamp) {
+        byteBuffer.position(0).limit(CQ_UNIT_SIZE);
+        buildCQValueByteBuffer0(byteBuffer, phyOffset, msgSize, tagsCode, storeTimestamp);
+    }
+
+    private void buildCQValueByteBuffer0(final ByteBuffer byteBuffer, final long phyOffset, final int msgSize,
+        final long tagsCode, final long storeTimestamp) {
+        byteBuffer.putLong(phyOffset).putInt(msgSize).putLong(tagsCode).putLong(storeTimestamp);
+        byteBuffer.flip();
+    }
+
+    private ByteBuffer buildDeleteCQKey(final boolean start, final byte[] topicBytes, final int queueId) {
+        final ByteBuffer byteBuffer = ByteBuffer.allocate(DELETE_CQ_KEY_LENGTH_WITHOUT_TOPIC_BYTES + topicBytes.length);
+
+        byteBuffer.putInt(topicBytes.length).put(CTRL_1).put(topicBytes).put(CTRL_1).putInt(queueId).put(start ? CTRL_0 : CTRL_2);
+        byteBuffer.flip();
+        return byteBuffer;
+    }
+}
diff --git a/store/src/main/java/org/apache/rocketmq/store/rocksdb/ConsumeQueueCompactionFilterFactory.java b/store/src/main/java/org/apache/rocketmq/store/rocksdb/ConsumeQueueCompactionFilterFactory.java
new file mode 100644
index 000000000..aa796c4d3
--- /dev/null
+++ b/store/src/main/java/org/apache/rocketmq/store/rocksdb/ConsumeQueueCompactionFilterFactory.java
@@ -0,0 +1,47 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.rocketmq.store.rocksdb;
+
+import org.apache.rocketmq.common.constant.LoggerName;
+import org.apache.rocketmq.logging.org.slf4j.Logger;
+import org.apache.rocketmq.logging.org.slf4j.LoggerFactory;
+import org.apache.rocketmq.store.MessageStore;
+import org.rocksdb.AbstractCompactionFilter;
+import org.rocksdb.AbstractCompactionFilterFactory;
+import org.rocksdb.RemoveConsumeQueueCompactionFilter;
+
+public class ConsumeQueueCompactionFilterFactory extends AbstractCompactionFilterFactory<RemoveConsumeQueueCompactionFilter> {
+    private static final Logger LOGGER = LoggerFactory.getLogger(LoggerName.ROCKSDB_LOGGER_NAME);
+    private final MessageStore messageStore;
+
+    public ConsumeQueueCompactionFilterFactory(final MessageStore messageStore) {
+        this.messageStore = messageStore;
+    }
+
+    @Override
+    public String name() {
+        return "ConsumeQueueCompactionFilterFactory";
+    }
+
+    @Override
+    public RemoveConsumeQueueCompactionFilter createCompactionFilter(final AbstractCompactionFilter.Context context) {
+        long minPhyOffset = this.messageStore.getMinPhyOffset();
+        LOGGER.info("manualCompaction minPhyOffset: {}, isFull: {}, isManual: {}",
+                minPhyOffset, context.isFullCompaction(), context.isManualCompaction());
+        return new RemoveConsumeQueueCompactionFilter(minPhyOffset);
+    }
+}
diff --git a/store/src/main/java/org/apache/rocketmq/store/rocksdb/ConsumeQueueRocksDBStorage.java b/store/src/main/java/org/apache/rocketmq/store/rocksdb/ConsumeQueueRocksDBStorage.java
new file mode 100644
index 000000000..362684560
--- /dev/null
+++ b/store/src/main/java/org/apache/rocketmq/store/rocksdb/ConsumeQueueRocksDBStorage.java
@@ -0,0 +1,133 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.rocketmq.store.rocksdb;
+
+import java.util.ArrayList;
+import java.util.List;
+
+import org.apache.rocketmq.common.UtilAll;
+import org.apache.rocketmq.common.config.AbstractRocksDBStorage;
+import org.apache.rocketmq.common.utils.DataConverter;
+import org.apache.rocketmq.store.MessageStore;
+import org.rocksdb.ColumnFamilyDescriptor;
+import org.rocksdb.ColumnFamilyHandle;
+import org.rocksdb.ColumnFamilyOptions;
+import org.rocksdb.CompactRangeOptions;
+import org.rocksdb.ReadOptions;
+import org.rocksdb.RocksDB;
+import org.rocksdb.RocksDBException;
+import org.rocksdb.RocksIterator;
+import org.rocksdb.WriteBatch;
+import org.rocksdb.WriteOptions;
+
+public class ConsumeQueueRocksDBStorage extends AbstractRocksDBStorage {
+    private final MessageStore messageStore;
+    private volatile ColumnFamilyHandle offsetCFHandle;
+
+    public ConsumeQueueRocksDBStorage(final MessageStore messageStore, final String dbPath, final int prefixLen) {
+        this.messageStore = messageStore;
+        this.dbPath = dbPath;
+        this.readOnly = false;
+    }
+
+    private void initOptions() {
+        this.options = RocksDBOptionsFactory.createDBOptions();
+
+        this.writeOptions = new WriteOptions();
+        this.writeOptions.setSync(false);
+        this.writeOptions.setDisableWAL(true);
+        this.writeOptions.setNoSlowdown(true);
+
+        this.totalOrderReadOptions = new ReadOptions();
+        this.totalOrderReadOptions.setPrefixSameAsStart(false);
+        this.totalOrderReadOptions.setTotalOrderSeek(false);
+
+        this.compactRangeOptions = new CompactRangeOptions();
+        this.compactRangeOptions.setBottommostLevelCompaction(CompactRangeOptions.BottommostLevelCompaction.kForce);
+        this.compactRangeOptions.setAllowWriteStall(true);
+        this.compactRangeOptions.setExclusiveManualCompaction(false);
+        this.compactRangeOptions.setChangeLevel(true);
+        this.compactRangeOptions.setTargetLevel(-1);
+        this.compactRangeOptions.setMaxSubcompactions(4);
+    }
+
+    @Override
+    protected boolean postLoad() {
+        try {
+            UtilAll.ensureDirOK(this.dbPath);
+
+            initOptions();
+
+            final List<ColumnFamilyDescriptor> cfDescriptors = new ArrayList();
+
+            ColumnFamilyOptions cqCfOptions = RocksDBOptionsFactory.createCQCFOptions(this.messageStore);
+            this.cfOptions.add(cqCfOptions);
+            cfDescriptors.add(new ColumnFamilyDescriptor(RocksDB.DEFAULT_COLUMN_FAMILY, cqCfOptions));
+
+            ColumnFamilyOptions offsetCfOptions = RocksDBOptionsFactory.createOffsetCFOptions();
+            this.cfOptions.add(offsetCfOptions);
+            cfDescriptors.add(new ColumnFamilyDescriptor("offset".getBytes(DataConverter.CHARSET_UTF8), offsetCfOptions));
+
+            final List<ColumnFamilyHandle> cfHandles = new ArrayList();
+            open(cfDescriptors, cfHandles);
+
+            this.defaultCFHandle = cfHandles.get(0);
+            this.offsetCFHandle = cfHandles.get(1);
+        } catch (final Exception e) {
+            LOGGER.error("postLoad Failed. {}", this.dbPath, e);
+            return false;
+        }
+        return true;
+    }
+
+    @Override
+    protected void preShutdown() {
+        this.offsetCFHandle.close();
+    }
+
+    public byte[] getCQ(final byte[] keyBytes) throws RocksDBException {
+        return get(this.defaultCFHandle, this.totalOrderReadOptions, keyBytes);
+    }
+
+    public byte[] getOffset(final byte[] keyBytes) throws RocksDBException {
+        return get(this.offsetCFHandle, this.totalOrderReadOptions, keyBytes);
+    }
+
+    public List<byte[]> multiGet(final List<ColumnFamilyHandle> cfhList, final List<byte[]> keys) throws RocksDBException {
+        return multiGet(this.totalOrderReadOptions, cfhList, keys);
+    }
+
+    public void batchPut(final WriteBatch batch) throws RocksDBException {
+        batchPut(this.writeOptions, batch);
+    }
+
+    public void manualCompaction(final long minPhyOffset) {
+        try {
+            manualCompaction(minPhyOffset, this.compactRangeOptions);
+        } catch (Exception e) {
+            LOGGER.error("manualCompaction Failed. minPhyOffset: {}", minPhyOffset, e);
+        }
+    }
+
+    public RocksIterator seekOffsetCF() {
+        return this.db.newIterator(this.offsetCFHandle, this.totalOrderReadOptions);
+    }
+
+    public ColumnFamilyHandle getOffsetCFHandle() {
+        return this.offsetCFHandle;
+    }
+}
\ No newline at end of file
diff --git a/store/src/main/java/org/apache/rocketmq/store/rocksdb/RocksDBOptionsFactory.java b/store/src/main/java/org/apache/rocketmq/store/rocksdb/RocksDBOptionsFactory.java
new file mode 100644
index 000000000..a3a99d334
--- /dev/null
+++ b/store/src/main/java/org/apache/rocketmq/store/rocksdb/RocksDBOptionsFactory.java
@@ -0,0 +1,161 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.rocketmq.store.rocksdb;
+
+import org.apache.rocketmq.common.config.ConfigRocksDBStorage;
+import org.apache.rocketmq.store.MessageStore;
+import org.rocksdb.BlockBasedTableConfig;
+import org.rocksdb.BloomFilter;
+import org.rocksdb.ColumnFamilyOptions;
+import org.rocksdb.CompactionOptionsUniversal;
+import org.rocksdb.CompactionStopStyle;
+import org.rocksdb.CompactionStyle;
+import org.rocksdb.CompressionType;
+import org.rocksdb.DBOptions;
+import org.rocksdb.DataBlockIndexType;
+import org.rocksdb.IndexType;
+import org.rocksdb.InfoLogLevel;
+import org.rocksdb.LRUCache;
+import org.rocksdb.RateLimiter;
+import org.rocksdb.SkipListMemTableConfig;
+import org.rocksdb.Statistics;
+import org.rocksdb.StatsLevel;
+import org.rocksdb.StringAppendOperator;
+import org.rocksdb.WALRecoveryMode;
+import org.rocksdb.util.SizeUnit;
+
+public class RocksDBOptionsFactory {
+
+    public static ColumnFamilyOptions createCQCFOptions(final MessageStore messageStore) {
+        BlockBasedTableConfig blockBasedTableConfig = new BlockBasedTableConfig().
+                setFormatVersion(5).
+                setIndexType(IndexType.kBinarySearch).
+                setDataBlockIndexType(DataBlockIndexType.kDataBlockBinaryAndHash).
+                setDataBlockHashTableUtilRatio(0.75).
+                setBlockSize(32 * SizeUnit.KB).
+                setMetadataBlockSize(4 * SizeUnit.KB).
+                setFilterPolicy(new BloomFilter(16, false)).
+                setCacheIndexAndFilterBlocks(false).
+                setCacheIndexAndFilterBlocksWithHighPriority(true).
+                setPinL0FilterAndIndexBlocksInCache(false).
+                setPinTopLevelIndexAndFilter(true).
+                setBlockCache(new LRUCache(1024 * SizeUnit.MB, 8, false)).
+                setWholeKeyFiltering(true);
+
+        ColumnFamilyOptions columnFamilyOptions = new ColumnFamilyOptions();
+        CompactionOptionsUniversal compactionOption = new CompactionOptionsUniversal();
+        compactionOption.setSizeRatio(100).
+                setMaxSizeAmplificationPercent(25).
+                setAllowTrivialMove(true).
+                setMinMergeWidth(2).
+                setMaxMergeWidth(Integer.MAX_VALUE).
+                setStopStyle(CompactionStopStyle.CompactionStopStyleTotalSize).
+                setCompressionSizePercent(-1);
+        return columnFamilyOptions.setMaxWriteBufferNumber(4).
+                setWriteBufferSize(128 * SizeUnit.MB).
+                setMinWriteBufferNumberToMerge(1).
+                setTableFormatConfig(blockBasedTableConfig).
+                setMemTableConfig(new SkipListMemTableConfig()).
+                setCompressionType(CompressionType.LZ4_COMPRESSION).
+                setBottommostCompressionType(CompressionType.ZSTD_COMPRESSION).
+                setNumLevels(7).
+                setCompactionStyle(CompactionStyle.UNIVERSAL).
+                setCompactionOptionsUniversal(compactionOption).
+                setMaxCompactionBytes(100 * SizeUnit.GB).
+                setSoftPendingCompactionBytesLimit(100 * SizeUnit.GB).
+                setHardPendingCompactionBytesLimit(256 * SizeUnit.GB).
+                setLevel0FileNumCompactionTrigger(2).
+                setLevel0SlowdownWritesTrigger(8).
+                setLevel0StopWritesTrigger(10).
+                setTargetFileSizeBase(256 * SizeUnit.MB).
+                setTargetFileSizeMultiplier(2).
+                setMergeOperator(new StringAppendOperator()).
+                setCompactionFilterFactory(new ConsumeQueueCompactionFilterFactory(messageStore)).
+                setReportBgIoStats(true).
+                setOptimizeFiltersForHits(true);
+    }
+
+    public static ColumnFamilyOptions createOffsetCFOptions() {
+        BlockBasedTableConfig blockBasedTableConfig = new BlockBasedTableConfig().
+                setFormatVersion(5).
+                setIndexType(IndexType.kBinarySearch).
+                setDataBlockIndexType(DataBlockIndexType.kDataBlockBinarySearch).
+                setBlockSize(32 * SizeUnit.KB).
+                setFilterPolicy(new BloomFilter(16, false)).
+                setCacheIndexAndFilterBlocks(false).
+                setCacheIndexAndFilterBlocksWithHighPriority(true).
+                setPinL0FilterAndIndexBlocksInCache(false).
+                setPinTopLevelIndexAndFilter(true).
+                setBlockCache(new LRUCache(128 * SizeUnit.MB, 8, false)).
+                setWholeKeyFiltering(true);
+
+        ColumnFamilyOptions columnFamilyOptions = new ColumnFamilyOptions();
+        return columnFamilyOptions.setMaxWriteBufferNumber(4).
+                setWriteBufferSize(64 * SizeUnit.MB).
+                setMinWriteBufferNumberToMerge(1).
+                setTableFormatConfig(blockBasedTableConfig).
+                setMemTableConfig(new SkipListMemTableConfig()).
+                setCompressionType(CompressionType.NO_COMPRESSION).
+                setNumLevels(7).
+                setCompactionStyle(CompactionStyle.LEVEL).
+                setLevel0FileNumCompactionTrigger(2).
+                setLevel0SlowdownWritesTrigger(8).
+                setLevel0StopWritesTrigger(10).
+                setTargetFileSizeBase(64 * SizeUnit.MB).
+                setTargetFileSizeMultiplier(2).
+                setMaxBytesForLevelBase(256 * SizeUnit.MB).
+                setMaxBytesForLevelMultiplier(2).
+                setMergeOperator(new StringAppendOperator()).
+                setInplaceUpdateSupport(true);
+    }
+
+    /**
+     * Create a rocksdb db options, the user must take care to close it after closing db.
+     * @return
+     */
+    public static DBOptions createDBOptions() {
+        //Turn based on https://github.com/facebook/rocksdb/wiki/RocksDB-Tuning-Guide
+        // and http://gitlab.alibaba-inc.com/aloha/aloha/blob/branch_2_5_0/jstorm-core/src/main/java/com/alibaba/jstorm/cache/rocksdb/RocksDbOptionsFactory.java
+        DBOptions options = new DBOptions();
+        Statistics statistics = new Statistics();
+        statistics.setStatsLevel(StatsLevel.EXCEPT_DETAILED_TIMERS);
+        return options.
+                setDbLogDir(ConfigRocksDBStorage.getDBLogDir()).
+                setInfoLogLevel(InfoLogLevel.INFO_LEVEL).
+                setWalRecoveryMode(WALRecoveryMode.PointInTimeRecovery).
+                setManualWalFlush(true).
+                setMaxTotalWalSize(0).
+                setWalSizeLimitMB(0).
+                setWalTtlSeconds(0).
+                setCreateIfMissing(true).
+                setCreateMissingColumnFamilies(true).
+                setMaxOpenFiles(-1).
+                setMaxLogFileSize(1 * SizeUnit.GB).
+                setKeepLogFileNum(5).
+                setMaxManifestFileSize(1 * SizeUnit.GB).
+                setAllowConcurrentMemtableWrite(false).
+                setStatistics(statistics).
+                setAtomicFlush(true).
+                setMaxBackgroundJobs(32).
+                setMaxSubcompactions(8).
+                setParanoidChecks(true).
+                setDelayedWriteRate(16 * SizeUnit.MB).
+                setRateLimiter(new RateLimiter(100 * SizeUnit.MB)).
+                setUseDirectIoForFlushAndCompaction(false).
+                setUseDirectReads(false);
+    }
+}
diff --git a/store/src/main/java/org/apache/rocketmq/store/timer/TimerMessageStore.java b/store/src/main/java/org/apache/rocketmq/store/timer/TimerMessageStore.java
index ac4c61cd6..3ab51a26d 100644
--- a/store/src/main/java/org/apache/rocketmq/store/timer/TimerMessageStore.java
+++ b/store/src/main/java/org/apache/rocketmq/store/timer/TimerMessageStore.java
@@ -57,7 +57,6 @@ import org.apache.rocketmq.common.topic.TopicValidator;
 import org.apache.rocketmq.common.utils.ThreadUtils;
 import org.apache.rocketmq.logging.org.slf4j.Logger;
 import org.apache.rocketmq.logging.org.slf4j.LoggerFactory;
-import org.apache.rocketmq.store.ConsumeQueue;
 import org.apache.rocketmq.store.DefaultMessageStore;
 import org.apache.rocketmq.store.MessageStore;
 import org.apache.rocketmq.store.PutMessageResult;
@@ -66,6 +65,9 @@ import org.apache.rocketmq.store.config.BrokerRole;
 import org.apache.rocketmq.store.config.MessageStoreConfig;
 import org.apache.rocketmq.store.logfile.MappedFile;
 import org.apache.rocketmq.store.metrics.DefaultStoreMetricsManager;
+import org.apache.rocketmq.store.queue.ConsumeQueueInterface;
+import org.apache.rocketmq.store.queue.CqUnit;
+import org.apache.rocketmq.store.queue.ReferredIterator;
 import org.apache.rocketmq.store.stats.BrokerStatsManager;
 import org.apache.rocketmq.store.util.PerfCounter;
 
@@ -333,7 +335,7 @@ public class TimerMessageStore {
             // if not, use cq offset.
             long msgQueueOffset = messageExt.getQueueOffset();
             int queueId = messageExt.getQueueId();
-            ConsumeQueue cq = (ConsumeQueue) this.messageStore.getConsumeQueue(TIMER_TOPIC, queueId);
+            ConsumeQueueInterface cq = this.messageStore.getConsumeQueue(TIMER_TOPIC, queueId);
             if (null == cq) {
                 return msgQueueOffset;
             }
@@ -346,15 +348,18 @@ public class TimerMessageStore {
                         offsetPy, sizePy);
                     break;
                 }
-                SelectMappedBufferResult bufferCQ = cq.getIndexBuffer(tmpOffset);
-                if (null == bufferCQ) {
-                    // offset in msg may be greater than offset of cq.
-                    tmpOffset -= 1;
-                    continue;
-                }
+                ReferredIterator<CqUnit> iterator = null;
                 try {
-                    long offsetPyTemp = bufferCQ.getByteBuffer().getLong();
-                    int sizePyTemp = bufferCQ.getByteBuffer().getInt();
+                    iterator = cq.iterateFrom(tmpOffset);
+                    CqUnit cqUnit = null;
+                    if (null == iterator || (cqUnit = iterator.next()) == null) {
+                        // offset in msg may be greater than offset of cq.
+                        tmpOffset -= 1;
+                        continue;
+                    }
+
+                    long offsetPyTemp = cqUnit.getPos();
+                    int sizePyTemp = cqUnit.getSize();
                     if (offsetPyTemp == offsetPy && sizePyTemp == sizePy) {
                         LOGGER.info("reviseQueueOffset check cq offset ok. {}, {}, {}",
                             tmpOffset, offsetPyTemp, sizePyTemp);
@@ -365,7 +370,9 @@ public class TimerMessageStore {
                 } catch (Throwable e) {
                     LOGGER.error("reviseQueueOffset check cq offset error.", e);
                 } finally {
-                    bufferCQ.release();
+                    if (iterator != null) {
+                        iterator.release();
+                    }
                 }
             }
 
@@ -633,7 +640,7 @@ public class TimerMessageStore {
         if (!isRunningEnqueue()) {
             return false;
         }
-        ConsumeQueue cq = (ConsumeQueue) this.messageStore.getConsumeQueue(TIMER_TOPIC, queueId);
+        ConsumeQueueInterface cq = this.messageStore.getConsumeQueue(TIMER_TOPIC, queueId);
         if (null == cq) {
             return false;
         }
@@ -643,18 +650,22 @@ public class TimerMessageStore {
             currQueueOffset = cq.getMinOffsetInQueue();
         }
         long offset = currQueueOffset;
-        SelectMappedBufferResult bufferCQ = cq.getIndexBuffer(offset);
-        if (null == bufferCQ) {
-            return false;
-        }
+        ReferredIterator<CqUnit> iterator = null;
         try {
+            iterator = cq.iterateFrom(offset);
+            if (null == iterator) {
+                return false;
+            }
+
             int i = 0;
-            for (; i < bufferCQ.getSize(); i += ConsumeQueue.CQ_STORE_UNIT_SIZE) {
+            while (iterator.hasNext()) {
+                i++;
                 perfCounterTicks.startTick("enqueue_get");
                 try {
-                    long offsetPy = bufferCQ.getByteBuffer().getLong();
-                    int sizePy = bufferCQ.getByteBuffer().getInt();
-                    bufferCQ.getByteBuffer().getLong(); //tags code
+                    CqUnit cqUnit = iterator.next();
+                    long offsetPy = cqUnit.getPos();
+                    int sizePy = cqUnit.getSize();
+                    cqUnit.getTagsCode(); //tags code
                     MessageExt msgExt = getMessageByCommitOffset(offsetPy, sizePy);
                     if (null == msgExt) {
                         perfCounterTicks.getCounter("enqueue_get_miss");
@@ -663,7 +674,7 @@ public class TimerMessageStore {
                         lastEnqueueButExpiredStoreTime = msgExt.getStoreTimestamp();
                         long delayedTime = Long.parseLong(msgExt.getProperty(TIMER_OUT_MS));
                         // use CQ offset, not offset in Message
-                        msgExt.setQueueOffset(offset + (i / ConsumeQueue.CQ_STORE_UNIT_SIZE));
+                        msgExt.setQueueOffset(offset + i);
                         TimerRequest timerRequest = new TimerRequest(offsetPy, sizePy, delayedTime, System.currentTimeMillis(), MAGIC_DEFAULT, msgExt);
                         // System.out.printf("build enqueue request, %s%n", timerRequest);
                         while (!enqueuePutQueue.offer(timerRequest, 3, TimeUnit.SECONDS)) {
@@ -687,14 +698,16 @@ public class TimerMessageStore {
                 if (!isRunningEnqueue()) {
                     return false;
                 }
-                currQueueOffset = offset + (i / ConsumeQueue.CQ_STORE_UNIT_SIZE);
+                currQueueOffset = offset + i;
             }
-            currQueueOffset = offset + (i / ConsumeQueue.CQ_STORE_UNIT_SIZE);
+            currQueueOffset = offset + i;
             return i > 0;
         } catch (Exception e) {
             LOGGER.error("Unknown exception in enqueuing", e);
         } finally {
-            bufferCQ.release();
+            if (iterator != null) {
+                iterator.release();
+            }
         }
         return false;
     }
@@ -1642,7 +1655,7 @@ public class TimerMessageStore {
                     if (System.currentTimeMillis() - start > storeConfig.getTimerProgressLogIntervalMs()) {
                         start = System.currentTimeMillis();
                         long tmpQueueOffset = currQueueOffset;
-                        ConsumeQueue cq = (ConsumeQueue) messageStore.getConsumeQueue(TIMER_TOPIC, 0);
+                        ConsumeQueueInterface cq = messageStore.getConsumeQueue(TIMER_TOPIC, 0);
                         long maxOffsetInQueue = cq == null ? 0 : cq.getMaxOffsetInQueue();
                         TimerMessageStore.LOGGER.info("[{}]Timer progress-check commitRead:[{}] currRead:[{}] currWrite:[{}] readBehind:{} currReadOffset:{} offsetBehind:{} behindMaster:{} " +
                                 "enqPutQueue:{} deqGetQueue:{} deqPutQueue:{} allCongestNum:{} enqExpiredStoreTime:{}",
@@ -1685,7 +1698,7 @@ public class TimerMessageStore {
 
     public long getEnqueueBehindMessages() {
         long tmpQueueOffset = currQueueOffset;
-        ConsumeQueue cq = (ConsumeQueue) messageStore.getConsumeQueue(TIMER_TOPIC, 0);
+        ConsumeQueueInterface cq = messageStore.getConsumeQueue(TIMER_TOPIC, 0);
         long maxOffsetInQueue = cq == null ? 0 : cq.getMaxOffsetInQueue();
         return maxOffsetInQueue - tmpQueueOffset;
     }
diff --git a/tieredstore/src/main/java/org/apache/rocketmq/tieredstore/TieredMessageStore.java b/tieredstore/src/main/java/org/apache/rocketmq/tieredstore/TieredMessageStore.java
index d7d13d61e..edaa5d19f 100644
--- a/tieredstore/src/main/java/org/apache/rocketmq/tieredstore/TieredMessageStore.java
+++ b/tieredstore/src/main/java/org/apache/rocketmq/tieredstore/TieredMessageStore.java
@@ -16,17 +16,14 @@
  */
 package org.apache.rocketmq.tieredstore;
 
-import com.google.common.base.Stopwatch;
-import io.opentelemetry.api.common.Attributes;
-import io.opentelemetry.api.common.AttributesBuilder;
-import io.opentelemetry.api.metrics.Meter;
-import io.opentelemetry.sdk.metrics.InstrumentSelector;
-import io.opentelemetry.sdk.metrics.ViewBuilder;
 import java.util.List;
 import java.util.Set;
 import java.util.concurrent.CompletableFuture;
 import java.util.concurrent.TimeUnit;
 import java.util.function.Supplier;
+
+import com.google.common.base.Stopwatch;
+
 import org.apache.commons.lang3.StringUtils;
 import org.apache.rocketmq.common.BoundaryType;
 import org.apache.rocketmq.common.MixAll;
@@ -55,6 +52,12 @@ import org.apache.rocketmq.tieredstore.metrics.TieredStoreMetricsConstant;
 import org.apache.rocketmq.tieredstore.metrics.TieredStoreMetricsManager;
 import org.apache.rocketmq.tieredstore.util.TieredStoreUtil;
 
+import io.opentelemetry.api.common.Attributes;
+import io.opentelemetry.api.common.AttributesBuilder;
+import io.opentelemetry.api.metrics.Meter;
+import io.opentelemetry.sdk.metrics.InstrumentSelector;
+import io.opentelemetry.sdk.metrics.ViewBuilder;
+
 public class TieredMessageStore extends AbstractPluginMessageStore {
 
     protected static final Logger logger = LoggerFactory.getLogger(TieredStoreUtil.TIERED_STORE_LOGGER_NAME);
diff --git a/tools/src/main/java/org/apache/rocketmq/tools/command/export/ExportMetadataInRocksDBCommand.java b/tools/src/main/java/org/apache/rocketmq/tools/command/export/ExportMetadataInRocksDBCommand.java
index 2a7d3fba4..1ecb1fa2c 100644
--- a/tools/src/main/java/org/apache/rocketmq/tools/command/export/ExportMetadataInRocksDBCommand.java
+++ b/tools/src/main/java/org/apache/rocketmq/tools/command/export/ExportMetadataInRocksDBCommand.java
@@ -106,8 +106,8 @@ public class ExportMetadataInRocksDBCommand implements SubCommand {
             final Map<String, JSONObject> jsonConfig = new HashMap<>();
             final Map<String, JSONObject> configTable = new HashMap<>();
             iterateKvStore(kvStore, (key, value) -> {
-                    final String configKey = new String(key, DataConverter.charset);
-                    final String configValue = new String(value, DataConverter.charset);
+                    final String configKey = new String(key, DataConverter.CHARSET_UTF8);
+                    final String configValue = new String(value, DataConverter.CHARSET_UTF8);
                     final JSONObject jsonObject = JSONObject.parseObject(configValue);
                     configTable.put(configKey, jsonObject);
                 }
@@ -120,8 +120,8 @@ public class ExportMetadataInRocksDBCommand implements SubCommand {
         } else {
             AtomicLong count = new AtomicLong(0);
             iterateKvStore(kvStore, (key, value) -> {
-                final String configKey = new String(key, DataConverter.charset);
-                final String configValue = new String(value, DataConverter.charset);
+                final String configKey = new String(key, DataConverter.CHARSET_UTF8);
+                final String configValue = new String(value, DataConverter.CHARSET_UTF8);
                 System.out.printf("%d, Key: %s, Value: %s%n", count.incrementAndGet(), configKey, configValue);
             });
         }
diff --git a/tools/src/main/java/org/apache/rocketmq/tools/command/metadata/RocksDBConfigToJsonCommand.java b/tools/src/main/java/org/apache/rocketmq/tools/command/metadata/RocksDBConfigToJsonCommand.java
new file mode 100644
index 000000000..b987ad873
--- /dev/null
+++ b/tools/src/main/java/org/apache/rocketmq/tools/command/metadata/RocksDBConfigToJsonCommand.java
@@ -0,0 +1,118 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.rocketmq.tools.command.metadata;
+
+import com.alibaba.fastjson.JSONObject;
+import org.apache.commons.cli.CommandLine;
+import org.apache.commons.cli.Option;
+import org.apache.commons.cli.Options;
+import org.apache.commons.lang3.StringUtils;
+import org.apache.rocketmq.common.config.RocksDBConfigManager;
+import org.apache.rocketmq.common.utils.DataConverter;
+import org.apache.rocketmq.remoting.RPCHook;
+import org.apache.rocketmq.tools.command.SubCommand;
+import org.apache.rocketmq.tools.command.SubCommandException;
+
+import java.io.File;
+import java.util.HashMap;
+import java.util.Map;
+
+public class RocksDBConfigToJsonCommand implements SubCommand {
+    private static final String TOPICS_JSON_CONFIG = "topics";
+    private static final String SUBSCRIPTION_GROUP_JSON_CONFIG = "subscriptionGroups";
+
+    @Override
+    public String commandName() {
+        return "rocksDBConfigToJson";
+    }
+
+    @Override
+    public String commandDesc() {
+        return "Convert RocksDB kv config (topics/subscriptionGroups) to json";
+    }
+
+    @Override
+    public Options buildCommandlineOptions(Options options) {
+        Option pathOption = new Option("p", "path", true,
+                "Absolute path to the metadata directory");
+        pathOption.setRequired(true);
+        options.addOption(pathOption);
+
+        Option configTypeOption = new Option("t", "configType", true, "Name of kv config, e.g. " +
+                "topics/subscriptionGroups");
+        configTypeOption.setRequired(true);
+        options.addOption(configTypeOption);
+
+        return options;
+    }
+
+    @Override
+    public void execute(CommandLine commandLine, Options options, RPCHook rpcHook) throws SubCommandException {
+        String path = commandLine.getOptionValue("path").trim();
+        if (StringUtils.isEmpty(path) || !new File(path).exists()) {
+            System.out.print("Rocksdb path is invalid.\n");
+            return;
+        }
+
+        String configType = commandLine.getOptionValue("configType").trim().toLowerCase();
+
+        final long memTableFlushInterval = 60 * 60 * 1000L;
+        RocksDBConfigManager kvConfigManager = new RocksDBConfigManager(memTableFlushInterval);
+        try {
+            if (TOPICS_JSON_CONFIG.toLowerCase().equals(configType)) {
+                // for topics.json
+                final Map<String, JSONObject> topicsJsonConfig = new HashMap<>();
+                final Map<String, JSONObject> topicConfigTable = new HashMap<>();
+                boolean isLoad = kvConfigManager.load(path, (key, value) -> {
+                    final String topic = new String(key, DataConverter.CHARSET_UTF8);
+                    final String topicConfig = new String(value, DataConverter.CHARSET_UTF8);
+                    final JSONObject jsonObject = JSONObject.parseObject(topicConfig);
+                    topicConfigTable.put(topic, jsonObject);
+                });
+
+                if (isLoad) {
+                    topicsJsonConfig.put("topicConfigTable", (JSONObject) JSONObject.toJSON(topicConfigTable));
+                    final String topicsJsonStr = JSONObject.toJSONString(topicsJsonConfig, true);
+                    System.out.print(topicsJsonStr + "\n");
+                    return;
+                }
+            }
+            if (SUBSCRIPTION_GROUP_JSON_CONFIG.toLowerCase().equals(configType)) {
+                // for subscriptionGroup.json
+                final Map<String, JSONObject> subscriptionGroupJsonConfig = new HashMap<>();
+                final Map<String, JSONObject> subscriptionGroupTable = new HashMap<>();
+                boolean isLoad = kvConfigManager.load(path, (key, value) -> {
+                    final String subscriptionGroup = new String(key, DataConverter.CHARSET_UTF8);
+                    final String subscriptionGroupConfig = new String(value, DataConverter.CHARSET_UTF8);
+                    final JSONObject jsonObject = JSONObject.parseObject(subscriptionGroupConfig);
+                    subscriptionGroupTable.put(subscriptionGroup, jsonObject);
+                });
+
+                if (isLoad) {
+                    subscriptionGroupJsonConfig.put("subscriptionGroupTable",
+                            (JSONObject) JSONObject.toJSON(subscriptionGroupTable));
+                    final String subscriptionGroupJsonStr = JSONObject.toJSONString(subscriptionGroupJsonConfig, true);
+                    System.out.print(subscriptionGroupJsonStr + "\n");
+                    return;
+                }
+            }
+            System.out.print("Config type was not recognized, configType=" + configType + "\n");
+        } finally {
+            kvConfigManager.stop();
+        }
+    }
+}
